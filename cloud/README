Basic cloud setup:

------------------------------------------
Create new VMs using vagrant:

cd cloud/vagrant
deactivate # leave the sigvisa virtualenv before calling ansible
vagrant up --provider=azure

Edit the cloud/vagrant/Vagrantfile to determine the number of VMs
created. VMs are provisioned using Ansible. The sigvisa_day95 image
has been pre-provisioned, so the main effect of Ansible is to pull the
latest code from git master. 

If using a lot of machines, Vagrant will be very slow to provision
because it touches them all in sequence. Instead we can run ansible
directly, which is smart about parallelizing:
vagrant up --provider=azure --no-provision
ansible-playbook -i .vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory -u vagrant playbook.yml

-------------------------------------------
To upload trained param models, use Fabric. Note the sigvisa_day95
image already contains basic parameteric models for the top40
stations, so you may not need to do this.  For some reason Fabric
refuses to recognize the SSH key unless ssh-agent is up and running,
so ensure that first:

eval `ssh-agent -s`
ssh-add ~/.ssh/azurevagrant.pem

Then edit the hosts list in cloud/fabscripts/push_param_models.py, to
match whatever you created with Vagrant (probably sigvisa1, ...,
sigvisaN@cloudapp.net). Finally, run

cd cloud/fabscripts/
fab -f push_param_models.py  deploy_models:runid=1,dump_fname="whatever"

--------------------------------------------

To run naive parallel inference on a given time period, run a command of the form

python cloud/inference/infer_parallel.py --stime=1199124000 --etime=1199145600 --nnodes=2 --label=stuff "experiments/ctf_regional.py --hz=2.0 --runid=1"

where nnodes is the number of machines to use (the script assumes
these are already running and provisioned at
sigvisa[1-n].cloudapp.net), the final command is the python script to
execute on the remote machines, and results will be stored in
cloud/remote_jobs/<label>/.

