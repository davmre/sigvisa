import numpy as np
import copy
import sys
import traceback
import pdb
import pickle
import os
import itertools
from collections import defaultdict


from sigvisa import Sigvisa
from sigvisa.graph.array_node import lldlld_X
from sigvisa.graph.nodes import Node
from sigvisa.graph.graph_utils import extract_sta_node, create_key, get_parent_value, parse_key
from sigvisa.graph.sigvisa_graph import get_param_model_id, dummyPriorModel, ModelNotFoundError, SigvisaGraph
from sigvisa.graph.dag import ParentConditionalNotDefined
from sigvisa.ssms_c import TransientCombinedSSM
from sigvisa.infer.propose_hough import hough_location_proposal, visualize_hough_array
from sigvisa.infer.propose_lstsqr import overpropose_new_locations
from sigvisa.infer.propose_mb import propose_mb
from sigvisa.infer.local_gibbs_move import proxylp_full, approximate_scalar_gibbs_distribution
from sigvisa.infer.propose_cheating import cheating_location_proposal
from sigvisa.infer.correlations.ar_correlation_model import ar_advantage
from sigvisa.infer.correlations.event_proposal import correlation_location_proposal, sample_corr_kwargs, plot_proposal_weights
from sigvisa.infer.template_mcmc import get_env_based_amplitude_distribution, get_env_based_amplitude_distribution2, get_env_diff_positive_part, sample_peak_time_from_cdf, merge_distribution, peak_log_p, preprocess_signal_for_sampling
from sigvisa.infer.template_xc import fastxc
from sigvisa.infer.mcmc_basic import mh_accept_util
from sigvisa.learn.train_param_common import load_modelid
from sigvisa.models.ttime import tt_residual, tt_predict
from sigvisa.models.templates.coda_height import amp_transfer
from sigvisa.models.distributions import Gaussian, Laplacian, PiecewiseLinear, TruncatedGaussian
from sigvisa.models.signal_model import unify_windows
from sigvisa.signals.common import Waveform
from sigvisa.utils.counter import Counter
from sigvisa.utils.fileutils import mkdir_p
from sigvisa.utils.array import index_to_time, time_to_index

from sigvisa.source.event import get_event
import sigvisa.source.brune_source as brune

hough_options = {'bin_width_deg':1.0, 'time_tick_s': 10.0, 'smoothbins': True}

def set_hough_options(ho):
    global hough_options
    hough_options = ho

def unass_template_logprob(sg, wn, template_dict, return_debug=False, 
                           atime_only=False, ignore_mb=False, 
                           entropy_score=False):
    """

    return the log prob of a set of template parameters, under the
    model of unassociated templates at a station sta.

    """

    # HACK

    tg = sg.template_generator(phase="UA")

    lps = {}
    lp = 0.0
    lp_atime = np.log(sg.uatemplate_rate) #-np.log(float(wn.npts)/wn.srate) # arrival time
    lp += lp_atime
    lps['ua_atime'] = lp_atime

    other_params = () if atime_only else tg.params(env=wn.is_env) 
    for param in other_params:

        model = tg.unassociated_model(param, nm=wn.nm)
        lp_param = model.log_p(template_dict[param])

        if entropy_score:
            lp_param += model.entropy()

        if return_debug:
            lps[param] = lp_param

        if ignore_mb and param=="coda_height": continue
        lp += lp_param

    if return_debug:
        return lp, lps
    else:
        return lp

def param_logprob(sg, site, sta, ev, phase, chan, band, param, val):

    """
    return the log probability for an individual template parameter,
    as generated by an event phase arrival, WITHOUT interfering with
    the graph.
    """

    if param=="coda_height":
        param="amp_transfer"
        val = amp_transfer(ev, band, phase, val)

    try:
        tmnodes = sg.get_template_nodes(ev.eid, sta, phase, band, chan)
        model = tmnodes[param][1].model
        cond = ev
    except Exception as e:
        model_type = sg._tm_type(param, site=site)
        if model_type == "dummy":
            return 0.0
        if model_type == "dummyPrior":
            model = dummyPriorModel[param]
            return model.log_p(x=val)

        s = Sigvisa()
        if s.is_array_station(site) and sg.arrays_joint:
            modelid = get_param_model_id(runids=sg.runids, sta=site,
                                         phase=phase, model_type=model_type,
                                         param=param, template_shape=sg.template_shape,
                                         chan=chan, band=band)
            cond = lldlld_X(ev, sta)
        else:
            try:
                modelid = get_param_model_id(runids=sg.runids, sta=sta,
                                             phase=phase, model_type=model_type,
                                             param=param, template_shape=sg.template_shape,
                                             chan=chan, band=band)
            except ModelNotFoundError as e:
                if sg.dummy_fallback:
                    modelid = -1
                else:
                    raise e

            cond = ev

        if modelid > -1:
            model = load_modelid(modelid)
        else:
            model = sg.dummy_prior[param]

    lp = model.log_p(x = val, cond = cond)
    if sg.hack_param_constraint:
        lp += Node.param_truncation_penalty(param=param, value=val)
    return lp

def ev_phase_template_logprob(sg, wn, eid, phase, template_dict, 
                              return_debug=False, atime_only=False, 
                              ignore_mb=False):

    """
    return log p(template params in template_dict) under the distribution generated by a phase arrival from event eid at station sta.
    """

    ev = sg.get_event(eid)
    sta = wn.sta
    s = Sigvisa()
    site = s.get_array_site(sta)

    if 'tt_residual' not in template_dict and 'arrival_time' in template_dict:
        template_dict['tt_residual'] = tt_residual(ev, wn.sta, template_dict['arrival_time'], phase=phase)
        if atime_only:
            # hack to avoid association problems from bad models. in
            # the atime only case we don't care about the true model
            # probability anyway since we're going to repropose the
            # template.
            model = Laplacian(0, 5.0)
            return model.log_p(template_dict['tt_residual'])

    if 'amp_transfer' not in template_dict and "coda_height" in template_dict:
        template_dict['amp_transfer'] = amp_transfer(ev, wn.band, phase, template_dict['coda_height'])
    # note if coda height is not specified, we'll ignore amp params
    # entirely: this is used by the create-new-template proposer
    # (in phase_template_proposal_logp etc)

    lp = 0
    lps = {}
    for (param, val) in template_dict.items():
        if param in ('arrival_time', 'coda_height'): continue
        if ignore_mb and param == 'amp_transfer': continue
        if atime_only and param != "tt_residual": continue

        lp_param = param_logprob(sg, site, wn.sta, ev, phase, wn.chan, wn.band, param, val)
        if return_debug:
            lps[param] = lp_param
            print "%s lp %s=%.2f is %.2f" % (wn.sta, param, val, lp_param)
        lp += lp_param

    if return_debug:
        return lp, lps
    else:
        return lp


def joint_association_distribution(sg, wn, eid, phases, 
                                   atime_only=False,
                                   associate_using_mb=True, 
                                   max_ttr="sg"):
    if max_ttr == "sg":
        # default max_ttr is slightly larger than the model's max, to account for the fact that 
        # the truncation penalty in nodes.py is really a soft penalty, which occasionally is
        # violated slightly, but we still want to give nonzero probability to those associations
        # since otherwise we get unkillable events. 
        max_ttr = sg.hack_ttr_max + 1.0


    ev = sg.get_event(eid)
    possible_associations = defaultdict(list)
    ignore_mb = not associate_using_mb
    
    for phase in phases:
        
        pred_atime = ev.time + tt_predict(ev, wn.sta, phase=phase)
        possible_associations[phase].append((None, 1.0))
        for tmid in sg.uatemplate_ids[(wn.sta,wn.chan,wn.band)]:
            tmnodes = sg.uatemplates[tmid]
            atime = tmnodes['arrival_time'].get_value()
            if np.abs(atime - pred_atime) < max_ttr: 
                odds = np.exp(template_association_logodds(sg, wn, tmid, eid, phase, ignore_mb=ignore_mb, atime_only=atime_only))
                possible_associations[phase].append((tmid, odds))
                sg.logger.debug( "odds for %s %d are %s" % (phase, tmid, odds))

    vals = [possible_associations[k] for k in phases]
    joint_dist = Counter()
    for assoc in itertools.product(*vals):
        tmids, odds = zip(*assoc)
        nontrivial_tmids = [t for t in tmids if t is not None]
        if len(set(nontrivial_tmids)) != len(nontrivial_tmids):
            # duplicate tmid, assigned to two phases
            continue
        joint_dist[tmids] = np.prod(odds)

    joint_dist.normalize()
    return joint_dist


def template_association_logodds(sg, wn, tmid, eid, phase, atime_only=False, ignore_mb=False):

    tmnodes = sg.uatemplates[tmid]
    param_values = dict([(k, n.get_value()) for (k,n) in tmnodes.items()])

    lp_unass = unass_template_logprob(sg, wn, param_values, 
                                      atime_only=atime_only, ignore_mb=ignore_mb)
    lp_ev = ev_phase_template_logprob(sg, wn, eid, phase, param_values, 
                                      atime_only=atime_only, ignore_mb=ignore_mb)
    
    logodds = lp_ev - lp_unass
    return logodds


def template_association_distribution(sg, wn, eid, phase, ignore_mb=False, forbidden=None):
    """
    Returns a counter with normalized probabilities for associating
    any existing unassociated templates at station sta with a given
    phase of event eid. Probability of no association is given by c[None].

    """

    sta, band, chan = wn.sta, wn.band, wn.chan

    c = Counter()
    for tmid in sg.uatemplate_ids[(sta,chan,band)]:
        if forbidden is not None and tmid in forbidden: continue
        c[tmid] += np.exp(template_association_logodds(sg, wn, tmid, eid,
                                                       phase, ignore_mb=ignore_mb))

    # if there are no unassociated templates, there's nothing to sample.
    n_u = len(sg.uatemplate_ids[(sta, chan, band)])
    if n_u == 0:
        c[None] = 1.0
        return c

    c[None] = np.exp(sg.ntemplates_sta_log_p(wn, n=n_u) - sg.ntemplates_sta_log_p(wn, n=n_u-1))

    c.normalize()

    # smooth probabilities slightly, so we don't get proposals that
    # are impossible to reverse
    nkeys = len(c.keys())
    for k in c.keys():
        c[k] += 1e-4/nkeys
    c.normalize()

    return c

def sample_template_to_associate(sg, wn, eid, phase, 
                                 ignore_mb=False, forbidden=None,
                                 fix_result=None):
    """
    Propose associating an unassociate template at sta with the
    (eid,phase) arrival, with probability proportional to the odds
    ratio p_{E,P}(T)/p_U(T). Alternately propose creating a new
    template, with probability proportional to p(N_U = n_U)/p(N_U =
    n_U - 1).

    Return:
    tmid: the unassociated template id proposed for
          association. (value of None indicates proposing a creation
          move)
    assoc_logprob: log probability of the proposal

    """


    c = template_association_distribution(sg, wn, eid, phase, ignore_mb=ignore_mb, forbidden=forbidden)
    if fix_result is not None:
        tmid = fix_result
    else:
        tmid = c.sample()
    assoc_logprob = np.log(c[tmid])
    return tmid, assoc_logprob

def associate_template(sg, wn, tmid, eid, phase, create_phase_arrival=False, node_lps=None):
    """

    Transform the graph to associate the template tmid with the arrival of eid/phase at sta.

    """

    tmnodes = sg.uatemplates[tmid]
    sta = wn.sta
    s = Sigvisa()
    site = s.get_array_site(sta)

    values = dict([(k, n.get_value()) for (k, n) in tmnodes.items()])
    phase_created = False
    if create_phase_arrival and phase not in sg.ev_arriving_phases(eid, sta=sta):
        tg = sg.template_generator(phase)
        sg.add_event_site_phase(tg, site, phase, sg.evnodes[eid])
        phase_created=True

    if node_lps is not None:
        if phase_created:
            node_lps.register_new_phase_pre(sg, site, phase, eid)
        else:
            node_lps.register_phase_changed_oldvals(sg, site, phase, eid, wn_invariant=True)

    # if a newly birthed event, it already has a phase arrival that just needs to be set
    sg.set_template(eid, wn.sta, phase, wn.band, wn.chan, values)

    if node_lps is not None:
        if phase_created:
            node_lps.register_new_phase_post(sg, site, phase, eid)
        else:
            node_lps.register_phase_changed_newvals(sg, site, phase, eid, wn_invariant=True)
        node_lps.register_remove_uatemplate(sg, tmid, wn_invariant=True)
    sg.destroy_unassociated_template(tmnodes, nosort=True)
    return

def unassociate_template(sg, wn, eid, phase, tmid=None, remove_event_phase=False, node_lps=None):

    s = Sigvisa()
    site = s.get_array_site(wn.sta)

    
    ev_tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)

    atime = ev_tmvals['arrival_time']
    tmnodes = sg.create_unassociated_template(wn, atime, nosort=True,
                                           tmid=tmid, initial_vals=ev_tmvals)
    tmid = tmnodes.values()[0].tmid
    if node_lps is not None:
        node_lps.register_new_uatemplate(sg, tmid)

    if remove_event_phase:
        # if we're just unassociating this phase (not deleting the
        # whole event), we need to delete the event phase arrival.
        if node_lps is not None:
            node_lps.register_phase_removed_pre(sg, site, phase, eid, wn_invariant=True)

        # assume we're doing this as part of a larger move,
        # so we'll fix the topo sorting later
        sg.delete_event_phase(eid, site, phase, re_sort=False)

    return tmid

def deassociation_logprob(sg, wn, eid, phase, 
                          deletion_prob=False, 
                          min_logprob=-6,
                          debug_info=None):

    # return prob of deassociating (or of deleting, if deletion_prob=True).
    if (eid, phase) not in wn.arrivals():
        # if this arrival doesn't actually occur during the signal contained at the wn,
        # delete it with probability 1. 
        if deletion_prob:
            return 0.0
        else:
            return -np.inf

    ev_tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
    #unass_lp = unass_template_logprob(sg, wn, ev_tmvals, entropy_score=True)
    #unass_lp_raw = unass_template_logprob(sg, wn, ev_tmvals)
    unass_lp = 0.0
    unass_lp_raw = 0.0

    n_u = len(sg.uatemplate_ids[(wn.sta,wn.chan,wn.band)])
    ntemplates_ratio_log = sg.ntemplates_sta_log_p(wn, n=n_u+1) - sg.ntemplates_sta_log_p(wn, n=n_u)

    deassociation_ratio_log = ntemplates_ratio_log + unass_lp

    
    #signal_lp_with_template = wn.log_p()
    #signal_lp_without_template = wn.log_p(arrivals=arrivals)
    deletion_ratio_log = wn.log_p_delta(eid, phase) #signal_lp_without_template - signal_lp_with_template

    log_normalizer = np.logaddexp(deassociation_ratio_log, deletion_ratio_log)

    # smooth the probabilities so we always give at least some
    # probability to each option (needed in order for reverse proposal
    # probabilities to be reasonable)
    adj = min_logprob + log_normalizer
    deassociation_ratio_log = np.logaddexp(deassociation_ratio_log, adj)
    deletion_ratio_log = np.logaddexp(deletion_ratio_log, adj)
    log_normalizer = np.logaddexp(log_normalizer, np.log(2) + adj)

    sg.logger.debug("deassociation logprob %.2f for %s %d %s, signal delta %.2f unass lp %.2f raw %.2f ntemplates %.2f" % (deassociation_ratio_log - log_normalizer, wn.label, eid, phase, deletion_ratio_log, unass_lp, unass_lp_raw,  ntemplates_ratio_log))

    if deletion_prob:
        return deletion_ratio_log - log_normalizer
    else:
        return deassociation_ratio_log - log_normalizer

def sample_deassociation_proposal(sg, wn, eid, phase, 
                                  fix_result=None, 
                                  propose_map=False,
                                  debug_info=None):
    lp = deassociation_logprob(sg, wn, eid, phase, debug_info=debug_info)
    if fix_result is not None:
        deassociate = fix_result
    elif propose_map:
        deassociate = np.exp(lp) > 0.5
    else:
        u = np.random.rand()
        deassociate = u < np.exp(lp)
    deassociate_lp = lp if deassociate else np.log(1-np.exp(lp))
    return deassociate, deassociate_lp

def correlation_atime_ll(sg, wn, tmvals, eid, phase, prebirth_unexplained):

    (start_idxs, end_idxs, identities, basis_prototypes, level_sizes, n_steps) = wn.wavelet_basis
    tg = sg.template_generator(phase)

    try:
        cssm = wn.arrival_ssms[(eid, phase)]
        wn._set_cssm_priors_from_model(arrivals=[(eid, phase)])
        pred_wavelet = cssm.mean_obs(n_steps)
    except:
        pred_wavelet = np.zeros(n_steps)


    fake_height=False
    if "coda_height" not in tmvals:
        # height shouldn't matter since correlation is scale-invariant
        fake_height = True
        tmvals["coda_height"] = np.log(wn.nm_env.c * 4)

    sg.debug_dists[wn.label]["pred_wavelet"] = pred_wavelet
    env = np.exp(tg.abstract_logenv_raw(tmvals, srate=wn.srate, fixedlen=n_steps))
    pred_signal = pred_wavelet * env
    sg.debug_dists[wn.label]["pred_signal"] = pred_signal
    #ll = ar_advantage(prebirth_unexplained, pred_signal, wn.nm)
    ll = fastxc(pred_signal, prebirth_unexplained) * 10

    if fake_height:
        del tmvals["coda_height"]

    return ll

def get_env_based_amplitude_distribution3(sg, wn, eid, phase, prior_min, prior_max, prior_dist, tmvals, unexplained):

    # propose from a linearly interpolated version of the posterior density,
    # using a very close approximation to the posterior, i.e. we actually
    # run the full signal probability calculations for each candidate amplitude. 


    atime = tmvals['arrival_time']
    ev_offset_idx = int(5*wn.srate)
    start_idx_true = time_to_index(atime, wn.st, wn.srate) - ev_offset_idx
    end_idx_true = int(start_idx_true + 60*wn.srate)
    start_idx = max(0, start_idx_true)
    end_idx = min(wn.npts, end_idx_true)
    start_offset = start_idx - start_idx_true
    end_offset = start_offset + (end_idx - start_idx)
    if end_idx-start_idx < wn.srate:
        # if less than 1s of available signal, don't even bother
        return None

    unexplained_local = unexplained[start_idx:end_idx]
    n = len(unexplained_local)

    env_height = np.max(np.abs(unexplained_local))

    data_min = np.log(env_height) - 2
    data_max = np.log(env_height) + 2
    prior_min = min(prior_min, 1)
    prior_max = max(prior_max, prior_min+1, -2)
    if np.isfinite(data_min):
        min_c = min(data_min, prior_min)
        max_c = max(data_max, prior_max)
        candidates = np.linspace(max(min_c, -5), min(max_c, 5), 20)
        candidates = np.array(sorted(list(candidates) + [np.log(env_height), np.log(env_height+wn.nm_env.c)]))
    else:
        candidates = np.linspace(max(prior_min, -4),  min(prior_max, 5), 20)
        
    provided_coda_height = tmvals['coda_height'] if "coda_height" in tmvals else None
    tg = sg.template_generator("P")
    lps = []

    """
    want to model what happens to the signal between start_idx_true and end_idx_true.
    the event starts at ev_offset_idx.
    the cssm generates signal of len n_steps
    """

    (start_idxs, end_idxs, identities, basis_prototypes, level_sizes, n_steps) = wn.wavelet_basis
    wn._set_cssm_priors_from_model(arrivals=[(eid, phase)])
    cssm = wn.arrival_ssms[(eid, phase)] 
    modeled_npts = end_idx_true-start_idx_true

    d = np.ones((end_idx_true-start_idx_true,))*np.nan
    v = wn.get_value()
    d[start_offset:end_offset] = v[start_idx:end_idx]
    def proxylp(candidate):
        tmvals['coda_height'] = candidate
        l = tg.abstract_logenv_raw(tmvals, srate=wn.srate, fixedlen=end_idx_true-start_idx_true + ev_offset_idx)
        env = np.exp(l)
        components = [(wn.noise_arssm, 0, end_idx_true-start_idx_true, None)]
        components.append((cssm, ev_offset_idx, n_steps, env))
        components.append((wn.iid_arssm, ev_offset_idx+n_steps, len(env) - n_steps, env[n_steps:]))
        tssm = TransientCombinedSSM(components, 1e-6)
        lp = tssm.run_filter(d)
        return lp + prior_dist.log_p(candidate)

    lps = np.array([proxylp(candidate) for candidate in candidates])

    def bad_indices(lps):
        best_idx = np.argmax(lps)
        best_lp = np.max(lps)
        lp_diff = np.abs(np.diff(lps))

        thresh = best_lp - 3
        significant_lps = ( lps[:-1] > thresh ) +  ( lps[1:] > thresh )
        badsteps = significant_lps * (lp_diff > 1)
        bad_idxs = np.arange(len(lps)-1)[badsteps]
        return bad_idxs

    bad_idxs = bad_indices(lps)
    while len(bad_idxs) > 0:
        new_candidates = []
        new_lps = []
        for idx in bad_idxs:
            c1 = candidates[idx]
            c2 = candidates[idx+1]
            c = c1 + (c2-c1)/2.0
            new_candidates.append(c)
            new_lps.append( proxylp(c))
        full_c = np.concatenate((candidates, new_candidates))
        full_lps = np.concatenate((lps, new_lps))
        perm = sorted(np.arange(len(full_c)), key = lambda i : full_c[i])
        candidates = np.array(full_c[perm])
        lps = np.array(full_lps[perm])
        bad_idxs = bad_indices(lps)

    assert( (np.diff(candidates) > 0).all() )

    if provided_coda_height is not None:
        tmvals['coda_height'] = provided_coda_height
    p = PiecewiseLinear(candidates, np.array(lps))

    return p


def smart_peak_time_proposal(sg, wn, tmvals, eid, phase, pred_atime, 
                             prebirth_unexplained=None, 
                             use_correlation=False, 
                             exclude_arrs=[], 
                             fix_result=None):
    # instead of sampling arrival time from the prior, sample
    # from the product of the prior with unexplained signal mass
    ptime = np.exp(tmvals['peak_offset'])
    pidx = int(np.round(ptime * wn.srate))
    discrete_ptime = float(pidx) / wn.srate


    # consider using a vague travel-time prior to
    # acknowldege the possibility that the event is not currently
    # in the correct location
    #tt_spread = np.random.choice((2.0, 10.0, 30.0, 80.0))
    tt_spread = 3.0

    t = np.linspace(wn.st - discrete_ptime, wn.et-discrete_ptime, wn.npts)
    atime_prior = np.exp(-np.abs(t - pred_atime)/tt_spread)
    if use_correlation:
        hard_cutoff = np.abs(t-pred_atime) < 6
    else:
        hard_cutoff = np.abs(t-pred_atime) < 25
    atime_prior *= hard_cutoff
    arrivals = wn.arrivals()

    # naively, env_diff_pos starts at wn.st and gives probabilities of peak times.
    # but we can interpret it as giving probabilities of arrival times, starting
    # at wn.st - discrete_ptime. 
    # this will align better with the atime-based correlation proposal. 
    other_arrivals = [a for a in arrivals if a not in exclude_arrs]
    env_diff_pos = get_env_diff_positive_part(wn, other_arrivals) + wn.nm_env.c

    # control dynamic range of env_diff_pos_distribution: 
    # don't disrupt the prior by more than 3 nats
    max_edp =  np.max(env_diff_pos)
    if max_edp > 3:
        env_diff_pos /= (max_edp/3.0)

    if use_correlation and prebirth_unexplained is not None:
        print "proposal using correlation", use_correlation
        try:
            sg.debug_dists
        except:
            sg.debug_dists = {}
        sg.debug_dists[wn.label] = {}


        sg.debug_dists[wn.label]["prior"] = atime_prior.copy()
        sg.debug_dists[wn.label]["env_diff_pos"] = env_diff_pos
        pred_env = wn.assem_env(arrivals=other_arrivals)
        env = wn.get_env().data
        ed = env - pred_env
        sg.debug_dists[wn.label]["env_diff"] = ed


        pbu = prebirth_unexplained[wn.label]
        sg.debug_dists[wn.label]["unexplained"] = pbu.copy()
        #try:
        atime_ll = correlation_atime_ll(sg, wn, tmvals, eid, phase, pbu)
        #except KeyError:
        # if the wn does not have an arrival from this eid, phase,
        # then we can't do a data-driven propsal
        #    atime_ll = np.zeros(env_diff_pos.shape)

        maxll = np.max(atime_ll)
        # temper atime_ll to have dynamic range of 10 nats, so it doesn't overwhelm the prior
        if maxll > 10:
            atime_ll /= maxll/10.0
            maxll = 10
        sg.debug_dists[wn.label]["atime_ll"] = atime_ll

        sidx = pidx
        eidx = len(atime_ll) 
        atime_prior[sidx:eidx] *= np.exp((atime_ll[:-pidx] if pidx > 0 else atime_ll) - maxll)
        atime_prior[:sidx] *= np.exp(-maxll)
        atime_prior[eidx:] *= np.exp(-maxll)

        atime_pdf = merge_distribution(env_diff_pos, atime_prior, smoothing=3, return_pdf=True, peak_detect=False)
        sg.debug_dists[wn.label]["final"] = atime_pdf
    else:
        atime_pdf = merge_distribution(env_diff_pos, atime_prior, smoothing=3, return_pdf=True)

    atime_cdf = preprocess_signal_for_sampling(atime_pdf)


    if not fix_result:

        if np.sum(atime_prior)==0:
            # if the window doesn't contain signal near the predicted arrival time,
            # we can't do a data-driven proposal, so just sample from (something like)
            # the prior
            atime_dist = Laplacian(pred_atime, tt_spread)
            proposed_atime = atime_dist.sample()
            atime_lp = atime_dist.log_p(proposed_atime)
        else:
            proposed_atime, atime_lp = sample_peak_time_from_cdf(atime_cdf, wn.st-discrete_ptime, wn.srate, return_lp=True)

        proposed_tt_residual = proposed_atime - pred_atime

        tmvals["tt_residual"] = proposed_tt_residual
        tmvals["arrival_time"] = proposed_atime

        assert(not np.isnan(atime_lp))
        return atime_lp
    else:
        atime = tmvals["arrival_time"] 
        if np.sum(atime_prior)==0:
            atime_dist = Laplacian(pred_atime, tt_spread)
            atime_lp = atime_dist.log_p(atime)
        else:
            atime_lp = peak_log_p(atime_cdf, wn.st-discrete_ptime, wn.srate, atime)
            #idx = int(np.floor((atime - (wn.st-discrete_ptime)) * wn.srate +.00001)) + 1
            #print "atime idx", idx, "lp",  np.log(atime_cdf[idx] - atime_cdf[idx-1])

        #print "atime_lp is", atime_lp, "for", atime
        assert(not np.isnan(atime_lp))
        return atime_lp


def heuristic_amplitude_posterior(sg, wn, tmvals, eid, phase, debug=False, exclude_arrs = [], unexplained=None, full_tssm_proposal=False):
    """
    Construct an amplitude proposal distribution by combining the env likelihood with
    the prior conditioned on the event location.

    This is especially necessary when proposing phases that don't appear to be
    present in the signal (i.e., are below the noise floor). If the prior predicts
    a log-amplitude of -28, and the likelihood predicts a log-amplitude of -4 (because
    it's impossible for the likelihood to distinguish amplitudes below the noise floor), then
    proposals from the likelihood alone would ultimately be rejected.

    """


    k_ampt = create_key("amp_transfer", eid=eid, sta=wn.sta, chan=":", band=":", phase=phase)
    try:
        n_ampt = sg.all_nodes[k_ampt]
    except:
        import pdb; pdb.set_trace()

    ev = sg.get_event(eid)
    source_amp = brune.source_logamp(ev.mb, phase=phase, band=wn.band)

    if n_ampt.model is not None:
        prior_mean = float(n_ampt.model.predict(cond=n_ampt._parent_values())) + source_amp
        prior_var = float(n_ampt.model.variance(cond=n_ampt._parent_values(), include_obs=True))
    else:
        cd = n_ampt.joint_conditional_dist()
        prior_mean = float(cd.predict()) + source_amp
        prior_var = float(cd.variance())
        
    prior_std = np.sqrt(prior_var)
    prior_dist = Gaussian(prior_mean, prior_std)

    prior_min = prior_mean - 3*prior_std
    prior_max = prior_mean + 3*prior_std

    if full_tssm_proposal:
        amp_dist_env = get_env_based_amplitude_distribution3(sg, wn, eid, phase,
                                                             prior_min=prior_min, 
                                                             prior_max=prior_max, 
                                                             prior_dist=prior_dist, 
                                                             tmvals=tmvals, 
                                                             unexplained=unexplained[wn.label])
    else:
        amp_dist_env = get_env_based_amplitude_distribution2(sg, wn, 
                                                             prior_min=prior_min, 
                                                             prior_max=prior_max, 
                                                             prior_dist=prior_dist, 
                                                             tmvals=tmvals, 
                                                             exclude_arrs=exclude_arrs)
    if amp_dist_env is None:
        return prior_dist

    return amp_dist_env


def heuristic_amplitude_posterior_old(sg, wn, tmvals, eid, phase, debug=False):
    """
    Construct an amplitude proposal distribution by combining the env likelihood with
    the prior conditioned on the event location.

    This is especially necessary when proposing phases that don't appear to be
    present in the signal (i.e., are below the noise floor). If the prior predicts
    a log-amplitude of -28, and the likelihood predicts a log-amplitude of -4 (because
    it's impossible for the likelihood to distinguish amplitudes below the noise floor), then
    proposals from the likelihood alone would ultimately be rejected.

    """

    amp_dist_env = get_env_based_amplitude_distribution(sg, wn, tmvals, exclude_arr=(eid, phase))

    k_ampt = create_key("amp_transfer", eid=eid, sta=wn.sta, chan=":", band=":", phase=phase)
    try:
        n_ampt = sg.all_nodes[k_ampt]
    except:
        import pdb; pdb.set_trace()

    ev = sg.get_event(eid)
    source_amp = brune.source_logamp(ev.mb, phase=phase, band=wn.band)

    prior_mean = float(n_ampt.model.predict(cond=n_ampt._parent_values())) + source_amp
    prior_var = float(n_ampt.model.variance(cond=n_ampt._parent_values(), include_obs=True))
    prior_dist = Gaussian(prior_mean, np.sqrt(prior_var))

    if debug:
        import pdb; pdb.set_trace()

    if amp_dist_env is None:
        return prior_dist

    if amp_dist_env.mean < np.log(wn.nm_env.c):
        # the Gaussian model of log-amplitude isn't very good at the noise floor
        # (it should really be a model of non-log amplitude, since noise is additive).
        # so we hack in some special cases:
        # TODO: find a better solution here.

        if prior_mean < amp_dist_env.mean:
            # if the prior thinks the env needs to be *really* small, vs just kind of small,
            # we believe the prior. Since we're proposing below the noise floor, our proposal
            # won't affect env probabilities anyway, so we should just maximize probability
            # under the prior.
            heuristic_posterior = prior_dist
        #elif prior_mean > np.log(wn.nm_env.c) + 2:
            # if the prior thinks there *should* be a visible arrival
            # here, but that's not supported by the env, we propose
            # to fit the env (paying the cost under the prior) since
            # this is almost certainly cheaper than believing the prior
            # at the cost of not fitting the env.
        else:
            #heuristic_posterior = amp_dist_env
            heuristic_posterior = Gaussian(-5, 1.0)
        #else:
        #    heuristic_posterior = amp_dist_env.product(prior_dist)
    else:
        # otherwise, combine the likelihood and prior for a heuristic posterior
        heuristic_posterior = amp_dist_env.product(prior_dist)
    #heuristic_posterior = Gaussian(-2.0, 0.5)


    #nstd = np.sqrt(wn.nm_env.marginal_variance())


    return heuristic_posterior


def clean_propose_phase_template(sg, wn, eid, phase, 
                                 fix_result=None, 
                                 debug_info=None,
                                 use_correlation=False,
                                 prebirth_unexplained=None,
                                 ev=None):
    # add the given phase to the graph, with appropriate proposal values (or fix_result)
    # return the tmvals and stuff
    if ev is None:
        ev = sg.get_event(eid)
        

    # add the template
    
    #sg._topo_sort()
    
    # sample most of the template params from the event-conditional prior
    tmnodes = sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
    k_ttr, n_ttr = tmnodes["tt_residual"]
    k_time, n_time = tmnodes["arrival_time"]
    k_amp, n_amp = tmnodes["amp_transfer"]
    k_height, n_height = tmnodes["coda_height"]
    tmvals = {}
    log_q = 0.0
    for param, (k, n) in tmnodes.items():
        if param in ("tt_residual", "amp_transfer") or n.deterministic():
            continue

        try:
            if fix_result is not None:
                if param in fix_result:
                    n.set_value(fix_result[param])
                else:
                    set_value_proxy(param, fix_result, tmnodes)
            else:
                n.parent_sample()

            param_lp = n.log_p()

        except ParentConditionalNotDefined:
            proposal_dist = n.joint_conditional_dist()
            if fix_result is not None:
                if param in fix_result:
                    n.set_value(fix_result[param])
                else:
                    set_value_proxy(param, fix_result, tmnodes)
            else:
                n.set_value(proposal_dist.sample())

            param_lp = proposal_dist.log_p(n.get_value())

        log_q += param_lp
        
        tmvals[param] = n.get_value()
        if debug_info is not None:
            debug_info[param] = (tmvals[param], param_lp, param_lp)
        sg.logger.debug( "param %s val %f lp %f" % (param, tmvals[param], param_lp))

    #if "arrival_time" not in tmvals:
    #    tmvals["arrival_time"] = tmnodes["arrival_time"][1].get_value()
 
    # then sample atime from the signal
    pred_atime = ev.time + tt_predict(ev, wn.sta, phase)
    debug_lps = {}
    if fix_result is not None:
        tmvals["arrival_time"] = fix_result["arrival_time"]
    peak_lp = smart_peak_time_proposal(sg, wn, tmvals, eid, phase,
                                       pred_atime,
                                       use_correlation=use_correlation,
                                       prebirth_unexplained=prebirth_unexplained,
                                       exclude_arrs=[],
                                       fix_result=(fix_result is not None))
    n_time.set_value(key=k_time, value = tmvals["arrival_time"])
    log_q += peak_lp
    if debug_info is not None:
        debug_info["tt_residual"] = (n_ttr.get_value(), peak_lp, n_ttr.log_p())
    #print "param atime val", tmvals["arrival_time"], "lp", peak_lp

    # then sample amplitude from the signal
    amp_dist = heuristic_amplitude_posterior(sg, wn, tmvals, eid, phase, 
                                             exclude_arrs=[(eid, phase)], 
                                             unexplained = prebirth_unexplained, 
                                             full_tssm_proposal=use_correlation)
    if fix_result is not None:
        tmvals["coda_height"] = fix_result["coda_height"]
    else:
        tmvals["coda_height"] = amp_dist.sample()
    n_height.set_value(key=k_height, value=tmvals["coda_height"])
    amp_lp = amp_dist.log_p(tmvals["coda_height"])
    amp_lp = max(amp_lp, -200) # avoid -inf
    log_q += amp_lp
    tmvals["amp_transfer"] = n_amp.get_value(key=k_amp)
    if debug_info is not None:
        debug_info["amp_transfer"] = (n_amp.get_value(), amp_lp, n_amp.log_p())
    #print "param atransfer val", tmvals["amp_transfer"], "lp", amp_lp

    if not np.isfinite(log_q):
        import pdb; pdb.set_trace()
    
    return tmvals, log_q

#########################################################################################

def death_proposal_log_ratio(sg, eid):
    lp_unass = 0
    lp_ev = 0

    ev = sg.get_event(eid)
    eid = ev.eid

    for (site, elements) in sg.site_elements.items():
        for sta in elements:
            for wn in sg.station_waves[sta]:
                for phase in sg.ev_arriving_phases(eid, sta):
                    tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)

                    lp_unass_tmpl = unass_template_logprob(sg, wn, tmvals)
                    lp_ev_tmpl = ev_phase_template_logprob(sg, wn, eid, phase, tmvals)
                    #print "ev tmpl prob", sta, phase, eid, lp_ev_tmpl

                    lp_unass += lp_unass_tmpl
                    lp_ev += lp_ev_tmpl
    r = lp_unass - lp_ev
    #assert(np.isfinite(r))
    return r

def death_proposal_distribution(sg):
    c = Counter()
    for eid in sg.evnodes.keys():
        if eid in sg.fixed_events: continue
        c[eid] = death_proposal_log_ratio(sg, eid)

    c.normalize_from_logs()


    # with probability ~.5, just sample an event uniformly.
    # this way all events have some possibility to die.
    for k in c.keys():
        if np.isfinite(c[k]):
            c[k] += .5/len(c)
        else:
            c[k] = .5/len(c)
    c.normalize()

    return c

def sample_death_proposal(sg, fix_result=None, debug_info=None):
    c = death_proposal_distribution(sg)
    if len(c) == 0:
        eid = None
        lp = 0.0
    else:
        if fix_result is not None:
            eid = fix_result
        else:
            eid = c.sample()

        lp = np.log(c[eid])

    debug_info["death_proposal_lp"] = lp

    if fix_result:
        return lp
    else:
        return eid, lp

def ev_death_executor(sg, location_proposal, 
                      proposal_includes_mb=True,
                      use_correlation=False,
                      repropose_uatemplates=False,
                      birth_type="mh",
                      inference_step=-1,
                      force_kill_eid=None,
                      propose_map=False):

    log_qforward = 0.0
    log_qbackward = 0.0
    
        
    debug_info = {}

    if force_kill_eid is None:
        eid, lq_death = sample_death_proposal(sg, debug_info=debug_info)
    else:
        eid = force_kill_eid
        lq_death = 0

    if eid is None:
        return None

    log_qforward += lq_death

    lp_old = sg.current_log_p()

    """
    s1 = sg.current_log_p_breakdown(silent=True)
    evs1 = [sg.get_event(eid1) for eid1 in sg.evnodes.keys()]
    vals1 = [(n.label, n.get_value(), n.log_p()) for n in sg.extended_evnodes[eid] if n.single_key is not None and not n.deterministic()]
    """

    lqf, replicate_untmpls, death_records = ev_template_death_helper(sg, eid, 
                                                                     repropose_uatemplates=repropose_uatemplates,
                                                                     propose_map=propose_map,
                                                                     debug_info=debug_info)
    log_qforward += lqf

    # this is a little inelegant 
    replicate_death, ev = ev_bare_death_move(sg, eid)
    sg._topo_sort()


    if sg.dump_proposal_debug_dir is not None:
        dump_path = os.path.join(sg.dump_proposal_debug_dir, "ev_%05d" % eid, "death_proposal_%d" % inference_step)
        mkdir_p(dump_path)
        if not os.path.exists(os.path.join(dump_path, "pickle.sg")):
            sg.debug_dump(dump_path = dump_path, pickle_only=True)

    lp_new = sg.current_log_p()
        
    if force_kill_eid is None:
        n_current_events = len(sg.evnodes) - len(sg.fixed_events)
        log_qbackward += -np.log(n_current_events + 1)
    lq_loc, replicate_birth, eid, extra = ev_bare_birth_move(sg, location_proposal, 
                                                             fix_result=(ev, eid),
                                                             debug_info=debug_info)

    log_qbackward += lq_loc

    lqb, replicate_tmpls, birth_records = \
            ev_template_birth_helper(sg, eid, 
                                     associate_using_mb=proposal_includes_mb, 
                                     fix_result=death_records, 
                                     use_correlation=use_correlation,
                                     repropose_uatemplates=repropose_uatemplates,
                                     debug_info=debug_info,
                                     proposal_type=birth_type)
    log_qbackward += lqb

    sg._topo_sort()
                        
    #lp_old2 = sg.current_log_p()
    #s2 = sg.current_log_p_breakdown(silent=True)
    #evs1 = [sg.get_event(eid) for eid in sg.evnodes.keys()]
    #vals2 = [(n.label, n.get_value(), n.log_p()) for n in sg.extended_evnodes[eid] if n.single_key is not None and not n.deterministic()]
    #assert(np.abs(lp_old2 - lp_old) < 1e-6)
    
    def rebirth():
        replicate_birth()
        replicate_tmpls()
        sg._topo_sort()
        
    def redeath():
        replicate_untmpls() # maybe not technically necessary
        replicate_death()
        sg._topo_sort()

    proposal_extra = (extra, eid, ev, debug_info)

    return lp_new, lp_old, log_qforward, log_qbackward, redeath, rebirth, proposal_extra

def ev_death_move_abstract(sg, location_proposal, log_to_run_dir=None, 
                           accept_action=None,
                           revert_action=None,
                           force_outcome=None, **kwargs):

    #n_current_events = len(sg.evnodes) - len(sg.fixed_events)
    #reverse_logprob = -np.log(n_current_events) # this accounts for the different "positions" we can birth an event into

    r = ev_death_executor(sg, location_proposal, **kwargs)
    if r is None:
        return False
    lp_new, lp_old, log_qforward, log_qbackward, redeath, rebirth, proposal_extra = r

    sg.logger.info( "death move acceptance %f from old %f new %f lqb %f lqf %f" %( (lp_new + log_qbackward) - (lp_old+log_qforward), lp_old, lp_new, log_qbackward, log_qforward) )

    def revert():
        if revert_action is not None:
            revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    def accept():
        redeath()
        if accept_action is not None:
            accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    accepted =  mh_accept_util(lp_old, lp_new, log_qforward, log_qbackward, accept_move=accept, revert_move=revert, force_outcome=force_outcome)
    return accepted

def ev_death_move_hough(sg, hough_kwargs={}, log_to_run_dir=None,  
                        inference_step=-1, **kwargs):

    def hlp(sg, fix_result=None, **kwargs):
        kwargs.update(hough_kwargs)
        return hough_location_proposal(sg, fix_result=fix_result, **kwargs)


    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        if log_to_run_dir is None:
            return
        
        hough_array, eid, proposed_ev, debug_info = proposal_extra
        log_file = os.path.join(log_to_run_dir, "hough_deaths.txt")

        logdir = os.path.join(log_to_run_dir, "ev_%05d" % eid)
        ev_log_file = os.path.join(logdir, "death_proposal_%d.txt" % inference_step)
        mkdir_p(logdir)
        with open(ev_log_file, 'w') as f:
            f.write(prettyprint_debug(debug_info))

        with open(log_file, 'a') as f:
            f.write("proposing to kill eid %d: %s\n" % (eid, proposed_ev))
            f.write("acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            """
            for (wn, phase), (assoc, tmvals) in associations.items():
                if assoc:
                    f.write(" associated %s at %s, %s, %s\n" % (phase, wn.sta, wn.chan, wn.band))
            """

            f.write("\n")


    return ev_death_move_abstract(sg, hlp, proposal_includes_mb=True, 
                                  accept_action=log_action, 
                                  revert_action=log_action, 
                                  inference_step=inference_step,
                                  **kwargs)


def ev_death_move_hough_meta(sg, **kwargs):
    hough_kwargs = sample_hough_kwargs(sg)
    proposal_type = np.random.choice(("mh", "mh", "dumb", ))
    repropose_uatemplates = False

    return ev_death_move_hough(sg, hough_kwargs=hough_kwargs, 
                               repropose_uatemplates=repropose_uatemplates,
                               birth_type = proposal_type, **kwargs)

def ev_death_move_hough_dumb(sg, **kwargs):
    hough_kwargs = {"one_event_semantics": False}
    return ev_death_move_hough(sg, hough_kwargs=hough_kwargs, birth_type="dumb", **kwargs)

def ev_death_move_correlation(sg, corr_kwargs={}, log_to_run_dir=None, inference_step=-1, **kwargs):

    def clp(sg, fix_result=None, **kwargs):
        kwargs.update(corr_kwargs)
        return correlation_location_proposal(sg, fix_result=fix_result, **kwargs)


    repropose_uatemplates = np.random.rand() < 0.5

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        if log_to_run_dir is None:
            return

        _, eid, proposed_ev, debug_info = proposal_extra
        log_file = os.path.join(log_to_run_dir, "corr_deaths.txt")

        # proposed event should be the most recently created
        if eid is None:
            eid = np.max(sg.evnodes.keys())
        
        with open(log_file, 'a') as f:
            f.write("proposing to kill eid %d: %s\n" % (eid, proposed_ev))
            f.write("kwargs %s repropose uatemplates %s\n" % (kwargs, repropose_uatemplates))
            f.write("acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            #for (wn, phase), (assoc, tmvals) in associations.items():
            #    if assoc:
            #        f.write(" associated %s at %s, %s, %s\n" % (phase, wn.sta, wn.chan, wn.band))
            f.write("\n")

        logdir = os.path.join(log_to_run_dir, "ev_%05d" % eid)
        ev_log_file = os.path.join(logdir, "death_proposal_%d.txt" % inference_step)
        mkdir_p(logdir)
        with open(ev_log_file, 'w') as f:
            f.write(prettyprint_debug(debug_info))

    return ev_death_move_abstract(sg, clp, proposal_includes_mb=False, 
                                  use_correlation=repropose_uatemplates, 
                                  accept_action=log_action, 
                                  revert_action=log_action,
                                  inference_step=inference_step,
                                  repropose_uatemplates=repropose_uatemplates, **kwargs)

def ev_death_move_correlation_random_sta(sg, **kwargs):
    #corr_kwargs = sample_corr_kwargs(sg)
    #proposal_type = np.random.choice(("mh", "mh", "dumb"))
    #return ev_death_move_correlation(sg, corr_kwargs=corr_kwargs, 
    #                                 birth_type=proposal_type, **kwargs)

    # any death move that reproposes uatemplates is basically an auto-fail, so 
    # don't bother actually running it
    return False

def ev_death_move_cheating(sg, **kwargs):
    return ev_death_move_abstract(sg, cheating_location_proposal, proposal_includes_mb=True, **kwargs)


def ev_death_move_lstsqr(sg, **kwargs):
    return ev_death_move_abstract(sg, overpropose_new_locations, **kwargs)

##########################################################################################

def ev_death_dist(sg):
    log_qforward = -np.log(len(sg.evnodes.keys()))
    
def ev_bare_death_move(sg, eid):
    
    def replicate_move():
        sg.remove_event(eid)
    
    ev = sg.get_event(eid)
    replicate_move()
    return replicate_move, ev

def ev_sta_template_death_helper(sg, wn, eid, 
                                 phases=None,
                                 repropose_uatemplates=False,
                                 fix_result=None,
                                 propose_map=False,
                                 debug_info=None):

    def perturb_uatemplate(sg, wn, tmid, fix_result=None):
        # when deassociating, we optionally perturb the parameters of the
        # newly created uatemplate, so that the uatemplate might not perfectly 
        # match the event template. this is to allow for birth moves that
        # co-opt existing uatemplates but repropose their parameters.
        param_stds = {"arrival_time": 4.0, "coda_height": 1.0, 
                      "coda_decay": 1.0, "peak_decay": 1.0, "peak_offset": 1.0
        }

        tmnodes = sg.get_template_nodes(-tmid, wn.sta, "UA", wn.band, wn.chan)
        lqf = 0.0
        replicate_fns = []
        for (p, (k, n)) in tmnodes.iteritems():
            current_val = n.get_value(k)
            if p == "mult_wiggle_std":
                proposal_dist = TruncatedGaussian(current_val, 0.15, a=0.0, b=1.0)
            else:
                proposal_dist = Gaussian(current_val, param_stds[p])

            if fix_result is None:
                proposed_val = proposal_dist.sample()
            else:
                proposed_val = fix_result[p]
            lqf += proposal_dist.log_p(proposed_val)
            
            # access the node by its label so that the move is replicatable
            f = lambda label=n.label, k=k, proposed_val=proposed_val: \
                        sg.all_nodes[label].set_value(proposed_val, key=k)
            f()
            replicate_fns.append(f)

        return lqf, replicate_fns
        


    death_record = {}
    
    s = Sigvisa()
    site = s.get_array_site(wn.sta)
    sta = wn.sta
    replicate_fns = []
    assoc_tmids = {}
    log_qforward = 0.0
    if phases is None:
        phases = sg.ev_arriving_phases(eid, sta)

    for phase in phases:
        if fix_result is not None:
            deassociate, tmid, fixed_tmvals = fix_result[phase]
        else:
            deassociate = None
            tmid = None
            fixed_tmvals = None
        deassociate, deassociate_logprob = sample_deassociation_proposal(sg, wn, eid, phase, 
                                                                         fix_result = deassociate,
                                                                         propose_map = propose_map,
                                                                         debug_info=debug_info)
        if debug_info is not None:
            if phase not in debug_info:
                debug_info[phase] = {}
            debug_info[phase]["deassociate"] = deassociate_logprob

        log_qforward += deassociate_logprob


        template_param_array = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
        if deassociate:
            tmid = unassociate_template(sg, wn, eid, phase, tmid=tmid, 
                                        remove_event_phase=True)
            replicate_fns.append(lambda wn=wn,phase=phase,eid=eid,tmid=tmid: \
                                 unassociate_template(sg, wn, eid, phase, tmid=tmid, 
                                                      remove_event_phase=True))
            sg.logger.debug("proposing to deassociate %s at %s (lp %.1f)" % (phase, sta, deassociate_logprob))
            assoc_tmids[phase] = tmid

            if repropose_uatemplates:
                death_record[phase] = template_param_array
                lqf, rfns = perturb_uatemplate(sg, wn, tmid, fix_result=fixed_tmvals)

                if debug_info is not None:
                    debug_info[phase]["repropose_lp"] = lqf
                
                replicate_fns.extend(rfns)
                log_qforward += lqf

        else:
            death_record[phase] = template_param_array
            sg.delete_event_phase(eid, site, phase, re_sort=False)
            replicate_fns.append(lambda eid=eid, site=site, phase=phase: sg.delete_event_phase(eid, site, phase))
            sg.logger.debug( "proposing to delete %s at %s (lp %f)"% (phase, sta, deassociate_logprob))
    sorted_tmids = [assoc_tmids[phase] if phase in assoc_tmids else None for phase in sorted(phases)]
    death_record["assoc_tmids"] = tuple(sorted_tmids)

    def replicate_move():
        for fn in replicate_fns:
            fn()
    
    return log_qforward, replicate_move, death_record

def ev_template_death_helper(sg, eid, 
                             repropose_uatemplates=False, 
                             fix_result=None,
                             propose_map=False,
                             debug_info=None):
    birth_records = {}
    replicate_fns = []
    log_qforward = 0.0
    for site,elements in sg.site_elements.items():
        phases = sg.ev_arriving_phases(eid, site=site)
        birth_records["%s_phases" % site] = phases
        for sta in elements:

            debug_info_sta = None
            if debug_info is not None:
                if sta not in debug_info:
                    debug_info[sta] = dict()
                debug_info_sta = debug_info[sta]

            for wn in sg.station_waves[sta]:
                fr_sta = None
                if fix_result is not None:
                    fr_sta = fix_result[wn.label]                
                lqf_sta, replicate_sta, birth_sta = ev_sta_template_death_helper(sg, wn, eid, 
                                                                                 fix_result=fr_sta, 
                                                                                 repropose_uatemplates=repropose_uatemplates,
                                                                                 propose_map=propose_map,
                                                                                 debug_info=debug_info_sta)
                replicate_fns.append(replicate_sta)
                log_qforward += lqf_sta
                birth_records[wn.label] = birth_sta

    def replicate_move():
        for fn in replicate_fns:
            fn()
            
    return log_qforward, replicate_move, birth_records


def ev_bare_birth_move(sg, location_proposal, 
                       debug_info=None,
                       eid=None,
                       fix_result=None):
    if fix_result is not None:
        ev, eid = fix_result
        extra = None
        log_qforward = location_proposal(sg, fix_result=ev)
    else:
        ev, log_qforward, extra = location_proposal(sg)
        if ev is None:
            return None, None, None, None
        
    evnodes = sg.add_event(ev, eid=eid, phases=None)
    eid = evnodes["loc"].eid
    
    if debug_info is not None:
        evnodes = set(sg.evnodes[eid].values())
        evlps = [(n.label.split(";")[1], n.log_p()) for n in evnodes]
        evlps += [('nevents', np.log(sg.event_rate))]
        debug_info["ev"] = (ev, log_qforward, evlps)
    
    def replicate_move():
        sg.add_event(ev, eid=eid, phases=None)
        
    return log_qforward, replicate_move, eid, extra


def propose_tmvals_from_gibbs_scan(sg, wn, eid, phase, fix_result=None, debug_info=None):
    tmnodes = sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
    logq = 0.0
    tmvals = {}
    params = ("peak_offset", "tt_residual", "amp_transfer", "peak_decay", "coda_decay", "mult_wiggle_std")
    for param in params:
        try:
            (k, n) = tmnodes[param]
        except:
            continue

        proxylp = proxylp_full(sg, wn, n)
        d = approximate_scalar_gibbs_distribution(sg, wn, eid, 
                                                  phase, param, 
                                                  n, proxylp, 
                                                  prior_weight = 0.01)
        
        if fix_result is not None:
            v = fix_result[param]
        else:
            v = d.sample()
        n.set_value(v)
        logq_param = d.log_p(v)
        logq += logq_param
        
        if debug_info is not None:
            debug_info[param] = (v, logq_param, n.log_p())
        
        tmvals[param] = v
        # print phase, param, v, logq_param, d.sample(), d.sample(), d.sample()
        
    return logq, tmvals

def propose_associations(sg, wn, eid, site_phases, fix_result=None, 
                         debug_info=None, atime_only=False, associate_using_mb=True):

    """
    Sample a joint association of all phases at this station,
    and update the graph to reflect the new association.
    """

    # ensure the phase list is sorted so that it matches up with assoc_tmids
    site_phases = sorted(site_phases)

    log_qforward = 0    
    band, chan = wn.band, wn.chan
    jd = joint_association_distribution(sg, wn, eid=eid, phases=site_phases, 
                                        atime_only=atime_only,
                                        associate_using_mb=associate_using_mb)
    if fix_result is None:
        assoc_tmids = jd.sample()
        assoc_lp = np.log(jd[assoc_tmids])
    else:
        assoc_tmids = fix_result["assoc_tmids"]

        impossible_lp = max( -30, np.log(np.min(jd.values())) - 5 ) #-np.inf
        assoc_lp = np.log(jd[assoc_tmids]) if assoc_tmids in jd else impossible_lp
    sg.logger.debug( "%s: using assoc %s with lp %f (dist %s)" % ( wn.label, zip(site_phases, assoc_tmids), assoc_lp, jd) )
    log_qforward += assoc_lp
    
    if debug_info is not None:
        debug_info["assoc"] = (zip(site_phases, assoc_tmids), assoc_lp, 0.0)

    replicate_fns = []
    birth_record = {}
    for i_phase, phase in enumerate(site_phases):
        debug_phase = None
        if debug_info is not None:
            if phase not in debug_info:
                debug_info[phase] = {}
            debug_phase = debug_info[phase]
            
        assoc_tmid = assoc_tmids[i_phase]
        birth_record[(phase)] = (assoc_tmid is not None, assoc_tmid, None)

        if assoc_tmid is not None:
            if debug_phase is not None:
                tmnodes = sg.get_template_nodes(-assoc_tmid, wn.sta, "UA", wn.band, wn.chan)
                ualps = dict([(param, n.log_p()) for (param, (k,n)) in tmnodes.items()])
                    
            associate_template(sg, wn, assoc_tmid, eid, phase, create_phase_arrival=True)
            replicate_fns.append(lambda sg=sg,wn=wn,phase=phase,eid=eid,tmid=assoc_tmid: \
                                  associate_template(sg, wn, tmid, eid, phase, create_phase_arrival=True))
            
            if debug_phase is not None:
                tmnodes = sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
                for (param, (k, n)) in tmnodes.items():
                    if n.deterministic(): continue
                    evlp = n.log_p()
                    uaparam = param
                    if param == "amp_transfer":
                        uaparam = "coda_height"
                    elif param == "tt_residual":
                        uaparam = "arrival_time"
                    ualp = ualps[uaparam]
                    if uaparam=="arrival_time":
                        ualp = np.log(sg.uatemplate_rate)
                    v = n.get_value(key=k)
                    debug_phase[param] = (v, ualp, evlp)

    return log_qforward, replicate_fns, assoc_tmids, birth_record

def create_dummy_mh_world(sg, wn, eid):
    # create a dummy sigvisa_graph and wave node containing (only) the signal 
    # relevant to a particular event. this is an optimization to avoid expensive
    # signal-probability calculations over (say) an entire hour of signal, when
    # in fact the event we're interested in only explains a small amount of that 
    # signal. 


    dummy_sg = SigvisaGraph(template_model_type=sg.template_model_type, 
                            template_shape=sg.template_shape,
                            #wiggle_model_type=sg.wiggle_model_type, 
                            wiggle_model_type="dummy", 
                            wiggle_family=sg.wiggle_family, 
                            skip_levels=sg.skip_levels,
                            dummy_fallback=sg.dummy_fallback,
                            runids = sg.runids,
                            phases=sg.phases, 
                            base_srate=sg.base_srate,
                            smoothing=sg.smoothing,
                            arrays_joint=sg.arrays_joint, 
                            gpmodel_build_trees=sg.gpmodel_build_trees,
                            hack_param_constraint=sg.hack_param_constraint,
                            uatemplate_rate=sg.uatemplate_rate,
                            fixed_arrival_npts=sg.fixed_arrival_npts,
                            dummy_prior=sg.dummy_prior,
                            raw_signals=sg.raw_signals, 
                            jointgp_hparam_prior=sg.jointgp_hparam_prior,
                            jointgp_param_run_init=sg.jointgp_param_run_init,
                            force_event_wn_matching=False,
                            hack_coarse_tts=sg.hack_coarse_tts,
                            hack_coarse_signal=sg.hack_coarse_signal,
                            hack_ttr_max=sg.hack_ttr_max,
                            phase_existence_model=sg.phase_existence_model,
                            min_mb = sg.min_mb,
                            inference_region=sg.inference_region)
    
    # find a window of time containing all the arriving phases of this event
    phases = sg.ev_arriving_phases(eid, sta=wn.sta)
    arrivals = wn.arrivals()
    sidx, eidx = None, None
    for phase in phases:

        if (eid, phase) not in arrivals: continue

        phase_sidx, phase_eidx = wn.template_idx_window(eid=eid, phase=phase, 
                                                        pre_arrival_slack_s=10.0)
        #phase_eidx = min(phase_eidx, int(phase_sidx + 180.0*wn.srate))

        if sidx is None:
            sidx, eidx = phase_sidx, phase_eidx
        else:
            sidx, eidx = unify_windows((phase_sidx, phase_eidx), (sidx, eidx))

    if sidx is None or (eidx - sidx) <= 0:
        return sg, wn, []
    
    # extract the signal data for this time period
    truncated_data = wn.get_value()[sidx:eidx].copy()
    dummy_stime = index_to_time(sidx, wn.st, wn.srate)
    dummy_etime = index_to_time(eidx, wn.st, wn.srate)
    dummy_wave = Waveform(truncated_data, srate=wn.srate, stime=dummy_stime, sta=wn.sta, filter_str=wn.filter_str, chan=wn.chan, band=wn.band)
    dummy_wn = dummy_sg.add_wave(dummy_wave)
    dummy_wn.nm_node.set_value(wn.nm)
    #dummy_wn.nm_env = wn.nm_env
    dummy_wn.wavelet_param_models=wn.wavelet_param_models

    #print "dummy stime %.1f etime %.1f len %.1f" % (dummy_stime, dummy_etime, dummy_etime-dummy_stime)

    # add the event and set all its phases to match their current values in the original sg
    ev = sg.get_event(eid)
    site = Sigvisa().get_array_site(wn.sta)
    evnodes = dummy_sg.add_event(ev, phases={site: phases}, eid=eid)
    all_dummy_tmnodes = []
    for phase in phases:
        tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
        dummy_tmnodes = dummy_sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
        for param, val in tmvals.items():
            k,n = dummy_tmnodes[param]
            n.set_value(val, key=k)
        all_dummy_tmnodes.append((phase, dummy_tmnodes))

    # also add any other templates that overlap with this event.
    # if they are templates from other events, we convert them
    # to uatemplates since the parameters are fixed anyway, and
    # this saves GP calculations that hopefully don't matter too much.
    for (eid2, phase) in wn.arrivals():
        if eid2 == eid: continue

        tmvals, _ = wn.get_template_params_for_arrival(eid2, phase)
        phase_sidx, phase_eidx = wn.template_idx_window(eid=eid2, phase=phase, 
                                                        pre_arrival_slack_s=0.0,
                                                        post_fade_slack_s=0.0)
        if phase_eidx > sidx and phase_sidx < eidx:
            dummy_sg.create_unassociated_template(dummy_wn, tmvals["arrival_time"], initial_vals=tmvals, nosort=True)
            #print "adding overlapping phase", eid2, phase
    dummy_sg._topo_sort()
        

    return dummy_sg, dummy_wn, all_dummy_tmnodes

def propose_new_phases_mh(sg, wn, eid, 
                          new_phases, 
                          use_correlation=False,
                          prebirth_unexplained=None,
                          mh_steps=None,
                          fix_result=None,
                          debug_info=None):

    log_qforward = 0
    replicate_fns = []

    # first create the new templates, and initialize to proposed values
    # (but don't bother recording the proposal probabilities since these
    # are only intermediate/auxiliary variables)
    site = Sigvisa().get_array_site(wn.sta)    
    for i_phase, phase in enumerate(new_phases):
        tg = sg.template_generator(phase)
        f1 = lambda tg=tg, site=site, phase=phase, eid=eid : \
               sg.add_event_site_phase(tg, site, phase, sg.evnodes[eid], sample_templates=False)
        f1()
        replicate_fns.append(f1)

        tmvals, tmpl_lp = clean_propose_phase_template(sg, wn, eid, 
                                                       use_correlation=use_correlation,
                                                       prebirth_unexplained=prebirth_unexplained,
                                                       phase=phase, 
                                                       fix_result=None, 
                                                       debug_info=None)      

    from sigvisa.infer.run_mcmc import single_template_MH

    if mh_steps is None:
        # hack to make sure we don't use too much inference time when GP models are in play
        #mh_steps = 5 if use_correlation else 25

        # new hack: using iid wavelets we don't have to worry as much about the GPs...
        mh_steps = 25

    # run a few iterations of MH on the proposed templates
    #tmnodes = [(phase, sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)) for phase in new_phases]
    #single_template_MH(sg, wn, tmnodes, steps=mh_steps)

    dummy_sg, dummy_wn, dummy_tmnodes = create_dummy_mh_world(sg, wn, eid)
    if len(dummy_tmnodes) == 0:
        # nothing to be done with MCMC on nonexistent templates.
        return log_qforward, replicate_fns

    dummy_wn.hack_wavelets_as_iid = True
    new_dummy_tmnodes = [(phase, tmnodes) for (phase, tmnodes) in dummy_tmnodes if phase in new_phases]

    dump_debug = False
    if sg.dump_proposal_debug_dir is not None:
        basedir = os.path.join(sg.dump_proposal_debug_dir, 'proposal_%05d' % eid)
        proposal_dir = os.path.join(basedir, wn.label)
        mkdir_p(proposal_dir)
        dump_debug = not os.path.exists(os.path.join(proposal_dir, "pre_mh.sg"))
        if dump_debug:
            lp1 = dummy_sg.current_log_p()
            dummy_sg.debug_dump(proposal_dir, pickle_only=True, pickle_name="pre_mh.sg")

    assert(dummy_wn != wn) # make sure we never screw up log_p method of an actual wn
    dummy_wn.log_p = dummy_wn.log_p_nonincremental # don't bother with incremental logp calculations
    sorted_params, param_vals = single_template_MH(dummy_sg, dummy_wn, new_dummy_tmnodes, steps=mh_steps)

    if dump_debug:
        header = ''
        for (phase, tmn) in dummy_tmnodes:
            for p in sorted_params:
                header += "%s_%s " % (phase, p)

        np.savetxt(os.path.join(proposal_dir, "tmvals.txt"), param_vals, fmt="%.3f", header=header)
        lp2 = dummy_sg.current_log_p()
        with open(os.path.join(proposal_dir, "lps.txt"), "w") as f:
            f.write("pre %f\npost %f" % (lp1, lp2))

        del dummy_wn.log_p
        dummy_sg.debug_dump(proposal_dir, pickle_only=True, pickle_name="post_mh.sg")

    # then propose template values from a local approximation to the posterior
    for phase in new_phases:
        fr_phase, debug_phase = None, None
        if debug_info is not None:
            debug_phase = debug_info[phase]
        if fix_result is not None:
            fr_phase = fix_result[phase]

        lqf, tmvals = propose_tmvals_from_gibbs_scan(dummy_sg, dummy_wn, eid, phase, 
                                                     fix_result=fr_phase,
                                                     debug_info=debug_phase)
        #lqf, tmvals = propose_tmvals_from_gibbs_scan(sg, wn, eid, phase, 
        #                                             fix_result=fr_phase,
        #                                             debug_info=debug_phase)

        def rf(eid=eid, wn=wn, tmvals=tmvals, phase=phase):
            sg.set_template(eid, wn.sta, phase, wn.band, wn.chan, tmvals)
        rf()
        replicate_fns.append(rf)
        log_qforward += lqf
            
    return log_qforward, replicate_fns

def set_value_proxy(param, vals, tmnodes):
    if param=="amp_transfer":
        proxy_param="coda_height"
    elif param=="tt_residual":
        proxy_param="arrival_time"
    else:
        raise KeyError(param)
    k_proxy, n_proxy = tmnodes[proxy_param]
    n_proxy.set_value(vals[proxy_param], key=k_proxy)


def dumb_propose_phase_template(sg, wn, eid, phase, 
                                fix_result=None, 
                                debug_info=None,
                                ev=None):
    # add the given phase to the graph, with appropriate proposal values (or fix_result)
    # return the tmvals and stuff
    if ev is None:
        ev = sg.get_event(eid)
        
    
    # sample the template params from the event-conditional prior
    tmnodes = sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
    tmvals = {}
    log_q = 0.0
    for param, (k, n) in tmnodes.items():
        if n.deterministic():
            continue
        if fix_result is not None:
            if param in fix_result:
                n.set_value(fix_result[param])
            else:
                set_value_proxy(param, fix_result, tmnodes)
        else:
            n.parent_sample()
        param_lp = n.log_p()
        log_q += param_lp

        sg.logger.debug( "dumb logq %s %s %s %s %f %s" % (param, wn.sta, phase, n.get_value(), param_lp, " fixed" if fix_result is not None else " unfixed"))

        tmvals[param] = n.get_value()
        if debug_info is not None:
            debug_info[param] = (tmvals[param], param_lp, param_lp)
        # print "param", param, "val", tmvals[param], "lp", param_lp
            
    return tmvals, log_q


def propose_new_phases_no_mh(sg, wn, eid, new_phases, fix_result=None, 
                             use_correlation=False,
                             prebirth_unexplained=None,
                             debug_info=None, proposal_type="smart"):

    log_qforward = 0
    replicate_fns = []

    site = Sigvisa().get_array_site(wn.sta)    
    for i_phase, phase in enumerate(new_phases):
        #if phase=="ScP" and wn.sta=="NV01":
        #    import pdb; pdb.set_trace()

        debug_phase = None
        if debug_info is not None:
            if phase not in debug_info:
                debug_info[phase] = {}
            debug_phase = debug_info[phase]            

        # cases:
        # dumb proposal: sample all templates from ev prior, and record lqf
        # old proposal: sample all templates from clean_propose, record lqf
        tg = sg.template_generator(phase)
        f1 = lambda tg=tg, site=site, phase=phase, eid=eid : \
               sg.add_event_site_phase(tg, site, phase, sg.evnodes[eid], sample_templates=False)
        f1()
        replicate_fns.append(f1)

        fr_phase = None
        if fix_result is not None:
            fr_phase = fix_result[phase]

        if (eid, phase) not in wn.arrivals():
            # try to avoid crashes
            sg.logger.warning("attempting to propose phase %s at %s but wn does not record the arrival!" % (phase, wn.sta))
            continue

        if proposal_type=="dumb":
            tmvals, tmpl_lp = dumb_propose_phase_template(sg, wn, eid, phase=phase, 
                                                          fix_result=fr_phase, 
                                                          debug_info=debug_phase)      
        else:
            tmvals, tmpl_lp = clean_propose_phase_template(sg, wn, eid, phase=phase, 
                                                           use_correlation=use_correlation,
                                                           prebirth_unexplained=prebirth_unexplained,
                                                           fix_result=fr_phase, 
                                                           debug_info=debug_phase)      
            #sg.logger.debug("%s %f" % (wn.sta, tmplg_lp))


        # to replay this move, we just need to reset the proposed values
        def rf(eid=eid, wn=wn, tmvals=tmvals, phase=phase):
            sg.set_template(eid, wn.sta, phase, wn.band, wn.chan, tmvals)
        replicate_fns.append(rf)
        log_qforward += tmpl_lp

    return log_qforward, replicate_fns

def ev_sta_template_birth_helper(sg, wn, eid, site_phases, fix_result=None, 
                                 debug_info=None, 
                                 use_correlation=False,
                                 repropose_uatemplates=False,
                                 prebirth_unexplained=None,
                                 associate_using_mb=True,
                                 proposal_type="smart"):

    if len(site_phases) == 0:
        nop = lambda : None
        return 0.0, nop, {"assoc": ((), 0.0, 0.0 )}

    # ensure site_phases is sorted so that it matches up with assoc_tmids
    site_phases = sorted(site_phases)

    # propose a set of associations to existing uatemplates
    log_qforward, replicate_fns, assoc_tmids, birth_record = \
        propose_associations(sg, wn, eid, site_phases, 
                             fix_result=fix_result, 
                             debug_info=debug_info, 
                             atime_only=repropose_uatemplates,
                             associate_using_mb=associate_using_mb)

    # for all phases not associated, propose template params from scratch,
    # either from 
    #  - a dumb parent-conditional proposal
    #  - a 'semismart' proposal which attempts to adapt atime and amplitude based on the signal
    #  - a smart proposal that internally runs MH steps to find good params


    # if this is a correlation proposal, we'll *also* repropose all of
    # the uatemplates we associate, to give them the opportunity to
    # fit the signal more precisely, with optimally aligned arrival
    # times etc.
    if repropose_uatemplates:
        new_phases = [phase for (phase, assoc) in zip(site_phases, assoc_tmids)]

        # for each associated template, we'll already executed the
        # association in propose_associations above, but the proposal
        # methods below assume the phase doesn't exist, so we need to
        # delete the currently-associated templates in order to
        # repropose them.
        site = Sigvisa().get_array_site(wn.sta)
        for (phase, tmid) in zip(site_phases, assoc_tmids):
            if tmid is None: continue
            tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
            assoc, assoc_tmid, _ = birth_record[phase]
            birth_record[phase] = (assoc, assoc_tmid, tmvals)

            f1 = lambda eid=eid, site=site, phase=phase : \
               sg.delete_event_phase(eid, site, phase, re_sort=False)
            f1()
            replicate_fns.append(f1)
            
    else:
        new_phases = [phase for (phase, assoc) in zip(site_phases, assoc_tmids) if assoc is None]
        

    if fix_result is not None:
        for phase in new_phases:
            assert(phase in fix_result.keys())

    if proposal_type=="mh":
        lqf, rfns = propose_new_phases_mh(sg, wn, eid, new_phases, 
                                          fix_result=fix_result,
                                          use_correlation=use_correlation,
                                          prebirth_unexplained=prebirth_unexplained,
                                          debug_info=debug_info)
    else:
        lqf, rfns = propose_new_phases_no_mh(sg, wn, eid, new_phases, 
                                             fix_result=fix_result, 
                                             debug_info=debug_info,
                                             use_correlation=use_correlation,
                                             prebirth_unexplained=prebirth_unexplained,
                                             proposal_type=proposal_type)

    log_qforward += lqf
    replicate_fns += rfns

    def replicate_fn():
        for fn in replicate_fns:
            fn()
        
    return log_qforward, replicate_fn, birth_record
        
    
def phase_birth_helper(sg, eid, site, phase, proposal_type="mh", fix_result=None):
    # boilerplate to birth a single phase across a site (as in a phase mh move),
    # rather than multple phases at a sta (as in the default ev_sta_template_birth_helper)
    lqf = 0.0
    replicate_fns = []
    death_records = {}

    stas = sg.site_elements[site]
    for sta in stas:
        ev = sg.get_event(eid)
        atime = ev.time + tt_predict(ev, sta, phase=phase)

        for wn in sg.station_waves[sta]:
            fr_sta = None
            if fix_result is not None and wn.label in fix_result:
                fr_sta = fix_result[wn.label]                

            if (wn.st <= atime and wn.et >= atime) or fr_sta is not None:
                # WARNING: can get errors if we have multiple wns matching
                # the same time period at this station

                r = ev_sta_template_birth_helper(sg, wn, eid, site_phases=(phase,),
                                                 fix_result=fr_sta,
                                                 associate_using_mb=True,
                                                 proposal_type=proposal_type)
                lqf_sta, replicate_sta,death_record = r
                lqf += lqf_sta
                replicate_fns.append(replicate_sta)
                death_records[wn.label] = death_record

    sg._topo_sort()
    replicate_fns.append(sg._topo_sort)

    def replicate_move():
        for fn in replicate_fns:
            fn()

    return lqf, replicate_move, death_records

def phase_death_helper(sg, eid, site, phase, fix_result=None):
    lqf = 0.0
    replicate_fns = []
    birth_records = {}

    stas = sg.site_elements[site]
    for sta in stas:
        for wn in sg.station_waves[sta]:
            if (eid, phase) not in wn.arrivals():
                continue

            fr_sta = None
            if fix_result is not None:
                fr_sta = fix_result[wn.label]                

            r = ev_sta_template_death_helper(sg, wn, eid, phases=(phase,),
                                             fix_result=fr_sta)
            lqf_sta, replicate_sta,birth_record = r
            lqf += lqf_sta
            replicate_fns.append(replicate_sta)
            birth_records[wn.label] = birth_record

    sg._topo_sort()
    replicate_fns.append(sg._topo_sort)

    def replicate_move():
        for fn in replicate_fns:
            fn()

    return lqf, replicate_move, birth_records

def phase_birth_proposal(sg, eid, site, fix_result=None):
    # of possible phases that don't currently exist, choose one to propose

    ev = sg.get_event(eid)
    possible_phases = sg.predict_phases_site(ev, site)
    current_phases = sg.ev_arriving_phases(eid, site=site)
    new_phases = possible_phases - current_phases

    if len(new_phases)==0:
        return None, 0.0

    phase_probs = Counter()
    for phase in new_phases:
        pm = sg.get_phase_existence_model(phase)
        lp = pm.log_p(True, ev=ev, site=site)
        phase_probs[phase] = np.exp(.5*lp)
    
    phase_probs.normalize()
    if fix_result is not None:
        phase = fix_result
    else:
        phase = phase_probs.sample()
    return phase, np.log(phase_probs[phase])

def phase_death_proposal(sg, eid, site, fix_result=None):
    ev = sg.get_event(eid)
    current_phases = sg.ev_arriving_phases(eid, site=site)
    if len(current_phases) == 0:
        return None, 0.0

    phase_probs = Counter()
    total_prob = 0.0
    for phase in current_phases:
        pm = sg.get_phase_existence_model(phase)
        lp = pm.log_p(False, ev=ev, site=site)
        phase_probs[phase] = np.exp(.5*lp)
        total_prob += phase_probs[phase]

    # return without proposing if the prior won't let
    # us remove any of the active phases..
    if total_prob == 0.0:
        return None, 0.0

    phase_probs.normalize()
    if fix_result is not None:
        phase = fix_result
    else:
        phase = phase_probs.sample()
    return phase, np.log(phase_probs[phase])
    


def phase_lp(sg, eid, site, wns):
    # get current logp
    #  (including site logp, relevant tmvals, and phase existence)

    lp = 0.0

    # always compute the ev prior, and
    # always compute all params at all stations, since
    #  - if we're not using GPs, this is cheap (though maybe not necessary)
    #  - if we're using GPs, this is necessary, since any parent-conditional 
    #    distribution can be changed by a change in ev location. 
    relevant_nodes = wns + [n for n in sg.extended_evnodes[eid] if not n.deterministic()]
    
    lp = sg.phase_existence_lp(eids=(eid,), sites=(site,))
    for wn in wns:
        # include any wns where our signal explanation will have changed.
        # if the only record is that we didn't decouple, we can skip this wn.

        tmids = [-eid for (eid, phase) in wn.arrivals() if phase=="UA"]
        lp += sg.ntemplates_sta_log_p(wn, n=len(tmids))
        for tmid in tmids:
            relevant_nodes += sg.uatemplates[tmid].values()

    lp += sg.joint_logprob_keys(relevant_nodes)

    return lp

def phase_birth_move(sg, eid, site):
    
    wns = []
    for sta in sg.site_elements[site]:
        wns += sg.station_waves[sta]


    # of possible phases that don't currently exist, choose one to propose
    phase, phase_lqf = phase_birth_proposal(sg, eid, site)
    if phase is None:
        # if all possible phases already exist
        return False

    lp_old = phase_lp(sg, eid, site, wns)
    #lp_old_full = sg.current_log_p()

    # call the birth helper
    lqf, replicate_birth, death_record = phase_birth_helper(sg, eid, site, phase)

    # get new logp
    lp_new = phase_lp(sg, eid, site, wns)
    #lp_new_full = sg.current_log_p()

    #assert( np.abs((lp_new_full - lp_old_full)  - (lp_new-lp_old)) < 1e-4 )

    # call the death helper
    lqb, replicate_death, birth_record = phase_death_helper(sg, eid, site, phase, fix_result=death_record)

    # do mh acceptance
    def accept():
        replicate_birth()

    return mh_accept_util(lp_old, lp_new, lqf, lqb, accept_move=accept)


def phase_death_move(sg, eid, site):
    wns = []
    for sta in sg.site_elements[site]:
        wns += sg.station_waves[sta]

    # DEBUG section to catch illegal phases before we start...
    current_phases = sg.ev_arriving_phases(eid, site=site)
    ev = sg.get_event(eid)
    ttimes = {}
    s = Sigvisa()
    sta = s.get_default_sta(site)
    for phase in current_phases:
        ttimes[phase] = tt_predict(ev, sta=sta, phase=phase)

    # choose a phase to kill
    phase, phase_lqf = phase_death_proposal(sg, eid, site)
    if phase is None:
        return False

    lp_old = phase_lp(sg, eid, site, wns)
    #lp_old_full = sg.current_log_p()

    lqf, replicate_death, birth_record = phase_death_helper(sg, eid, site, phase)

    lp_new = phase_lp(sg, eid, site, wns)
    #lp_new_full = sg.current_log_p()

    lqb, replicate_birth, death_record = phase_birth_helper(sg, eid, site, phase, 
                                                            fix_result=birth_record)

    #assert( np.abs((lp_new_full - lp_old_full)  - (lp_new-lp_old)) < 1e-4 )

    # do mh acceptance
    def accept():
        replicate_death()

    return mh_accept_util(lp_old, lp_new, lqf, lqb, accept_move=accept)


def ev_template_birth_helper(sg, eid, fix_result=None, 
                             associate_using_mb=True,
                             proposal_type="mh",
                             use_correlation=False,
                             repropose_uatemplates=False,
                             debug_info=None, **kwargs):
    death_records = {}
    replicate_fns = []
    log_qforward = 0

    prebirth_unexplained = None
    if use_correlation:
        if fix_result is not None:
            exclude_eids = [eid,]
        else:
            exclude_eids = []
        prebirth_unexplained = {}
        for sta, wns in sg.station_waves.items():
            for wn in wns:
                prebirth_unexplained[wn.label] = wn.unexplained_kalman(exclude_eids=exclude_eids)

    proposed_ev = sg.get_event(eid)
    lqf_stas = {}
    for site,elements in sg.site_elements.items():
        key = "%s_phases" % site
        fr_phases = None
        if fix_result is not None:
            fr_phases = fix_result[key]
        site_phases, lqf = sg.sample_phases_site(proposed_ev, site=site, fix_result=fr_phases)
        site_phases = sorted(list(site_phases))
        death_records[key] = site_phases
        log_qforward += lqf
        lqf_stas[site + "_phases"] = lqf

        #site_phases = sorted(sg.predict_phases_site(proposed_ev, site=site))
        for sta in elements:
            debug_info_sta = None
            if debug_info is not None:
                if sta not in debug_info:
                    debug_info[sta] = dict()
                debug_info_sta = debug_info[sta]
                debug_info[sta]["wn_old"] = np.sum([wn.log_p() for wn in sg.station_waves[sta]])
                
            for wn in sg.station_waves[sta]:
                fr_sta = None
                if fix_result is not None:
                    fr_sta = fix_result[wn.label]                
                lqf_sta, replicate_sta, death_sta = \
                    ev_sta_template_birth_helper(sg, wn, eid=eid, 
                                                 site_phases=site_phases,
                                                 fix_result=fr_sta,
                                                 associate_using_mb=associate_using_mb,
                                                 use_correlation=use_correlation,
                                                 repropose_uatemplates=repropose_uatemplates,
                                                 prebirth_unexplained=prebirth_unexplained,
                                                 debug_info=debug_info_sta, 
                                                 proposal_type=proposal_type,
                                                 **kwargs)
                log_qforward += lqf_sta
                lqf_stas[wn.label] = lqf_sta
                replicate_fns.append(replicate_sta)
                death_records[wn.label] = death_sta
                
            if debug_info_sta is not None:
                debug_info[sta]["wn_new"] = np.sum([wn.log_p() for wn in sg.station_waves[sta]])
                
    def replicate_move():
        for fn in replicate_fns:
            fn()
    
    return log_qforward, replicate_move, death_records

                
    
def ev_birth_executor(sg, location_proposal, 
                      proposal_includes_mb=True, 
                      proposal_type="mh",
                      use_correlation=False, 
                      repropose_uatemplates=False,
                      force_eid=None,
                      force_outcome=None,
                      inference_step=None):
    debug_info = {}
        

    log_qbackward = 0.0
    log_qforward = 0.0

    n_current_events = len(sg.evnodes) - len(sg.fixed_events)
    if force_eid is None:
        log_qforward += -np.log(n_current_events + 1)
    
    lp_old = sg.current_log_p()

    lq_loc, replicate_birth, eid, extra = ev_bare_birth_move(sg, location_proposal, debug_info=debug_info, eid=force_eid)
    if lq_loc is None:
        return None

    log_qforward += lq_loc


    lqf, replicate_tmpls, birth_records = \
                    ev_template_birth_helper(sg, eid, 
                                             associate_using_mb=proposal_includes_mb, 
                                             use_correlation=use_correlation,
                                             repropose_uatemplates=repropose_uatemplates,
                                             proposal_type=proposal_type,
                                             debug_info=debug_info)
    log_qforward += lqf
    sg._topo_sort()
    
    lp_new = sg.current_log_p()

    if sg.dump_proposal_debug_dir is not None:
        dump_path = os.path.join(sg.dump_proposal_debug_dir, 'proposal_%05d' % eid)
        if not os.path.exists(os.path.join(dump_path, "pickle.sg")):
            sg.debug_dump(dump_path = dump_path, pickle_only=True)

    
    lqb, replicate_untmpls, death_records = ev_template_death_helper(sg, eid, fix_result=birth_records, repropose_uatemplates=repropose_uatemplates, debug_info=debug_info)
    log_qbackward += lqb

    if force_eid is None:
        lq_death = sample_death_proposal(sg, fix_result=eid, debug_info=debug_info)
        log_qbackward += lq_death

    replicate_death, ev = ev_bare_death_move(sg, eid)
    sg._topo_sort()
    
    # should get rid of this (and corresponding line in death move) at
    # some point once I'm confident, since it's actually pretty
    # expensive
    #lp_old2 = sg.current_log_p()
    #assert(np.abs(lp_old2 - lp_old) < 1e-6)

    def rebirth():
        replicate_birth()
        replicate_tmpls()
        sg._topo_sort()
        
    def redeath():
        replicate_untmpls() # maybe not technically necessary
        replicate_death()
        sg._topo_sort()

    proposal_extra = (extra, eid, ev, debug_info)
    return lp_new, lp_old, log_qforward, log_qbackward, rebirth, redeath, proposal_extra

def ev_birth_move_abstract(sg, location_proposal, revert_action=None, 
                           accept_action=None, force_outcome=None, **kwargs):

    r = ev_birth_executor(sg, location_proposal, **kwargs)
    if r is None:
        # location proposal did not return an event
        return False
    else:
        lp_new, lp_old, log_qforward, log_qbackward, rebirth, redeath, proposal_extra = r


    def revert():
        if revert_action is not None:
            revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        #revert_move()

    def accept():
        rebirth()
        if accept_action is not None:
            accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)


    sg.logger.info( "birth move acceptance %f from old %f new %f lqb %f lqf %f" % ( (lp_new + log_qbackward) - (lp_old+log_qforward), lp_old, lp_new, log_qbackward, log_qforward))


    return mh_accept_util(lp_old, lp_new, log_qforward, log_qbackward, accept_move=accept, revert_move=revert, force_outcome=force_outcome)

def ev_birth_move_hough(sg, log_to_run_dir=None, hough_kwargs = {}, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, proposed_ev, debug_info = proposal_extra

        if log_to_run_dir is None:
            sg.logger.warning("WARNING: not logging event because no rundir specified")
            return

        log_file = os.path.join(log_to_run_dir, "hough_proposals.txt")
        birth_dir = os.path.join(log_to_run_dir, "birth_proposals")
        mkdir_p(birth_dir)
        ev_log_file = os.path.join(birth_dir, "birth_proposal_%d.txt" % eid)

        # proposed event should be the most recently created
        if eid is None:
            eid = np.max(sg.evnodes.keys())

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s eid %d\n" % (proposed_ev, eid))
            f.write(" hough args %s other args %s\n" % (repr(hough_kwargs), repr(kwargs)))
            f.write(" acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            f.write("\n")
        with open(ev_log_file, 'w') as f:
            f.write(prettyprint_debug(debug_info))


    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, proposed_ev, debug_info = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

        if log_to_run_dir is None:
            return
                
        if np.random.rand() < 1.0: #0.1:
            sites = sg.site_elements.keys()
            sg.logger.info("saving hough array picture...")
            fname = 'last_hough_%d_%s.png' % (eid, "_".join(["",] + hough_kwargs.keys()))
            visualize_hough_array(hough_array, sites, os.path.join(log_to_run_dir, fname), region=sg.inference_region)


    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, proposed_ev, debug_info = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

        if log_to_run_dir is None:
            return

        if log_to_run_dir is not None:
            log_event_birth(sg, hough_array, log_to_run_dir, eid)
        else:
            raise Exception("why are we not logging?")

    def hlp(sg, **kwargs):
        kwargs.update(hough_kwargs)
        return hough_location_proposal(sg, **kwargs)

    return ev_birth_move_abstract(sg, location_proposal=hlp, revert_action=revert_action, accept_action=accept_action, proposal_includes_mb=True, **kwargs)


def prior_location_proposal(sg, fix_result=None, proposal_dist_seed=None):
    if proposal_dist_seed is not None:
        np.random.seed(proposal_dist_seed)

    ev, lp = sg.prior_sample_event(return_logp=True, fix_result=fix_result)
    if fix_result is not None:
        return lp
    else:
        return ev, lp, None

def ev_birth_move_prior(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        _, eid, proposed_ev, debug_info = proposal_extra

        if log_to_run_dir is None:
            sg.logger.warning("WARNING: not logging event because no rundir specified")
            return

        log_file = os.path.join(log_to_run_dir, "prior_proposals.txt")
        birth_dir = os.path.join(log_to_run_dir, "birth_proposals")
        mkdir_p(birth_dir)
        ev_log_file = os.path.join(birth_dir, "birth_proposal_%d.txt" % eid)

        # proposed event should be the most recently created
        if eid is None:
            eid = np.max(sg.evnodes.keys())

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s eid %d\n" % (proposed_ev, eid))
            f.write(" acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            f.write("\n")

        with open(ev_log_file, 'w') as f:
            f.write(prettyprint_debug(debug_info))


    return ev_birth_move_abstract(sg, location_proposal=prior_location_proposal, 
                                  accept_action=log_action,
                                  revert_action=log_action,
                                  proposal_includes_mb=True, 
                                  proposal_type="dumb", **kwargs)

def ev_death_move_prior(sg, log_to_run_dir=None, inference_step=-1, **kwargs):


    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        if log_to_run_dir is None:
            return
        
        _ , eid, proposed_ev, debug_info = proposal_extra
        log_file = os.path.join(log_to_run_dir, "prior_deaths.txt")

        logdir = os.path.join(log_to_run_dir, "ev_%05d" % eid)
        ev_log_file = os.path.join(logdir, "death_proposal_%d.txt" % inference_step)
        mkdir_p(logdir)
        with open(ev_log_file, 'w') as f:
            f.write(prettyprint_debug(debug_info))

        with open(log_file, 'a') as f:
            f.write("proposing to kill eid %d: %s\n" % (eid, proposed_ev))
            f.write("acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            f.write("\n")


    return ev_death_move_abstract(sg, location_proposal=prior_location_proposal, 
                                  proposal_includes_mb=True, 
                                  inference_step=inference_step,
                                  accept_action=log_action,
                                  revert_action=log_action,
                                  birth_type="dumb", **kwargs)

def sample_hough_kwargs(sg):
    #phase_choices = ( ("Pn",), ("Pg", "Lg"), ("Pn", "Sn", "Lg", "Pg"), )
    #phase_choices = ( ("Pg", "Lg"), ("Pg", "Lg"), )
    phase_choices = ( ("P",), ("P", "S") , ("P","Pn","Pg","S","Sn"))
    mbbins_choices = ( (12, 2, 2, 2), (1, 1, 1, 12))
    multipliers = (1.0, 1.5)
    offsets = (False, True)
    one_event_semantics = (False, True, True, True)

    # avoid stupid "must be one dimensional" error
    mbbin_idx = np.random.choice(np.arange(len(mbbins_choices))) 
    phase_idx = np.random.choice(np.arange(len(phase_choices)))
    hough_kwargs = {"one_event_semantics": np.random.choice(one_event_semantics),
                    "offset": np.random.choice(offsets),
                    "bin_width_multiplier": np.random.choice(multipliers),
                    "mbbins": mbbins_choices[mbbin_idx],
                    "phases": phase_choices[phase_idx]}

    if sg.inference_region is not None:
        stime = sg.inference_region.stime
        etime = sg.inference_region.etime

        restricted_length = 1200.0
        restricted_windows = int(np.ceil((etime - stime) /restricted_length))
        restricted_length = (etime-stime) / restricted_windows
        restricted_stime = np.linspace(stime, etime, restricted_windows)
        restricted_etime = restricted_stime + restricted_length
        intervals = zip(restricted_stime, restricted_etime)

        if np.random.rand() < 0.5:
            idx = np.random.choice(np.arange(len(intervals)))
            interval = intervals[idx]
            hough_kwargs["stime"] = interval[0]
            hough_kwargs["etime"] = interval[1]

    return hough_kwargs

def ev_birth_move_hough_meta(sg, **kwargs):
    hough_kwargs = sample_hough_kwargs(sg)

    proposal_type = np.random.choice(("mh", "mh", "dumb", ))
    #repropose_uatemplates = np.random.rand() < 0.5
    repropose_uatemplates = False

    return ev_birth_move_hough(sg, hough_kwargs=hough_kwargs, 
                               repropose_uatemplates=repropose_uatemplates,
                               proposal_type=proposal_type, **kwargs)
    

def ev_birth_move_correlation(sg, corr_kwargs={}, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        if log_to_run_dir is None:
            return

        (proposal_weights, proposal_idx, proposal_otime_posteriors, training_xs), eid, proposed_ev, debug_info = proposal_extra
        xx = training_xs[proposal_idx]
        #hough_array, eid, associations = proposal_extra

        log_file = os.path.join(log_to_run_dir, "correlation_proposals.txt")
        birth_dir = os.path.join(log_to_run_dir, "birth_proposals")
        mkdir_p(birth_dir)
        ev_log_file = os.path.join(birth_dir, "birth_proposal_%d.txt" % eid)
        corr_log_file = os.path.join(birth_dir, "birth_proposal_%d_correlations.txt" % eid)

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s eid %d\n" % (proposed_ev, eid))
            f.write(" proposal based on match of event idx %d with weight %.4f\n" % (proposal_idx, proposal_weights[proposal_idx]))
            f.write(" corr kwargs %s other args %s\n" % (str(corr_kwargs), str(kwargs)))
            f.write(" acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            #for (wn, phase), (assoc, tmvals) in associations.items():
            #    if assoc:
            #        f.write(" associated %s at %s, %s, %s\n" % (phase, wn.sta, wn.chan, wn.band))
            f.write("\n")

        with open(ev_log_file, 'w') as f:
            f.write(prettyprint_debug(debug_info))
        with open(corr_log_file, 'w') as f:
            f.write(debug_proposal_weights(proposal_weights, training_xs, proposal_idx))

    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

        (proposal_weights, proposal_idx, proposal_otime_posteriors, training_xs), eid, proposed_ev, debug_info = proposal_extra
        if log_to_run_dir is not None:
            if "stas" in corr_kwargs: 
                stas = corr_kwargs["stas"]
            else:
                stas = ()

            log_dir = os.path.join(log_to_run_dir, "ev_%05d" % eid)
            mkdir_p(log_dir)
            plot_fname = os.path.join(log_dir, "proposal.png")
            plot_proposal_weights(training_xs, proposal_weights, stas, fname=plot_fname)
        else:
            raise Exception("why are we not logging?")

    def clp(sg, fix_result=None, **kwargs):
        kwargs.update(corr_kwargs)
        return correlation_location_proposal(sg, fix_result=fix_result, **kwargs)

    return ev_birth_move_abstract(sg, location_proposal=clp, 
                                  revert_action=revert_action, 
                                  accept_action=accept_action, 
                                  proposal_includes_mb=False, 
                                  use_correlation=True, 
                                  repropose_uatemplates=True, **kwargs)

def debug_proposal_weights(proposal_weights, training_xs, proposal_idx):
    n = len(proposal_weights)
    p = sorted(np.arange(n), key = lambda i : -proposal_weights[i])
    training_xs = np.asarray(training_xs).reshape((n, -1))

    s = ""
    for i in p:
        lon, lat, depth = training_xs[i, :3]
        weight = proposal_weights[i]
        s += "%04d (%7.2f %7.2f %5.1f) %f\n" % (i, lon, lat, depth, weight)

    return s

def ev_birth_move_correlation_random_sta(sg, **kwargs):
    corr_kwargs = sample_corr_kwargs(sg)    
    proposal_type = "mh"
    
    return ev_birth_move_correlation(sg, corr_kwargs=corr_kwargs, 
                                     proposal_type=proposal_type, **kwargs)

def ev_birth_move_cheating(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "correlation_proposals.txt")


    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        #if log_to_run_dir is not None:
        #    log_event_birth(sg, None, log_to_run_dir, eid)
        #else:
        #    raise Exception("why are we not logging?")

    return ev_birth_move_abstract(sg, location_proposal=cheating_location_proposal, revert_action=revert_action, accept_action=accept_action, proposal_includes_mb=True, **kwargs)


def ev_birth_move_lstsqr(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        refined_proposals, eid, associations, debug_info = proposal_extra
        log_file = os.path.join(log_to_run_dir, "lsqr_proposals.txt")

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        if refined_proposals is None:
            refined_proposals = []

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write("acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            for abserror, z, C in refined_proposals:
                f.write("  %.2f lon %.2f lat %.2f depth %.2f time %.2f\n" % (abserror, z[0], z[1], z[2], z[3]))
            f.write("\n")

    return ev_birth_move_abstract(sg, location_proposal=overpropose_new_locations, accept_action=log_action, revert_action=log_action, **kwargs)

##############################################################

def log_event_birth(sg, hough_array, run_dir, eid):

    log_dir = os.path.join(run_dir, "ev_%05d" % eid)
    mkdir_p(log_dir)

    # save post-birth signals and general state
    # sg.debug_dump(dump_path=log_dir, pickle_graph=False)


    # save Hough transform
    sites = sg.site_elements.keys()
    if hough_array is not None:
        sg.logger.info("visualizing hough array...")
        visualize_hough_array(hough_array, sites, os.path.join(log_dir, 'proposal.png'), region=sg.inference_region)


def prettyprint_debug(birth_debug):
    s = ""

    # track lp_new - (lp_old + log_qforward)
    overall_score = 0

    inferred_lpnew = 0
    inferred_lpold = 0
    inferred_qforward = 0

    ev, lq_ev, lps_ev = birth_debug["ev"]
    s += "proposed ev %s\n" % ev
    s += "proposal logq %.2f, lps " % lq_ev
    total_lp = 0
    for (param, lp) in lps_ev:
        s += "%s %.2f, " % (param, lp)
        inferred_lpnew += lp
        total_lp += lp

    inferred_qforward += lq_ev
    delta = total_lp - lq_ev
    s += "total %.2f, delta %.2f\n" % (total_lp, delta)
    overall_score = delta
    
    for sta in sorted(birth_debug.keys()):
        if sta=="ev": continue
        if sta=="death_proposal_lp": continue

        wn_old, wn_new = birth_debug[sta]["wn_old"], birth_debug[sta]["wn_new"]
        inferred_lpold += wn_old
        inferred_lpnew += wn_new
        wn_delta = wn_new - wn_old

        try:
            phase_assocs, assoc_lp, _ = birth_debug[sta]["assoc"]
        except KeyError:
            s += "sta %s wn_old %.2f wn_new %.2f wn_delta %.2f NO ASSOC INFO overall %.2f\n" % (sta, wn_old, wn_new, wn_delta, wn_delta)
            continue
            

        s += "sta %s wn_old %.2f wn_new %.2f wn_delta %.2f assoc %.2f deassoc DEASSOCSCORE overall STASCORE\n" % (sta, wn_old, wn_new, wn_delta, assoc_lp)
        sta_score = wn_delta - assoc_lp
        inferred_qforward += assoc_lp

        phase_assocs = dict(phase_assocs)
        deassoc_score = 0.0

        for phase in sorted(birth_debug[sta].keys()):
            if "wn" in phase or phase=="assoc" : continue
            phase_score = 0


            deassoc_lp = birth_debug[sta][phase]["deassociate"]
            deassoc_score += deassoc_lp
            del birth_debug[sta][phase]["deassociate"]
            phase_score += deassoc_lp

            repropose_lp = 0.0
            repropose_str = 0.0
            if "repropose_lp" in birth_debug[sta][phase]:
                repropose_lp = birth_debug[sta][phase]["repropose_lp"]
                del birth_debug[sta][phase]["repropose_lp"]
                repropose_str = "death/repropose lq %.2f, " % (repropose_lp)
                phase_score += repropose_lp
                
            tmid = phase_assocs[phase]
            if tmid is not None:
                s += " phase %s: associating tmid %d, death/deassoc lq %.2f, %sscore PHASESCORE\n" % (phase, tmid, deassoc_lp, repropose_str)
            else:
                s += " phase %s: birthing new template, death/deletion lq %.2f, score PHASESCORE\n" % (phase, deassoc_lp)


            d = birth_debug[sta][phase]
            for param, (v, lp1, lp2) in sorted(d.items()):
                delta = lp2-lp1
                if tmid is not None:
                    s += "   %s %.2f ualp %.2f evlp %.2f delta %.2f\n" % (param, v, lp1, lp2, delta)
                    inferred_lpold += lp1
                    inferred_lpnew += lp2
                else:
                    s += "   %s %.2f logq %.2f logp %.2f delta %.2f\n" % (param, v, lp1, lp2, delta)
                    inferred_qforward += lp1
                    inferred_lpnew += lp2

                phase_score += delta
            s = s.replace("PHASESCORE", "%.2f" % phase_score)

            sta_score += phase_score

        overall_score += sta_score
        s = s.replace("DEASSOCSCORE", "%.2f" % deassoc_score)
        s = s.replace("STASCORE", "%.2f" % sta_score)

    s += "death proposal lp %.3f\n" % birth_debug["death_proposal_lp"]
    overall_score += birth_debug["death_proposal_lp"]

    s += "final proposal score %.2f\n" % overall_score
    s += "inferred lpold %.1f lpnew %.1f delta %.1f log_qforward %.1f alt_score %.1f\n" % (inferred_lpold, inferred_lpnew, inferred_lpnew-inferred_lpold, inferred_qforward, inferred_lpnew - inferred_lpold - inferred_qforward)
    s += "REMEMBER: the acceptance ratio also includes the reverse proposal probability from the death move.\n"

    return s
