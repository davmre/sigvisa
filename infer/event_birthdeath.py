import numpy as np
import copy
import sys
import traceback
import pdb
import pickle
import os

from sigvisa import Sigvisa
from sigvisa.graph.array_node import lldlld_X
from sigvisa.graph.nodes import Node
from sigvisa.graph.graph_utils import extract_sta_node, create_key, get_parent_value, parse_key
from sigvisa.graph.sigvisa_graph import get_param_model_id, dummyPriorModel, ModelNotFoundError
from sigvisa.ssms_c import TransientCombinedSSM
from sigvisa.infer.propose_hough import hough_location_proposal, visualize_hough_array
from sigvisa.infer.propose_lstsqr import overpropose_new_locations
from sigvisa.infer.propose_mb import propose_mb
from sigvisa.infer.propose_cheating import cheating_location_proposal
from sigvisa.infer.correlations.ar_correlation_model import ar_advantage
from sigvisa.infer.correlations.event_proposal import correlation_location_proposal
from sigvisa.infer.template_mcmc import get_env_based_amplitude_distribution, get_env_based_amplitude_distribution2, get_env_diff_positive_part, sample_peak_time_from_cdf, merge_distribution, peak_log_p, preprocess_signal_for_sampling
from sigvisa.infer.mcmc_basic import mh_accept_util
from sigvisa.learn.train_param_common import load_modelid
from sigvisa.models.ttime import tt_residual, tt_predict
from sigvisa.models.templates.coda_height import amp_transfer
from sigvisa.models.distributions import Gaussian, Laplacian, PiecewiseLinear
from sigvisa.utils.counter import Counter
from sigvisa.utils.fileutils import mkdir_p
from sigvisa.source.event import get_event
import sigvisa.source.brune_source as brune

hough_options = {'bin_width_deg':1.0, 'time_tick_s': 10.0, 'smoothbins': True}

def set_hough_options(ho):
    global hough_options
    hough_options = ho

def unass_template_logprob(sg, wn, template_dict, ignore_mb=False):
    """

    return the log prob of a set of template parameters, under the
    model of unassociated templates at a station sta.

    """

    # HACK

    tg = sg.template_generator(phase="UA")


    lp = 0.0
    lp += -np.log(float(wn.npts)/wn.srate) # arrival time
    for param in tg.params(env=wn.is_env):
        if ignore_mb and param=="coda_height": continue
        model = tg.unassociated_model(param, nm=wn.nm)
        lp += model.log_p(template_dict[param])
    return lp

def param_logprob(sg, site, sta, ev, phase, chan, band, param, val):

    """
    return the log probability for an individual template parameter,
    as generated by an event phase arrival, WITHOUT interfering with
    the graph.
    """

    try:
        tmnodes = sg.get_template_nodes(ev.eid, sta, phase, band, chan)
        model = tmnodes[param][1].model
        cond = ev
    except Exception as e:
        model_type = sg._tm_type(param, site=site)
        if model_type == "dummy":
            return 0.0
        if model_type == "dummyPrior":
            model = dummyPriorModel(param)
            return model.log_p(x=val)

        s = Sigvisa()
        if s.is_array_station(site) and sg.arrays_joint:
            modelid = get_param_model_id(runids=sg.runids, sta=site,
                                         phase=phase, model_type=model_type,
                                         param=param, template_shape=sg.template_shape,
                                         chan=chan, band=band)
            cond = lldlld_X(ev, sta)
        else:
            try:
                modelid = get_param_model_id(runids=sg.runids, sta=sta,
                                             phase=phase, model_type=model_type,
                                             param=param, template_shape=sg.template_shape,
                                             chan=chan, band=band)
            except ModelNotFoundError as e:
                if sg.dummy_fallback:
                    modelid = -1
                else:
                    raise e

            cond = ev

        if modelid > -1:
            model = load_modelid(modelid)
        else:
            model = sg.dummy_prior[param]

    lp = model.log_p(x = val, cond = cond)
    if sg.hack_param_constraint:
        lp += Node.param_truncation_penalty(param=param, value=val)
    return lp

def ev_phase_template_logprob(sg, wn, eid, phase, template_dict, verbose=False, ignore_mb=False):

    """

    return log p(template params in template_dict) under the distribution generated by a phase arrival from event eid at station sta.

    """

    ev = sg.get_event(eid)
    sta = wn.sta
    s = Sigvisa()
    site = s.get_array_site(sta)

    if 'tt_residual' not in template_dict and 'arrival_time' in template_dict:
        template_dict['tt_residual'] = tt_residual(ev, wn.sta, template_dict['arrival_time'], phase=phase)

    if 'amp_transfer' not in template_dict and "coda_height" in template_dict:
        template_dict['amp_transfer'] = amp_transfer(ev, wn.band, phase, template_dict['coda_height'])
    # note if coda height is not specified, we'll ignore amp params
    # entirely: this is used by the create-new-template proposer
    # (in phase_template_proposal_logp etc)

    lp = 0
    for (param, val) in template_dict.items():
        if param in ('arrival_time', 'coda_height'): continue
        if ignore_mb and param == 'amp_transfer': continue
        lp_param = param_logprob(sg, site, wn.sta, ev, phase, wn.chan, wn.band, param, val)
        if verbose:
            print "%s lp %s=%.2f is %.2f" % (wn.sta, param, val, lp_param)
        lp += lp_param

    return lp


def template_association_logodds(sg, sta, tmid, eid, phase, ignore_mb=False):

    tmnodes = sg.uatemplates[tmid]
    param_values = dict([(k, n.get_value()) for (k,n) in tmnodes.items()])

    lp_unass = unass_template_logprob(sg, sta, param_values, ignore_mb=ignore_mb)
    lp_ev = ev_phase_template_logprob(sg, sta, eid, phase, param_values, ignore_mb=ignore_mb)

    logodds = lp_ev - lp_unass
    #print "%s %d logodds %f" % (sta, tmid, logodds)
    return logodds


def template_association_distribution(sg, wn, eid, phase, ignore_mb=False, forbidden=None):
    """
    Returns a counter with normalized probabilities for associating
    any existing unassociated templates at station sta with a given
    phase of event eid. Probability of no association is given by c[None].

    """

    sta, band, chan = wn.sta, wn.band, wn.chan

    c = Counter()
    for tmid in sg.uatemplate_ids[(sta,chan,band)]:
        if forbidden is not None and tmid in forbidden: continue
        c[tmid] += np.exp(template_association_logodds(sg, wn, tmid, eid,
                                                       phase, ignore_mb=ignore_mb))

    # if there are no unassociated templates, there's nothing to sample.
    n_u = len(sg.uatemplate_ids[(sta, chan, band)])
    if n_u == 0:
        c[None] = 1.0
        return c

    c[None] = np.exp(sg.ntemplates_sta_log_p(wn, n=n_u) - sg.ntemplates_sta_log_p(wn, n=n_u-1))

    c.normalize()

    # smooth probabilities slightly, so we don't get proposals that
    # are impossible to reverse
    nkeys = len(c.keys())
    for k in c.keys():
        c[k] += 1e-4/nkeys
    c.normalize()

    return c

def sample_template_to_associate(sg, wn, eid, phase, 
                                 ignore_mb=False, forbidden=None,
                                 fix_result=None):
    """
    Propose associating an unassociate template at sta with the
    (eid,phase) arrival, with probability proportional to the odds
    ratio p_{E,P}(T)/p_U(T). Alternately propose creating a new
    template, with probability proportional to p(N_U = n_U)/p(N_U =
    n_U - 1).

    Return:
    tmid: the unassociated template id proposed for
          association. (value of None indicates proposing a creation
          move)
    assoc_logprob: log probability of the proposal

    """


    c = template_association_distribution(sg, wn, eid, phase, ignore_mb=ignore_mb, forbidden=forbidden)
    if fix_result is not None:
        tmid = fix_result
    else:
        tmid = c.sample()
    assoc_logprob = np.log(c[tmid])
    return tmid, assoc_logprob

def associate_template(sg, wn, tmid, eid, phase, create_phase_arrival=False, node_lps=None):
    """

    Transform the graph to associate the template tmid with the arrival of eid/phase at sta.

    """

    tmnodes = sg.uatemplates[tmid]
    sta = wn.sta
    s = Sigvisa()
    site = s.get_array_site(sta)

    values = dict([(k, n.get_value()) for (k, n) in tmnodes.items()])
    phase_created = False
    if create_phase_arrival and phase not in sg.ev_arriving_phases(eid, sta=sta):
        tg = sg.template_generator(phase)
        sg.add_event_site_phase(tg, site, phase, sg.evnodes[eid])
        phase_created=True

    if node_lps is not None:
        if phase_created:
            node_lps.register_new_phase_pre(sg, site, phase, eid)
        else:
            node_lps.register_phase_changed_oldvals(sg, site, phase, eid, wn_invariant=True)

    # if a newly birthed event, it already has a phase arrival that just needs to be set
    sg.set_template(eid, wn.sta, phase, wn.band, wn.chan, values)

    if node_lps is not None:
        if phase_created:
            node_lps.register_new_phase_post(sg, site, phase, eid)
        else:
            node_lps.register_phase_changed_newvals(sg, site, phase, eid, wn_invariant=True)
        node_lps.register_remove_uatemplate(sg, tmid, wn_invariant=True)
    sg.destroy_unassociated_template(tmnodes, nosort=True)
    return

def unassociate_template(sg, wn, eid, phase, tmid=None, remove_event_phase=False, node_lps=None):

    s = Sigvisa()
    site = s.get_array_site(wn.sta)

    
    ev_tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)

    atime = ev_tmvals['arrival_time']
    tmnodes = sg.create_unassociated_template(wn, atime, nosort=True,
                                           tmid=tmid, initial_vals=ev_tmvals)
    tmid = tmnodes.values()[0].tmid
    if node_lps is not None:
        node_lps.register_new_uatemplate(sg, tmid)

    if remove_event_phase:
        # if we're just unassociating this phase (not deleting the
        # whole event), we need to delete the event phase arrival.
        if node_lps is not None:
            node_lps.register_phase_removed_pre(sg, site, phase, eid, wn_invariant=True)
        sg.delete_event_phase(eid, wn.sta, phase)

    return tmid

def deassociation_logprob(sg, wn, eid, phase, deletion_prob=False, min_logprob=-6):

    # return prob of deassociating (or of deleting, if deletion_prob=True).
    arrivals = copy.copy(wn.arrivals())
    try:
        arrivals.remove((eid, phase))
    except KeyError:
        # if this arrival doesn't actually occur during the signal contained at the wn,
        # delete it with probability 1. 
        if deletion_prob:
            return 0.0
        else:
            return -np.inf

    ev_tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)

    unass_lp = unass_template_logprob(sg, wn, ev_tmvals)

    n_u = len(sg.uatemplate_ids[(wn.sta,wn.chan,wn.band)])
    ntemplates_ratio_log = sg.ntemplates_sta_log_p(wn, n=n_u+1) - sg.ntemplates_sta_log_p(wn, n=n_u)


    deassociation_ratio_log = unass_lp + ntemplates_ratio_log

    signal_lp_with_template = wn.log_p()

    signal_lp_without_template = wn.log_p(arrivals=arrivals)
    deletion_ratio_log = signal_lp_without_template - signal_lp_with_template

    log_normalizer = np.logaddexp(deassociation_ratio_log, deletion_ratio_log)

    # smooth the probabilities so we always give at least some
    # probability to each option (needed in order for reverse proposal
    # probabilities to be reasonable)
    adj = min_logprob + log_normalizer
    deassociation_ratio_log = np.logaddexp(deassociation_ratio_log, adj)
    deletion_ratio_log = np.logaddexp(deletion_ratio_log, adj)
    log_normalizer = np.logaddexp(log_normalizer, np.log(2) + adj)

    if deletion_prob:
        return deletion_ratio_log - log_normalizer
    else:
        return deassociation_ratio_log - log_normalizer

def sample_deassociation_proposal(sg, wn, eid, phase, fix_result=None):
    lp = deassociation_logprob(sg, wn, eid, phase)
    if fix_result is not None:
        deassociate = fix_result
    else:
        u = np.random.rand()
        deassociate = u < np.exp(lp)
    deassociate_lp = lp if deassociate else np.log(1-np.exp(lp))
    return deassociate, deassociate_lp

def correlation_atime_ll(sg, wn, tmvals, eid, phase, prebirth_unexplained):

    (start_idxs, end_idxs, identities, basis_prototypes, level_sizes, n_steps) = wn.wavelet_basis
    tg = sg.template_generator("P")

    wn._set_cssm_priors_from_model(arrivals=[(eid, phase)])
    cssm = wn.arrival_ssms[(eid, phase)]

    pred_wavelet = cssm.mean_obs(n_steps)

    sg.debug_dists[wn.label]["pred_wavelet"] = pred_wavelet
    env = np.exp(tg.abstract_logenv_raw(tmvals, srate=wn.srate, fixedlen=n_steps))
    pred_signal = pred_wavelet * env
    sg.debug_dists[wn.label]["pred_signal"] = pred_wavelet
    ll = ar_advantage(prebirth_unexplained, pred_signal, wn.nm)

    return ll

def get_env_based_amplitude_distribution3(sg, wn, eid, phase, prior_min, prior_max, prior_dist, tmvals, unexplained):

    # propose from a linearly interpolated version of the posterior density,
    # using a very close approximation to the posterior, i.e. we actually
    # run the full signal probability calculations for each candidate amplitude. 


    atime = tmvals['arrival_time']
    ev_offset_idx = int(5*wn.srate)
    start_idx_true = int((atime - wn.st) * wn.srate) - ev_offset_idx
    end_idx_true = int(start_idx_true + 60*wn.srate)
    start_idx = max(0, start_idx_true)
    end_idx = min(wn.npts, end_idx_true)
    start_offset = start_idx - start_idx_true
    end_offset = start_offset + (end_idx - start_idx)
    if end_idx-start_idx < wn.srate:
        # if less than 1s of available signal, don't even bother
        return None

    unexplained_local = unexplained[start_idx:end_idx]
    n = len(unexplained_local)

    env_height = np.max(np.abs(unexplained_local))

    data_min = np.log(env_height) - 2
    data_max = np.log(env_height) + 2
    prior_min = min(prior_min, 1)
    prior_max = max(prior_max, prior_min+1, -2)
    if np.isfinite(data_min):
        min_c = min(data_min, prior_min)
        max_c = max(data_max, prior_max)
        candidates = np.linspace(max(min_c, -5), min(max_c, 5), 20)
        candidates = np.array(sorted(list(candidates) + [np.log(env_height), np.log(env_height+wn.nm_env.c)]))
    else:
        candidates = np.linspace(max(prior_min, -4),  min(prior_max, 5), 20)
        

    provided_coda_height = tmvals['coda_height']
    tg = sg.template_generator("P")
    lps = []

    """
    want to model what happens to the signal between start_idx_true and end_idx_true.
    the event starts at ev_offset_idx.
    the cssm generates signal of len n_steps
    """

    (start_idxs, end_idxs, identities, basis_prototypes, level_sizes, n_steps) = wn.wavelet_basis
    wn._set_cssm_priors_from_model(arrivals=[(eid, phase)])
    cssm = wn.arrival_ssms[(eid, phase)] 
    modeled_npts = end_idx_true-start_idx_true

    d = np.ones((end_idx_true-start_idx_true,))*np.nan
    v = wn.get_value()
    d[start_offset:end_offset] = v[start_idx:end_idx]
    def proxylp(candidate):
        tmvals['coda_height'] = candidate
        l = tg.abstract_logenv_raw(tmvals, srate=wn.srate, fixedlen=end_idx_true-start_idx_true + ev_offset_idx)
        env = np.exp(l)
        components = [(wn.noise_arssm, 0, end_idx_true-start_idx_true, None)]
        components.append((cssm, ev_offset_idx, n_steps, env))
        components.append((wn.iid_arssm, ev_offset_idx+n_steps, len(env) - n_steps, env[n_steps:]))
        tssm = TransientCombinedSSM(components, 1e-6)
        lp = tssm.run_filter(d)
        return lp + prior_dist.log_p(candidate)

    lps = np.array([proxylp(candidate) for candidate in candidates])

    def bad_indices(lps):
        best_idx = np.argmax(lps)
        best_lp = np.max(lps)
        lp_diff = np.abs(np.diff(lps))

        thresh = best_lp - 3
        significant_lps = ( lps[:-1] > thresh ) +  ( lps[1:] > thresh )
        badsteps = significant_lps * (lp_diff > 1)
        bad_idxs = np.arange(len(lps)-1)[badsteps]
        return bad_idxs

    bad_idxs = bad_indices(lps)
    while len(bad_idxs) > 0:
        new_candidates = []
        new_lps = []
        for idx in bad_idxs:
            c1 = candidates[idx]
            c2 = candidates[idx+1]
            c = c1 + (c2-c1)/2.0
            new_candidates.append(c)
            new_lps.append( proxylp(c))
        full_c = np.concatenate((candidates, new_candidates))
        full_lps = np.concatenate((lps, new_lps))
        perm = sorted(np.arange(len(full_c)), key = lambda i : full_c[i])
        candidates = np.array(full_c[perm])
        lps = np.array(full_lps[perm])
        bad_idxs = bad_indices(lps)

    assert( (np.diff(candidates) > 0).all() )

    tmvals['coda_height'] = provided_coda_height
    p = PiecewiseLinear(candidates, np.array(lps))

    return p


def smart_peak_time_proposal(sg, wn, tmvals, eid, phase, pred_atime, 
                             prebirth_unexplained=None, 
                             use_correlation=False, 
                             exclude_arrs=[], 
                             fix_result=None):
    # instead of sampling arrival time from the prior, sample
    # from the product of the prior with unexplained signal mass
    ptime = np.exp(tmvals['peak_offset'])
    pidx = int(np.round(ptime * wn.srate))
    discrete_ptime = float(pidx) / wn.srate


    # consider using a vague travel-time prior to
    # acknowldege the possibility that the event is not currently
    # in the correct location
    #tt_spread = np.random.choice((2.0, 10.0, 30.0, 80.0))
    tt_spread = 3.0

    t = np.linspace(wn.st - discrete_ptime, wn.et-discrete_ptime, wn.npts)
    atime_prior = np.exp(-np.abs(t - pred_atime)/tt_spread)
    hard_cutoff = np.abs(t-pred_atime) < 25
    atime_prior *= hard_cutoff
    arrivals = wn.arrivals()

    # naively, env_diff_pos starts at wn.st and gives probabilities of peak times.
    # but we can interpret it as giving probabilities of arrival times, starting
    # at wn.st - discrete_ptime. 
    # this will align better with the atime-based correlation proposal. 
    other_arrivals = [a for a in arrivals if a not in exclude_arrs]
    env_diff_pos = get_env_diff_positive_part(wn, other_arrivals) + wn.nm_env.c

    # control dynamic range of env_diff_pos_distribution: 
    # don't disrupt the prior by more than 3 nats
    max_edp =  np.max(env_diff_pos)
    if max_edp > 3:
        env_diff_pos /= (max_edp/3.0)

    if use_correlation and prebirth_unexplained is not None:
        try:
            sg.debug_dists
        except:
            sg.debug_dists = {}
        sg.debug_dists[wn.label] = {}


        sg.debug_dists[wn.label]["prior"] = atime_prior.copy()
        sg.debug_dists[wn.label]["env_diff_pos"] = env_diff_pos
        pred_env = wn.assem_env(arrivals=other_arrivals)
        env = wn.get_env().data
        ed = env - pred_env
        sg.debug_dists[wn.label]["env_diff"] = ed


        pbu = prebirth_unexplained[wn.label]
        sg.debug_dists[wn.label]["unexplained"] = pbu.copy()
        try:
            atime_ll = correlation_atime_ll(sg, wn, tmvals, eid, phase, pbu)
        except KeyError:
            # if the wn does not have an arrival from this eid, phase,
            # then we can't do a data-driven propsal
            atime_ll = np.zeros(env_diff_pos.shape)

        maxll = np.max(atime_ll)
        # temper atime_ll to have dynamic range of 10 nats, so it doesn't overwhelm the prior
        if maxll > 5:
            atime_ll /= maxll/5.0
            maxll = 5
        sg.debug_dists[wn.label]["atime_ll"] = atime_ll

        sidx = pidx
        eidx = len(atime_ll) 
        atime_prior[sidx:eidx] *= np.exp(atime_ll[:-pidx] - maxll)
        atime_prior[:sidx] *= np.exp(-maxll)
        atime_prior[eidx:] *= np.exp(-maxll)


        atime_pdf = merge_distribution(env_diff_pos, atime_prior, smoothing=3, return_pdf=True, peak_detect=False)
        sg.debug_dists[wn.label]["final"] = atime_pdf

    else:
        atime_pdf = merge_distribution(env_diff_pos, atime_prior, smoothing=3, return_pdf=True)

    atime_cdf = preprocess_signal_for_sampling(atime_pdf)


    if not fix_result:

        if np.sum(atime_prior)==0:
            # if the window doesn't contain signal near the predicted arrival time,
            # we can't do a data-driven proposal, so just sample from (something like)
            # the prior
            atime_dist = Laplacian(pred_atime, tt_spread)
            proposed_atime = atime_dist.sample()
            atime_lp = atime_dist.log_p(proposed_atime)
        else:
            proposed_atime, atime_lp = sample_peak_time_from_cdf(atime_cdf, wn.st-discrete_ptime, wn.srate, return_lp=True)
            #idx = int(np.floor((proposed_atime - (wn.st-discrete_ptime)) * wn.srate +.00001)) + 1
            #print "atime idx", idx, "lp",  np.log(atime_cdf[idx] - atime_cdf[idx-1]), "actual lp", atime_lp


        proposed_tt_residual = proposed_atime - pred_atime

        tmvals["tt_residual"] = proposed_tt_residual
        tmvals["arrival_time"] = proposed_atime

        assert(not np.isnan(atime_lp))
        return atime_lp
    else:
        atime = tmvals["arrival_time"] 
        if np.sum(atime_prior)==0:
            atime_dist = Laplacian(pred_atime, tt_spread)
            atime_lp = atime_dist.log_p(atime)
        else:
            atime_lp = peak_log_p(atime_cdf, wn.st-discrete_ptime, wn.srate, atime)
            #idx = int(np.floor((atime - (wn.st-discrete_ptime)) * wn.srate +.00001)) + 1
            #print "atime idx", idx, "lp",  np.log(atime_cdf[idx] - atime_cdf[idx-1])

        #print "atime_lp is", atime_lp, "for", atime
        assert(not np.isnan(atime_lp))
        return atime_lp


def heuristic_amplitude_posterior(sg, wn, tmvals, eid, phase, debug=False, exclude_arrs = [], unexplained=None, full_tssm_proposal=False):
    """
    Construct an amplitude proposal distribution by combining the env likelihood with
    the prior conditioned on the event location.

    This is especially necessary when proposing phases that don't appear to be
    present in the signal (i.e., are below the noise floor). If the prior predicts
    a log-amplitude of -28, and the likelihood predicts a log-amplitude of -4 (because
    it's impossible for the likelihood to distinguish amplitudes below the noise floor), then
    proposals from the likelihood alone would ultimately be rejected.

    """


    k_ampt = create_key("amp_transfer", eid=eid, sta=wn.sta, chan=":", band=":", phase=phase)
    try:
        n_ampt = sg.all_nodes[k_ampt]
    except:
        import pdb; pdb.set_trace()

    ev = sg.get_event(eid)
    source_amp = brune.source_logamp(ev.mb, phase=phase, band=wn.band)

    prior_mean = float(n_ampt.model.predict(cond=n_ampt._parent_values())) + source_amp
    prior_var = float(n_ampt.model.variance(cond=n_ampt._parent_values(), include_obs=True))
    prior_std = np.sqrt(prior_var)
    prior_dist = Gaussian(prior_mean, prior_std)

    prior_min = prior_mean - 3*prior_std
    prior_max = prior_mean + 3*prior_std

    if full_tssm_proposal:
        amp_dist_env = get_env_based_amplitude_distribution3(sg, wn, eid, phase,
                                                             prior_min=prior_min, 
                                                             prior_max=prior_max, 
                                                             prior_dist=prior_dist, 
                                                             tmvals=tmvals, 
                                                             unexplained=unexplained[wn.label])
    else:
        amp_dist_env = get_env_based_amplitude_distribution2(sg, wn, 
                                                             prior_min=prior_min, 
                                                             prior_max=prior_max, 
                                                             prior_dist=prior_dist, 
                                                             tmvals=tmvals, 
                                                             exclude_arrs=exclude_arrs)
    return amp_dist_env


def heuristic_amplitude_posterior_old(sg, wn, tmvals, eid, phase, debug=False):
    """
    Construct an amplitude proposal distribution by combining the env likelihood with
    the prior conditioned on the event location.

    This is especially necessary when proposing phases that don't appear to be
    present in the signal (i.e., are below the noise floor). If the prior predicts
    a log-amplitude of -28, and the likelihood predicts a log-amplitude of -4 (because
    it's impossible for the likelihood to distinguish amplitudes below the noise floor), then
    proposals from the likelihood alone would ultimately be rejected.

    """

    amp_dist_env = get_env_based_amplitude_distribution(sg, wn, tmvals, exclude_arr=(eid, phase))

    k_ampt = create_key("amp_transfer", eid=eid, sta=wn.sta, chan=":", band=":", phase=phase)
    try:
        n_ampt = sg.all_nodes[k_ampt]
    except:
        import pdb; pdb.set_trace()

    ev = sg.get_event(eid)
    source_amp = brune.source_logamp(ev.mb, phase=phase, band=wn.band)

    prior_mean = float(n_ampt.model.predict(cond=n_ampt._parent_values())) + source_amp
    prior_var = float(n_ampt.model.variance(cond=n_ampt._parent_values(), include_obs=True))
    prior_dist = Gaussian(prior_mean, np.sqrt(prior_var))

    if debug:
        import pdb; pdb.set_trace()

    if amp_dist_env is None:
        return prior_dist

    if amp_dist_env.mean < np.log(wn.nm_env.c):
        # the Gaussian model of log-amplitude isn't very good at the noise floor
        # (it should really be a model of non-log amplitude, since noise is additive).
        # so we hack in some special cases:
        # TODO: find a better solution here.

        if prior_mean < amp_dist_env.mean:
            # if the prior thinks the env needs to be *really* small, vs just kind of small,
            # we believe the prior. Since we're proposing below the noise floor, our proposal
            # won't affect env probabilities anyway, so we should just maximize probability
            # under the prior.
            heuristic_posterior = prior_dist
        #elif prior_mean > np.log(wn.nm_env.c) + 2:
            # if the prior thinks there *should* be a visible arrival
            # here, but that's not supported by the env, we propose
            # to fit the env (paying the cost under the prior) since
            # this is almost certainly cheaper than believing the prior
            # at the cost of not fitting the env.
        else:
            #heuristic_posterior = amp_dist_env
            heuristic_posterior = Gaussian(-5, 1.0)
        #else:
        #    heuristic_posterior = amp_dist_env.product(prior_dist)
    else:
        # otherwise, combine the likelihood and prior for a heuristic posterior
        heuristic_posterior = amp_dist_env.product(prior_dist)
    #heuristic_posterior = Gaussian(-2.0, 0.5)


    #nstd = np.sqrt(wn.nm_env.marginal_variance())


    return heuristic_posterior

def propose_phase_template(sg, wn, eid, phase, tmvals=None, 
                           smart_peak_time=True, use_correlation=False,
                           include_presampled=True,
                           prebirth_unexplained=None, 
                           fix_result=False, ev=None, 
                           exclude_arrs=[]):
    # sample a set of params for a phase template from an appropriate distribution (as described above).
    # return as an array.

    # we assume that add_event already sampled all the params parent-conditionally
    if tmvals is None:
        tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)

    if ev is None:
        ev = sg.get_event(eid)


    if use_correlation:
        uas = [(e, p) for (e, p) in wn.arrivals() if p=="UA"]
        exclude_arrs = uas + exclude_arrs
    exclude_arrs = [(eid, phase)] + exclude_arrs
    exclude_arrs = list(set(exclude_arrs))

    pred_atime = ev.time + tt_predict(ev, wn.sta, phase)
    lp = 0
    if smart_peak_time:
        peak_lp = smart_peak_time_proposal(sg, wn, tmvals, eid, phase, 
                                           pred_atime, 
                                           use_correlation=use_correlation,
                                           prebirth_unexplained=prebirth_unexplained,
                                           exclude_arrs=exclude_arrs,
                                           fix_result=fix_result)

        lp += peak_lp
        print "peak_lp", peak_lp
        try:
            proposed_tt_residual = tmvals["tt_residual"]
        except KeyError:
            proposed_tt_residual = None
        proposed_atime = tmvals["arrival_time"]

    
    amp_dist = heuristic_amplitude_posterior(sg, wn, tmvals, eid, phase, exclude_arrs=exclude_arrs, unexplained = prebirth_unexplained, full_tssm_proposal=use_correlation)

    if 'amp_transfer' in tmvals:
        del tmvals['amp_transfer']

    if smart_peak_time:
        if "tt_residual" in tmvals:
            del tmvals["tt_residual"]
        del tmvals["arrival_time"]

    if amp_dist is not None:

        if fix_result:
            amplitude = tmvals["coda_height"]
        else:
            amplitude = amp_dist.sample()
        del tmvals['coda_height']

        # compute log-prob of non-amplitude parameters
        if include_presampled:
            param_lp = ev_phase_template_logprob(sg, wn, eid, phase, tmvals)
            print "param_lp", param_lp
            lp += param_lp

        tmvals['coda_height'] = amplitude
        amp_lp = amp_dist.log_p(amplitude)
        lp += amp_lp
        print "amp_lp", amp_lp
    else:
        if include_presampled:
            lp += ev_phase_template_logprob(sg, wn, eid, phase, tmvals)
        else:
            print "WARNING: no amp_dist to compute amplitude probability from, inference is incorrect"

    if smart_peak_time:
        if proposed_tt_residual is not None:
            tmvals["tt_residual"] = proposed_tt_residual
        
        tmvals["arrival_time"] = proposed_atime

    if np.isnan(np.array(tmvals.values(), dtype=float)).any():
        raise ValueError()
    assert(not np.isnan(lp))

    if fix_result:
        return lp
    else:
        return tmvals, lp

#########################################################################################

def death_proposal_log_ratio(sg, eid):
    lp_unass = 0
    lp_ev = 0

    ev = sg.get_event(eid)
    eid = ev.eid

    for (site, elements) in sg.site_elements.items():
        for sta in elements:
            for wn in sg.station_waves[sta]:
                for phase in sg.ev_arriving_phases(eid, sta):
                    tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)

                    lp_unass_tmpl = unass_template_logprob(sg, wn, tmvals)
                    lp_ev_tmpl = ev_phase_template_logprob(sg, wn, eid, phase, tmvals)
                    #print "ev tmpl prob", sta, phase, eid, lp_ev_tmpl

                    lp_unass += lp_unass_tmpl
                    lp_ev += lp_ev_tmpl
    r = lp_unass - lp_ev
    assert(np.isfinite(r))
    return r

def death_proposal_distribution(sg):
    c = Counter()
    for eid in sg.evnodes.keys():
        if eid in sg.fixed_events: continue
        c[eid] = death_proposal_log_ratio(sg, eid)

    c.normalize_from_logs()


    # with probability ~.1, just sample an event uniformly.
    # this way all events have some possibility to die.
    for k in c.keys():
        if np.isfinite(c[k]):
            c[k] += .1/len(c)
        else:
            c[k] = .1/len(c)
    c.normalize()

    return c

def sample_death_proposal(sg):
    c = death_proposal_distribution(sg)
    if len(c) == 0:
        return None, 1.0
    eid = c.sample()
    return eid, np.log(c[eid])

def death_proposal_logprob(sg, eid):
    c = death_proposal_distribution(sg)
    if len(c) == 0:
        return 1.0
    lp = np.log(c[eid])
    #assert(np.isfinite(lp))
    return lp


def ev_death_helper(sg, eid, use_correlation=False, associate_using_mb=True, fix_result=None):

    # fix_result is a dict mapping (wn, phase) -> (disassociated, tmvals)

    ev = sg.get_event(eid)

    next_uatemplateid = sg.next_uatemplateid

    move_logprob = 0
    reverse_logprob = 0

    forward_fns = []
    inverse_fns = []
    inverse_fns.append(lambda : sg.add_event(ev, eid=eid))

    tmids = []
    tmid_i = 0

    death_record = {}

    for elements in sg.site_elements.values():
        for sta in elements:
            for wn in sg.station_waves[sta]:

                s = Sigvisa()
                site = s.get_array_site(sta)
                template_param_array = None
                for phase in sg.ev_arriving_phases(eid, sta):
                    #if (eid, phase) not in wn.arrivals():
                    #    continue

                    if fix_result is not None:
                        deassociate, fixed_tmvals = fix_result[(wn, phase)]
                    else:
                        deassociate = None
                        fixed_tmvals = None
                    deassociate, deassociate_logprob = sample_deassociation_proposal(sg, wn, eid, phase, fix_result = deassociate)

                    move_logprob += deassociate_logprob

                    if deassociate:
                        # deassociation will produce a new uatemplated
                        # with incrementing tmid. We keep track of this
                        # tmid (kind of a hack) to ensure that we
                        # reassociate the same template if the move gets
                        # rejected.
                        forward_fns.append(lambda wn=wn,phase=phase: tmids.append(unassociate_template(sg, wn, eid, phase)))
                        inverse_fns.append(lambda wn=wn,phase=phase,tmid_i=tmid_i: associate_template(sg, wn, tmids[tmid_i], eid, phase))

                        print "proposing to deassociate at %s (lp %.1f)" % (sta, deassociate_logprob)
                        if use_correlation:
                            # since the correlation birth move can propose new atimes/amps for uatemplates, 
                            # the death move needs to be able to reverse these changes. so we 
                            # propose a new atime/amp conditioned on the event we're about to kill
                            # (on the grounds that since the template we're trying to reproduce was
                            # chosen to associate to this event, its parameters must be likely under
                            # that distribution).
                            
                            if fix_result is not None:
                                tmpl_lp = propose_phase_template(sg, wn, eid, phase, 
                                                                 use_correlation=False, 
                                                                 include_presampled=False,
                                                                 tmvals = fixed_tmvals,
                                                                 fix_result=True)
                                #print "fixed death reproposal", fixed_tmvals, tmpl_lp
                            else:
                                tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
                                tmvals, tmpl_lp = propose_phase_template(sg, wn, eid, phase, 
                                                                         use_correlation=False, 
                                                                         include_presampled=False,
                                                                         tmvals = tmvals,
                                                                         fix_result=False)
                                #print "live death reproposal", tmvals, tmpl_lp

                                # after we unassociate the template from the event, we'll set its
                                # values to our proposed ones. 
                                forward_fns.append(lambda wn=wn,phase=phase,tmvals=tmvals,tmid_i=tmid_i : sg.set_template(-tmids[tmid_i], wn.sta, "UA", wn.band, wn.chan, tmvals))

                                # to reverse this operation, we set the template to its original (associated)
                                # params. 
                                template_param_array = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
                                inverse_fns.append(lambda wn=wn,phase=phase,template_param_array=template_param_array : sg.set_template(eid,wn.sta, phase, wn.band, wn.chan, template_param_array))


                            move_logprob += tmpl_lp

                    else:
                        if fix_result is not None:
                            template_param_array = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
                            inverse_fns.append(lambda wn=wn,phase=phase,template_param_array=template_param_array : sg.set_template(eid,wn.sta, phase, wn.band, wn.chan, template_param_array))
                            print "proposing to delete at %s (lp %f)"% (sta, deassociate_logprob)
                            
                    death_record[(wn, phase)] = (deassociate, template_param_array, tmid_i)
                    #deassociations.append((wn, phase, deassociate, tmid_i, template_param_array))
                    if deassociate:
                        tmid_i += 1

    if fix_result is not None:
        return move_logprob

    # order of operations:
    # first, deassociate the templates we need to deassociate
    # second, calculate probabilities of re-associating them to the event (while it's still around)
    # finally, kill the event
    for fn in forward_fns:
        fn()
    sg._topo_sort()
    
    # now that the forward_fns have built up the list of tmids for dissassociated arrivals,
    # we can update our records to replace the actual tmids. 
    canonicalized_death_record = {}
    for k, (deassociate, template_param_array, tmid_i) in death_record.items():
        canonicalized_death_record[k] = (deassociate, template_param_array, 
                                         tmids[tmid_i] if deassociate else None)

    reverse_logprob = ev_birth_helper(sg, ev, use_correlation=use_correlation, 
                                      associate_using_mb=associate_using_mb, eid=eid,
                                      fix_result=canonicalized_death_record)

    sg.remove_event(eid)

    def revert_move():
        for fn in inverse_fns:
            fn()
        sg._topo_sort()
        sg.next_uatemplateid = next_uatemplateid

    return move_logprob, reverse_logprob, revert_move



def ev_death_helper_full(sg, eid, location_proposal, proposal_includes_mb=False, use_correlation=False):
    ev = sg.get_event(eid)
    if not proposal_includes_mb:
        lqb, reset_coda_heights = propose_mb(sg, eid, fix_result=ev.mb)
        sg.evnodes[eid]["mb"].set_value(4.0)
        reset_coda_heights()
    else:
        lqb = 0.0

    log_qforward, log_qbackward, revert_move = ev_death_helper(sg, eid, associate_using_mb=False, use_correlation=use_correlation)
    #try:
    lp_loc = location_proposal(sg, fix_result=ev)
    print "death helper", lqb, log_qbackward, lp_loc
    #except Exception as e:
    #    print "exception in birth probability evaluation: ", e
    #    lp_loc = -np.inf

    def revert():
        revert_move()
        if not proposal_includes_mb:
            sg.evnodes[eid]["mb"].set_value(ev.mb)
            reset_coda_heights()

    return log_qforward, lqb + log_qbackward + lp_loc, revert

def ev_death_move_abstract(sg, location_proposal, log_to_run_dir=None, force_outcome=None, **kwargs):
    eid, eid_logprob = sample_death_proposal(sg)
    if eid is None:
        return False
    move_logprob = eid_logprob
    n_current_events = len(sg.evnodes) - len(sg.fixed_events)
    reverse_logprob = -np.log(n_current_events) # this accounts for the different "positions" we can birth an event into

    lp_old = sg.current_log_p()
    log_qforward, log_qbackward, revert_move = ev_death_helper_full(sg, eid, location_proposal, **kwargs)
    lp_new = sg.current_log_p()


    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "hough_proposals.txt")

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write("acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            for (wn, phase), (assoc, tmvals) in associations.items():
                if assoc:
                    f.write(" associated %s at %s, %s, %s\n" % (phase, wn.sta, wn.chan, wn.band))
            f.write("\n")


    log_qforward += move_logprob
    log_qbackward += reverse_logprob

    print "death move acceptance", (lp_new + log_qbackward) - (lp_old+log_qforward), "from", lp_old, lp_new, log_qbackward, log_qforward



    return mh_accept_util(lp_old, lp_new, log_qforward, log_qbackward, accept_move=None, revert_move=revert_move, force_outcome=force_outcome)

def ev_death_move_hough(sg, hough_kwargs={}, **kwargs):
    def hlp(sg, fix_result=None, **kwargs):
        kwargs.update(hough_kwargs)
        return hough_location_proposal(sg, fix_result=fix_result, **kwargs)
    return ev_death_move_abstract(sg, hlp, proposal_includes_mb=True, **kwargs)


def ev_death_move_hough_offset(sg, **kwargs):
    hough_kwargs = {"offset": True}
    return ev_death_move_hough(sg, hough_kwargs, **kwargs)

def ev_death_move_hough_oes(sg, **kwargs):
    hough_kwargs = {"one_event_semantics": True}
    return ev_death_move_hough(sg, hough_kwargs, **kwargs)

def ev_death_move_hough_oes_offset(sg, **kwargs):
    hough_kwargs = {"one_event_semantics": True, "offset": True}
    return ev_death_move_hough(sg, hough_kwargs, **kwargs)

def ev_death_move_correlation(sg, **kwargs):
    return ev_death_move_abstract(sg, correlation_location_proposal, proposal_includes_mb=False, **kwargs)

def ev_death_move_cheating(sg, **kwargs):
    return ev_death_move_abstract(sg, cheating_location_proposal, proposal_includes_mb=True, **kwargs)


def ev_death_move_lstsqr(sg, **kwargs):
    return ev_death_move_abstract(sg, overpropose_new_locations, **kwargs)

##########################################################################################

def ev_birth_helper(sg, proposed_ev, use_correlation=False, 
                            associate_using_mb=True, eid=None,
                            fix_result=None):
    forward_fns = []
    inverse_fns = []
    birth_record = {}

    prebirth_unexplained = None
    if use_correlation:
        if fix_result:
            exclude_eids = [eid,]
        else:
            exclude_eids = []
        prebirth_unexplained = {}
        for sta, wns in sg.station_waves.items():
            for wn in wns:
                prebirth_unexplained[wn.label] = wn.unexplained_kalman(exclude_eids=exclude_eids)

    # add an event, WITH all its template nodes initialized to parent-sampled values.
    # we need to replace these values before computing any signal-based probabilities.
    # luckily,
    if fix_result is None:
        evnodes = sg.add_event(proposed_ev, sample_templates=True, eid=eid)
        eid = evnodes['mb'].eid

    # loop over phase arrivals at each station and propose either
    # associating an existing unass. template with the new event, or
    # creating a new template.
    # don't modify the graph, but generate a list of functions
    # to execute the forward and reverse moves
    log_qforward = 0
    for site,elements in sg.site_elements.items():
        site_phases = sg.predict_phases_site(proposed_ev, site=site)
        for sta in elements:
            for wn in sg.station_waves[sta]:

                s = Sigvisa()
                site = s.get_array_site(sta)
                band, chan = wn.band, wn.chan

                proposed_tmids = set()
                for phase in site_phases:
                    #if (eid, phase) not in wn.arrivals():
                    #    continue

                    # we should really do the associations one-by-one,
                    # instead of just keeping a list of tmids we've
                    # proposed to associate and then doing it all at the
                    # end.as it currently stands the death move doesn't
                    # quite compute the correct reverse probabilities.

                    if fix_result is not None:
                        deassociate, fixed_tmvals, fixed_tmid = fix_result[(wn, phase)]
                        if not deassociate:
                            fixed_tmid = None
                    else:
                        fixed_tmid = None
                    tmid, assoc_logprob = sample_template_to_associate(sg, wn, eid, phase, 
                                                                       ignore_mb=not associate_using_mb, 
                                                                       forbidden=proposed_tmids,
                                                                       fix_result=fixed_tmid)

                    if tmid is not None:
                        forward_fns.append(lambda wn=wn,phase=phase,tmid=tmid: associate_template(sg, wn, tmid, eid, phase))
                        inverse_fns.append(lambda wn=wn,phase=phase,tmid=tmid: unassociate_template(sg, wn, eid, phase, tmid=tmid))
                        proposed_tmids.add(tmid)
                        print "proposing to associate template %d at %s,%s with assoc lp %.1f" % (tmid, wn.sta, phase, assoc_logprob)

                    tmpl_lp  = 0.0
                    tmvals = None
                    tmvals_old = None
                    if tmid is None or use_correlation:
                        exclude_arrs = []
                        if tmid is not None:
                            tmvals_old = sg.get_template_vals(-tmid, wn.sta, "UA", wn.band, wn.chan)
                            inverse_fns.append(lambda wn=wn,phase=phase,tmvals=tmvals_old : sg.set_template(-tmid, wn.sta, "UA", wn.band, wn.chan, tmvals))

                            exclude_arrs = [(-tmid, "UA")]                            

                        if fix_result is not None:
                            #print "fix result: tmpl lp %f for %s, %s" % (tmpl_lp, tmid, fixed_tmvals)
                            tmpl_lp = \
                                 propose_phase_template(sg, wn, eid, phase, 
                                                        use_correlation=use_correlation, 
                                                        prebirth_unexplained=prebirth_unexplained, 
                                                        include_presampled = (tmid is None), 
                                                        tmvals = fixed_tmvals, 
                                                        exclude_arrs=exclude_arrs,
                                                        fix_result=True)
                            #print "fix result: tmpl lp %f for %s, %s" % (tmpl_lp, tmid, fixed_tmvals)
                        else:
                            if tmid is None:
                                # we are birthing anew, so use the parent-conditional event template
                                tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
                            else:
                                # we are modifying an existing template, so use those values
                                tmvals = sg.get_template_vals(-tmid, wn.sta, "UA", wn.band, wn.chan)

                            tmvals, tmpl_lp = \
                                 propose_phase_template(sg, wn, eid, phase, 
                                                        use_correlation=use_correlation, 
                                                        prebirth_unexplained=prebirth_unexplained, 
                                                        include_presampled = (tmid is None), 
                                                        tmvals = tmvals, 
                                                        exclude_arrs=exclude_arrs,
                                                        fix_result=False)
                            #print "true birth: tmpl lp %f for %s, %s" % (tmpl_lp, tmid, tmvals)
                            #print "proposed values", tmvals
                            if np.isnan(np.array(tmvals.values(), dtype=float)).any():
                                raise ValueError()
                            forward_fns.append(lambda wn=wn,phase=phase,tmvals=tmvals : sg.set_template(eid, wn.sta, phase, wn.band, wn.chan, tmvals))
                        print "proposing to birth new phase %s,%s with assoc lp %.1f tmpl lp %f" % (sta, phase, assoc_logprob, tmpl_lp)
                    
                    birth_record[(wn, phase)] = (tmid is not None, tmvals_old)
                    sta_phase_logprob = assoc_logprob + tmpl_lp
                    log_qforward += sta_phase_logprob
                    print "birth qforward + ", assoc_logprob, tmpl_lp, "=", log_qforward

    if fix_result is not None:
        return log_qforward

    inverse_fns.append(lambda : sg.remove_event(eid))

    # execute all the forward moves
    for fn in forward_fns:
        fn()
    sg._topo_sort()

    log_qbackward = ev_death_helper(sg, eid, use_correlation=use_correlation, associate_using_mb=associate_using_mb, fix_result=birth_record)

    def revert_move():
        for fn in inverse_fns:
            fn()

    return log_qforward, log_qbackward, revert_move, eid, birth_record
    


def ev_birth_helper_full(sg, location_proposal, eid=None, proposal_includes_mb=True, use_correlation=False):
    # propose a new ev location
    #try:
    ev, lp_loc, extra = location_proposal(sg)
    if ev is None:
        return 0, 0, None, None

    print "proposing new ev", ev


        

    #except Exception as e:
    #    print "exception in birth proposal", e
    #    def noop(): pass
    #    return -np.inf, 0.0, noop, (None, 0, [])

    # propose its associations
    log_qforward, log_qbackward, revert_move, eid, associations = ev_birth_helper(sg, ev, associate_using_mb=proposal_includes_mb, eid=eid, use_correlation=use_correlation)

    # propose its magnitude
    if not proposal_includes_mb:
        lqf = propose_mb(sg, eid)
    else:
        lqf = 0

    print "birth helper", lqf, log_qforward, lp_loc, log_qbackward

    return lp_loc + log_qforward + lqf, log_qbackward, revert_move, (extra, eid, associations)

def ev_birth_move_abstract(sg, location_proposal, revert_action=None, accept_action=None, force_outcome=None, **kwargs):

    n_current_events = len(sg.evnodes) - len(sg.fixed_events)
    birth_position_lp = -np.log(n_current_events+1) # we imagine there are n+1 "positions" we can birth an event into

    lp_old = sg.current_log_p()
    

    #wn_logps_1 = dict([(sta, wn.log_p()) for (sta, wns) in sg.station_waves.items() for wn in wns])
    sg.current_log_p_breakdown()
    log_qforward, log_qbackward, revert_move, proposal_extra = ev_birth_helper_full(sg, location_proposal, **kwargs)
    if revert_move is None:
        # location proposal did not return an event
        return False

    lp_new = sg.current_log_p()

    #wn_logps_2 = dict([(sta, wn.log_p()) for (sta, wns) in sg.station_waves.items() for wn in wns])

    (extra, eid, associations) = proposal_extra

    log_qforward += birth_position_lp
    log_qbackward += death_proposal_logprob(sg, eid)

    sg.current_log_p_breakdown()

    def revert():
        if revert_action is not None:
            revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        revert_move()

    def accept():
        if accept_action is not None:
            accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    print "birth move acceptance", (lp_new + log_qbackward) - (lp_old+log_qforward), "from", lp_old, lp_new, log_qbackward, log_qforward


    return mh_accept_util(lp_old, lp_new, log_qforward, log_qbackward, accept_move=accept, revert_move=revert, force_outcome=force_outcome)

def ev_birth_move_hough(sg, log_to_run_dir=None, hough_kwargs = {}, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "hough_proposals.txt")

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write(" hough args %s\n" % repr(hough_kwargs))
            f.write(" acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            for (wn, phase), (assoc, tmvals) in associations.items():
                if assoc:
                    f.write(" associated %s at %s, %s, %s\n" % (phase, wn.sta, wn.chan, wn.band))
            f.write("\n")

    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        if np.random.rand() < 0.1:
            sites = sg.site_elements.keys()
            print "saving hough array picture...",
            fname = 'last_hough%s.png' % ("_".join(["",] + hough_kwargs.keys()))
            visualize_hough_array(hough_array, sites, os.path.join(log_to_run_dir, fname), region=sg.inference_region)
            print "done"

    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        if log_to_run_dir is not None:
            log_event_birth(sg, hough_array, log_to_run_dir, eid, associations)
        else:
            raise Exception("why are we not logging?")

    def hlp(sg, **kwargs):
        kwargs.update(hough_kwargs)
        return hough_location_proposal(sg, **kwargs)

    return ev_birth_move_abstract(sg, location_proposal=hlp, revert_action=revert_action, accept_action=accept_action, proposal_includes_mb=True, **kwargs)


def ev_birth_move_hough_offset(sg, **kwargs):
    hough_kwargs = {"offset": True}
    return ev_birth_move_hough(sg, hough_kwargs=hough_kwargs, **kwargs)

def ev_birth_move_hough_oes(sg, **kwargs):
    hough_kwargs = {"one_event_semantics": True}
    return ev_birth_move_hough(sg, hough_kwargs=hough_kwargs, **kwargs)

def ev_birth_move_hough_oes_offset(sg, **kwargs):
    hough_kwargs = {"one_event_semantics": True, "offset": True}
    return ev_birth_move_hough(sg, hough_kwargs=hough_kwargs, **kwargs)


def ev_birth_move_correlation(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        _, eid, associations = proposal_extra
        #hough_array, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "correlation_proposals.txt")

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write(" acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            for (wn, phase), (assoc, tmvals) in associations.items():
                if assoc:
                    f.write(" associated %s at %s, %s, %s\n" % (phase, wn.sta, wn.chan, wn.band))
            f.write("\n")


    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        #if log_to_run_dir is not None:
        #    log_event_birth(sg, None, log_to_run_dir, eid, associations)
        #else:
        #    raise Exception("why are we not logging?")

    return ev_birth_move_abstract(sg, location_proposal=correlation_location_proposal, revert_action=revert_action, accept_action=accept_action, proposal_includes_mb=False, **kwargs)


def ev_birth_move_cheating(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "correlation_proposals.txt")


    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        #if log_to_run_dir is not None:
        #    log_event_birth(sg, None, log_to_run_dir, eid, associations)
        #else:
        #    raise Exception("why are we not logging?")

    return ev_birth_move_abstract(sg, location_proposal=cheating_location_proposal, revert_action=revert_action, accept_action=accept_action, proposal_includes_mb=True, **kwargs)


def ev_birth_move_lstsqr(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        refined_proposals, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "lsqr_proposals.txt")

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        if refined_proposals is None:
            refined_proposals = []

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write("acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            for abserror, z, C in refined_proposals:
                f.write("  %.2f lon %.2f lat %.2f depth %.2f time %.2f\n" % (abserror, z[0], z[1], z[2], z[3]))
            f.write("\n")

    return ev_birth_move_abstract(sg, location_proposal=overpropose_new_locations, accept_action=log_action, revert_action=log_action, **kwargs)

##############################################################

def log_event_birth(sg, hough_array, run_dir, eid, associations):

    log_dir = os.path.join(run_dir, "ev_%05d" % eid)
    mkdir_p(log_dir)

    # save post-birth signals and general state
    # sg.debug_dump(dump_path=log_dir, pickle_graph=False)


    # save Hough transform
    sites = sg.site_elements.keys()
    if hough_array is not None:
        print "visualizing hough array...",
        visualize_hough_array(hough_array, sites, os.path.join(log_dir, 'hough.png'), region=sg.inference_region)
    print "done"
