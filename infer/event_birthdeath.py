import numpy as np
import copy
import sys
import traceback
import pdb
import pickle
import os
import itertools
from collections import defaultdict


from sigvisa import Sigvisa
from sigvisa.graph.array_node import lldlld_X
from sigvisa.graph.nodes import Node
from sigvisa.graph.graph_utils import extract_sta_node, create_key, get_parent_value, parse_key
from sigvisa.graph.sigvisa_graph import get_param_model_id, dummyPriorModel, ModelNotFoundError
from sigvisa.ssms_c import TransientCombinedSSM
from sigvisa.infer.propose_hough import hough_location_proposal, visualize_hough_array
from sigvisa.infer.propose_lstsqr import overpropose_new_locations
from sigvisa.infer.propose_mb import propose_mb
from sigvisa.infer.local_gibbs_move import proxylp_full, approximate_scalar_gibbs_distribution
from sigvisa.infer.propose_cheating import cheating_location_proposal
from sigvisa.infer.correlations.ar_correlation_model import ar_advantage
from sigvisa.infer.correlations.event_proposal import correlation_location_proposal
from sigvisa.infer.template_mcmc import get_env_based_amplitude_distribution, get_env_based_amplitude_distribution2, get_env_diff_positive_part, sample_peak_time_from_cdf, merge_distribution, peak_log_p, preprocess_signal_for_sampling
from sigvisa.infer.mcmc_basic import mh_accept_util
from sigvisa.learn.train_param_common import load_modelid
from sigvisa.models.ttime import tt_residual, tt_predict
from sigvisa.models.templates.coda_height import amp_transfer
from sigvisa.models.distributions import Gaussian, Laplacian, PiecewiseLinear
from sigvisa.utils.counter import Counter
from sigvisa.utils.fileutils import mkdir_p
from sigvisa.source.event import get_event
import sigvisa.source.brune_source as brune

hough_options = {'bin_width_deg':1.0, 'time_tick_s': 10.0, 'smoothbins': True}

def set_hough_options(ho):
    global hough_options
    hough_options = ho

def unass_template_logprob(sg, wn, template_dict, return_debug=False, ignore_mb=False):
    """

    return the log prob of a set of template parameters, under the
    model of unassociated templates at a station sta.

    """

    # HACK

    tg = sg.template_generator(phase="UA")

    lps = {}
    lp = 0.0
    lp_atime = np.log(sg.uatemplate_rate) #-np.log(float(wn.npts)/wn.srate) # arrival time
    lp += lp_atime
    lps['ua_atime'] = lp_atime
    
    for param in tg.params(env=wn.is_env):

        model = tg.unassociated_model(param, nm=wn.nm)
        lp_param = model.log_p(template_dict[param])
        if return_debug:
            lps[param] = lp_param

        if ignore_mb and param=="coda_height": continue
        lp += lp_param

    if return_debug:
        return lp, lps
    else:
        return lp

def param_logprob(sg, site, sta, ev, phase, chan, band, param, val):

    """
    return the log probability for an individual template parameter,
    as generated by an event phase arrival, WITHOUT interfering with
    the graph.
    """

    if param=="coda_height":
        param="amp_transfer"
        val = amp_transfer(ev, band, phase, val)

    try:
        tmnodes = sg.get_template_nodes(ev.eid, sta, phase, band, chan)
        model = tmnodes[param][1].model
        cond = ev
    except Exception as e:
        model_type = sg._tm_type(param, site=site)
        if model_type == "dummy":
            return 0.0
        if model_type == "dummyPrior":
            model = dummyPriorModel(param)
            return model.log_p(x=val)

        s = Sigvisa()
        if s.is_array_station(site) and sg.arrays_joint:
            modelid = get_param_model_id(runids=sg.runids, sta=site,
                                         phase=phase, model_type=model_type,
                                         param=param, template_shape=sg.template_shape,
                                         chan=chan, band=band)
            cond = lldlld_X(ev, sta)
        else:
            try:
                modelid = get_param_model_id(runids=sg.runids, sta=sta,
                                             phase=phase, model_type=model_type,
                                             param=param, template_shape=sg.template_shape,
                                             chan=chan, band=band)
            except ModelNotFoundError as e:
                if sg.dummy_fallback:
                    modelid = -1
                else:
                    raise e

            cond = ev

        if modelid > -1:
            model = load_modelid(modelid)
        else:
            model = sg.dummy_prior[param]

    lp = model.log_p(x = val, cond = cond)
    if sg.hack_param_constraint:
        lp += Node.param_truncation_penalty(param=param, value=val)
    return lp

def ev_phase_template_logprob(sg, wn, eid, phase, template_dict, return_debug=False, ignore_mb=False):

    """
    return log p(template params in template_dict) under the distribution generated by a phase arrival from event eid at station sta.
    """

    ev = sg.get_event(eid)
    sta = wn.sta
    s = Sigvisa()
    site = s.get_array_site(sta)

    if 'tt_residual' not in template_dict and 'arrival_time' in template_dict:
        template_dict['tt_residual'] = tt_residual(ev, wn.sta, template_dict['arrival_time'], phase=phase)

    if 'amp_transfer' not in template_dict and "coda_height" in template_dict:
        template_dict['amp_transfer'] = amp_transfer(ev, wn.band, phase, template_dict['coda_height'])
    # note if coda height is not specified, we'll ignore amp params
    # entirely: this is used by the create-new-template proposer
    # (in phase_template_proposal_logp etc)

    lp = 0
    lps = {}
    for (param, val) in template_dict.items():
        if param in ('arrival_time', 'coda_height'): continue
        if ignore_mb and param == 'amp_transfer': continue
        lp_param = param_logprob(sg, site, wn.sta, ev, phase, wn.chan, wn.band, param, val)
        if return_debug:
            lps[param] = lp_param
            print "%s lp %s=%.2f is %.2f" % (wn.sta, param, val, lp_param)
        lp += lp_param

    if return_debug:
        return lp, lps
    else:
        return lp

def joint_association_distribution(sg, wn, eid, phases, associate_using_mb=True, max_ttr=25.0):
    ev = sg.get_event(eid)
    possible_associations = defaultdict(list)
    ignore_mb = not associate_using_mb
    
    for phase in phases:
        
        pred_atime = ev.time + tt_predict(ev, wn.sta, phase=phase)
        possible_associations[phase].append((None, 1.0))
        for tmid in sg.uatemplate_ids[(wn.sta,wn.chan,wn.band)]:
            tmnodes = sg.uatemplates[tmid]
            atime = tmnodes['arrival_time'].get_value()
            if np.abs(atime - pred_atime) < max_ttr: 
                odds = np.exp(template_association_logodds(sg, wn, tmid, eid, phase, ignore_mb=ignore_mb))
                possible_associations[phase].append((tmid, odds))
                sg.logger.debug( "odds for %s %d are %s" % (phase, tmid, odds))

    vals = [possible_associations[k] for k in phases]
    joint_dist = Counter()
    for assoc in itertools.product(*vals):
        tmids, odds = zip(*assoc)
        nontrivial_tmids = [t for t in tmids if t is not None]
        if len(set(nontrivial_tmids)) != len(nontrivial_tmids):
            # duplicate tmid, assigned to two phases
            continue
        joint_dist[tmids] = np.prod(odds)
    joint_dist.normalize()
    return joint_dist


def template_association_logodds(sg, wn, tmid, eid, phase, ignore_mb=False):

    tmnodes = sg.uatemplates[tmid]
    param_values = dict([(k, n.get_value()) for (k,n) in tmnodes.items()])

    lp_unass = unass_template_logprob(sg, wn, param_values, ignore_mb=ignore_mb)
    lp_ev = ev_phase_template_logprob(sg, wn, eid, phase, param_values, ignore_mb=ignore_mb)

    logodds = lp_ev - lp_unass
    return logodds


def template_association_distribution(sg, wn, eid, phase, ignore_mb=False, forbidden=None):
    """
    Returns a counter with normalized probabilities for associating
    any existing unassociated templates at station sta with a given
    phase of event eid. Probability of no association is given by c[None].

    """

    sta, band, chan = wn.sta, wn.band, wn.chan

    c = Counter()
    for tmid in sg.uatemplate_ids[(sta,chan,band)]:
        if forbidden is not None and tmid in forbidden: continue
        c[tmid] += np.exp(template_association_logodds(sg, wn, tmid, eid,
                                                       phase, ignore_mb=ignore_mb))

    # if there are no unassociated templates, there's nothing to sample.
    n_u = len(sg.uatemplate_ids[(sta, chan, band)])
    if n_u == 0:
        c[None] = 1.0
        return c

    c[None] = np.exp(sg.ntemplates_sta_log_p(wn, n=n_u) - sg.ntemplates_sta_log_p(wn, n=n_u-1))

    c.normalize()

    # smooth probabilities slightly, so we don't get proposals that
    # are impossible to reverse
    nkeys = len(c.keys())
    for k in c.keys():
        c[k] += 1e-4/nkeys
    c.normalize()

    return c

def sample_template_to_associate(sg, wn, eid, phase, 
                                 ignore_mb=False, forbidden=None,
                                 fix_result=None):
    """
    Propose associating an unassociate template at sta with the
    (eid,phase) arrival, with probability proportional to the odds
    ratio p_{E,P}(T)/p_U(T). Alternately propose creating a new
    template, with probability proportional to p(N_U = n_U)/p(N_U =
    n_U - 1).

    Return:
    tmid: the unassociated template id proposed for
          association. (value of None indicates proposing a creation
          move)
    assoc_logprob: log probability of the proposal

    """


    c = template_association_distribution(sg, wn, eid, phase, ignore_mb=ignore_mb, forbidden=forbidden)
    if fix_result is not None:
        tmid = fix_result
    else:
        tmid = c.sample()
    assoc_logprob = np.log(c[tmid])
    return tmid, assoc_logprob

def associate_template(sg, wn, tmid, eid, phase, create_phase_arrival=False, node_lps=None):
    """

    Transform the graph to associate the template tmid with the arrival of eid/phase at sta.

    """

    tmnodes = sg.uatemplates[tmid]
    sta = wn.sta
    s = Sigvisa()
    site = s.get_array_site(sta)

    values = dict([(k, n.get_value()) for (k, n) in tmnodes.items()])
    phase_created = False
    if create_phase_arrival and phase not in sg.ev_arriving_phases(eid, sta=sta):
        tg = sg.template_generator(phase)
        sg.add_event_site_phase(tg, site, phase, sg.evnodes[eid])
        phase_created=True

    if node_lps is not None:
        if phase_created:
            node_lps.register_new_phase_pre(sg, site, phase, eid)
        else:
            node_lps.register_phase_changed_oldvals(sg, site, phase, eid, wn_invariant=True)

    # if a newly birthed event, it already has a phase arrival that just needs to be set
    sg.set_template(eid, wn.sta, phase, wn.band, wn.chan, values)

    if node_lps is not None:
        if phase_created:
            node_lps.register_new_phase_post(sg, site, phase, eid)
        else:
            node_lps.register_phase_changed_newvals(sg, site, phase, eid, wn_invariant=True)
        node_lps.register_remove_uatemplate(sg, tmid, wn_invariant=True)
    sg.destroy_unassociated_template(tmnodes, nosort=True)
    return

def unassociate_template(sg, wn, eid, phase, tmid=None, remove_event_phase=False, node_lps=None):

    s = Sigvisa()
    site = s.get_array_site(wn.sta)

    
    ev_tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)

    atime = ev_tmvals['arrival_time']
    tmnodes = sg.create_unassociated_template(wn, atime, nosort=True,
                                           tmid=tmid, initial_vals=ev_tmvals)
    tmid = tmnodes.values()[0].tmid
    if node_lps is not None:
        node_lps.register_new_uatemplate(sg, tmid)

    if remove_event_phase:
        # if we're just unassociating this phase (not deleting the
        # whole event), we need to delete the event phase arrival.
        if node_lps is not None:
            node_lps.register_phase_removed_pre(sg, site, phase, eid, wn_invariant=True)

        # assume we're doing this as part of a larger move,
        # so we'll fix the topo sorting later
        sg.delete_event_phase(eid, site, phase, re_sort=False)

    return tmid

def deassociation_logprob(sg, wn, eid, phase, deletion_prob=False, min_logprob=-6):

    # return prob of deassociating (or of deleting, if deletion_prob=True).
    arrivals = copy.copy(wn.arrivals())
    try:
        arrivals.remove((eid, phase))
    except KeyError:
        # if this arrival doesn't actually occur during the signal contained at the wn,
        # delete it with probability 1. 
        if deletion_prob:
            return 0.0
        else:
            return -np.inf

    ev_tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
    unass_lp = unass_template_logprob(sg, wn, ev_tmvals)

    n_u = len(sg.uatemplate_ids[(wn.sta,wn.chan,wn.band)])
    ntemplates_ratio_log = sg.ntemplates_sta_log_p(wn, n=n_u+1) - sg.ntemplates_sta_log_p(wn, n=n_u)

    deassociation_ratio_log = unass_lp + ntemplates_ratio_log

    signal_lp_with_template = wn.log_p()

    signal_lp_without_template = wn.log_p(arrivals=arrivals)
    deletion_ratio_log = signal_lp_without_template - signal_lp_with_template

    log_normalizer = np.logaddexp(deassociation_ratio_log, deletion_ratio_log)

    # smooth the probabilities so we always give at least some
    # probability to each option (needed in order for reverse proposal
    # probabilities to be reasonable)
    adj = min_logprob + log_normalizer
    deassociation_ratio_log = np.logaddexp(deassociation_ratio_log, adj)
    deletion_ratio_log = np.logaddexp(deletion_ratio_log, adj)
    log_normalizer = np.logaddexp(log_normalizer, np.log(2) + adj)

    if deletion_prob:
        return deletion_ratio_log - log_normalizer
    else:
        return deassociation_ratio_log - log_normalizer

def sample_deassociation_proposal(sg, wn, eid, phase, fix_result=None):
    lp = deassociation_logprob(sg, wn, eid, phase)
    if fix_result is not None:
        deassociate = fix_result
    else:
        u = np.random.rand()
        deassociate = u < np.exp(lp)
    deassociate_lp = lp if deassociate else np.log(1-np.exp(lp))
    return deassociate, deassociate_lp

def correlation_atime_ll(sg, wn, tmvals, eid, phase, prebirth_unexplained):

    (start_idxs, end_idxs, identities, basis_prototypes, level_sizes, n_steps) = wn.wavelet_basis
    tg = sg.template_generator("P")

    wn._set_cssm_priors_from_model(arrivals=[(eid, phase)])
    cssm = wn.arrival_ssms[(eid, phase)]

    pred_wavelet = cssm.mean_obs(n_steps)

    sg.debug_dists[wn.label]["pred_wavelet"] = pred_wavelet
    env = np.exp(tg.abstract_logenv_raw(tmvals, srate=wn.srate, fixedlen=n_steps))
    pred_signal = pred_wavelet * env
    sg.debug_dists[wn.label]["pred_signal"] = pred_wavelet
    ll = ar_advantage(prebirth_unexplained, pred_signal, wn.nm)

    return ll

def get_env_based_amplitude_distribution3(sg, wn, eid, phase, prior_min, prior_max, prior_dist, tmvals, unexplained):

    # propose from a linearly interpolated version of the posterior density,
    # using a very close approximation to the posterior, i.e. we actually
    # run the full signal probability calculations for each candidate amplitude. 


    atime = tmvals['arrival_time']
    ev_offset_idx = int(5*wn.srate)
    start_idx_true = int((atime - wn.st) * wn.srate) - ev_offset_idx
    end_idx_true = int(start_idx_true + 60*wn.srate)
    start_idx = max(0, start_idx_true)
    end_idx = min(wn.npts, end_idx_true)
    start_offset = start_idx - start_idx_true
    end_offset = start_offset + (end_idx - start_idx)
    if end_idx-start_idx < wn.srate:
        # if less than 1s of available signal, don't even bother
        return None

    unexplained_local = unexplained[start_idx:end_idx]
    n = len(unexplained_local)

    env_height = np.max(np.abs(unexplained_local))

    data_min = np.log(env_height) - 2
    data_max = np.log(env_height) + 2
    prior_min = min(prior_min, 1)
    prior_max = max(prior_max, prior_min+1, -2)
    if np.isfinite(data_min):
        min_c = min(data_min, prior_min)
        max_c = max(data_max, prior_max)
        candidates = np.linspace(max(min_c, -5), min(max_c, 5), 20)
        candidates = np.array(sorted(list(candidates) + [np.log(env_height), np.log(env_height+wn.nm_env.c)]))
    else:
        candidates = np.linspace(max(prior_min, -4),  min(prior_max, 5), 20)
        

    provided_coda_height = tmvals['coda_height']
    tg = sg.template_generator("P")
    lps = []

    """
    want to model what happens to the signal between start_idx_true and end_idx_true.
    the event starts at ev_offset_idx.
    the cssm generates signal of len n_steps
    """

    (start_idxs, end_idxs, identities, basis_prototypes, level_sizes, n_steps) = wn.wavelet_basis
    wn._set_cssm_priors_from_model(arrivals=[(eid, phase)])
    cssm = wn.arrival_ssms[(eid, phase)] 
    modeled_npts = end_idx_true-start_idx_true

    d = np.ones((end_idx_true-start_idx_true,))*np.nan
    v = wn.get_value()
    d[start_offset:end_offset] = v[start_idx:end_idx]
    def proxylp(candidate):
        tmvals['coda_height'] = candidate
        l = tg.abstract_logenv_raw(tmvals, srate=wn.srate, fixedlen=end_idx_true-start_idx_true + ev_offset_idx)
        env = np.exp(l)
        components = [(wn.noise_arssm, 0, end_idx_true-start_idx_true, None)]
        components.append((cssm, ev_offset_idx, n_steps, env))
        components.append((wn.iid_arssm, ev_offset_idx+n_steps, len(env) - n_steps, env[n_steps:]))
        tssm = TransientCombinedSSM(components, 1e-6)
        lp = tssm.run_filter(d)
        return lp + prior_dist.log_p(candidate)

    lps = np.array([proxylp(candidate) for candidate in candidates])

    def bad_indices(lps):
        best_idx = np.argmax(lps)
        best_lp = np.max(lps)
        lp_diff = np.abs(np.diff(lps))

        thresh = best_lp - 3
        significant_lps = ( lps[:-1] > thresh ) +  ( lps[1:] > thresh )
        badsteps = significant_lps * (lp_diff > 1)
        bad_idxs = np.arange(len(lps)-1)[badsteps]
        return bad_idxs

    bad_idxs = bad_indices(lps)
    while len(bad_idxs) > 0:
        new_candidates = []
        new_lps = []
        for idx in bad_idxs:
            c1 = candidates[idx]
            c2 = candidates[idx+1]
            c = c1 + (c2-c1)/2.0
            new_candidates.append(c)
            new_lps.append( proxylp(c))
        full_c = np.concatenate((candidates, new_candidates))
        full_lps = np.concatenate((lps, new_lps))
        perm = sorted(np.arange(len(full_c)), key = lambda i : full_c[i])
        candidates = np.array(full_c[perm])
        lps = np.array(full_lps[perm])
        bad_idxs = bad_indices(lps)

    assert( (np.diff(candidates) > 0).all() )

    tmvals['coda_height'] = provided_coda_height
    p = PiecewiseLinear(candidates, np.array(lps))

    return p


def smart_peak_time_proposal(sg, wn, tmvals, eid, phase, pred_atime, 
                             prebirth_unexplained=None, 
                             use_correlation=False, 
                             exclude_arrs=[], 
                             fix_result=None):
    # instead of sampling arrival time from the prior, sample
    # from the product of the prior with unexplained signal mass
    ptime = np.exp(tmvals['peak_offset'])
    pidx = int(np.round(ptime * wn.srate))
    discrete_ptime = float(pidx) / wn.srate


    # consider using a vague travel-time prior to
    # acknowldege the possibility that the event is not currently
    # in the correct location
    #tt_spread = np.random.choice((2.0, 10.0, 30.0, 80.0))
    tt_spread = 3.0

    t = np.linspace(wn.st - discrete_ptime, wn.et-discrete_ptime, wn.npts)
    atime_prior = np.exp(-np.abs(t - pred_atime)/tt_spread)
    hard_cutoff = np.abs(t-pred_atime) < 25
    atime_prior *= hard_cutoff
    arrivals = wn.arrivals()

    # naively, env_diff_pos starts at wn.st and gives probabilities of peak times.
    # but we can interpret it as giving probabilities of arrival times, starting
    # at wn.st - discrete_ptime. 
    # this will align better with the atime-based correlation proposal. 
    other_arrivals = [a for a in arrivals if a not in exclude_arrs]
    env_diff_pos = get_env_diff_positive_part(wn, other_arrivals) + wn.nm_env.c

    # control dynamic range of env_diff_pos_distribution: 
    # don't disrupt the prior by more than 3 nats
    max_edp =  np.max(env_diff_pos)
    if max_edp > 3:
        env_diff_pos /= (max_edp/3.0)

    if use_correlation and prebirth_unexplained is not None:
        try:
            sg.debug_dists
        except:
            sg.debug_dists = {}
        sg.debug_dists[wn.label] = {}


        sg.debug_dists[wn.label]["prior"] = atime_prior.copy()
        sg.debug_dists[wn.label]["env_diff_pos"] = env_diff_pos
        pred_env = wn.assem_env(arrivals=other_arrivals)
        env = wn.get_env().data
        ed = env - pred_env
        sg.debug_dists[wn.label]["env_diff"] = ed


        pbu = prebirth_unexplained[wn.label]
        sg.debug_dists[wn.label]["unexplained"] = pbu.copy()
        try:
            atime_ll = correlation_atime_ll(sg, wn, tmvals, eid, phase, pbu)
        except KeyError:
            # if the wn does not have an arrival from this eid, phase,
            # then we can't do a data-driven propsal
            atime_ll = np.zeros(env_diff_pos.shape)

        maxll = np.max(atime_ll)
        # temper atime_ll to have dynamic range of 10 nats, so it doesn't overwhelm the prior
        if maxll > 5:
            atime_ll /= maxll/5.0
            maxll = 5
        sg.debug_dists[wn.label]["atime_ll"] = atime_ll

        sidx = pidx
        eidx = len(atime_ll) 
        atime_prior[sidx:eidx] *= np.exp(atime_ll[:-pidx] - maxll)
        atime_prior[:sidx] *= np.exp(-maxll)
        atime_prior[eidx:] *= np.exp(-maxll)


        atime_pdf = merge_distribution(env_diff_pos, atime_prior, smoothing=3, return_pdf=True, peak_detect=False)
        sg.debug_dists[wn.label]["final"] = atime_pdf

    else:
        atime_pdf = merge_distribution(env_diff_pos, atime_prior, smoothing=3, return_pdf=True)

    atime_cdf = preprocess_signal_for_sampling(atime_pdf)


    if not fix_result:

        if np.sum(atime_prior)==0:
            # if the window doesn't contain signal near the predicted arrival time,
            # we can't do a data-driven proposal, so just sample from (something like)
            # the prior
            atime_dist = Laplacian(pred_atime, tt_spread)
            proposed_atime = atime_dist.sample()
            atime_lp = atime_dist.log_p(proposed_atime)
        else:
            proposed_atime, atime_lp = sample_peak_time_from_cdf(atime_cdf, wn.st-discrete_ptime, wn.srate, return_lp=True)
            #idx = int(np.floor((proposed_atime - (wn.st-discrete_ptime)) * wn.srate +.00001)) + 1
            #print "atime idx", idx, "lp",  np.log(atime_cdf[idx] - atime_cdf[idx-1]), "actual lp", atime_lp


        proposed_tt_residual = proposed_atime - pred_atime

        tmvals["tt_residual"] = proposed_tt_residual
        tmvals["arrival_time"] = proposed_atime

        assert(not np.isnan(atime_lp))
        return atime_lp
    else:
        atime = tmvals["arrival_time"] 
        if np.sum(atime_prior)==0:
            atime_dist = Laplacian(pred_atime, tt_spread)
            atime_lp = atime_dist.log_p(atime)
        else:
            atime_lp = peak_log_p(atime_cdf, wn.st-discrete_ptime, wn.srate, atime)
            #idx = int(np.floor((atime - (wn.st-discrete_ptime)) * wn.srate +.00001)) + 1
            #print "atime idx", idx, "lp",  np.log(atime_cdf[idx] - atime_cdf[idx-1])

        #print "atime_lp is", atime_lp, "for", atime
        assert(not np.isnan(atime_lp))
        return atime_lp


def heuristic_amplitude_posterior(sg, wn, tmvals, eid, phase, debug=False, exclude_arrs = [], unexplained=None, full_tssm_proposal=False):
    """
    Construct an amplitude proposal distribution by combining the env likelihood with
    the prior conditioned on the event location.

    This is especially necessary when proposing phases that don't appear to be
    present in the signal (i.e., are below the noise floor). If the prior predicts
    a log-amplitude of -28, and the likelihood predicts a log-amplitude of -4 (because
    it's impossible for the likelihood to distinguish amplitudes below the noise floor), then
    proposals from the likelihood alone would ultimately be rejected.

    """


    k_ampt = create_key("amp_transfer", eid=eid, sta=wn.sta, chan=":", band=":", phase=phase)
    try:
        n_ampt = sg.all_nodes[k_ampt]
    except:
        import pdb; pdb.set_trace()

    ev = sg.get_event(eid)
    source_amp = brune.source_logamp(ev.mb, phase=phase, band=wn.band)

    prior_mean = float(n_ampt.model.predict(cond=n_ampt._parent_values())) + source_amp
    prior_var = float(n_ampt.model.variance(cond=n_ampt._parent_values(), include_obs=True))
    prior_std = np.sqrt(prior_var)
    prior_dist = Gaussian(prior_mean, prior_std)

    prior_min = prior_mean - 3*prior_std
    prior_max = prior_mean + 3*prior_std

    if full_tssm_proposal:
        amp_dist_env = get_env_based_amplitude_distribution3(sg, wn, eid, phase,
                                                             prior_min=prior_min, 
                                                             prior_max=prior_max, 
                                                             prior_dist=prior_dist, 
                                                             tmvals=tmvals, 
                                                             unexplained=unexplained[wn.label])
    else:
        amp_dist_env = get_env_based_amplitude_distribution2(sg, wn, 
                                                             prior_min=prior_min, 
                                                             prior_max=prior_max, 
                                                             prior_dist=prior_dist, 
                                                             tmvals=tmvals, 
                                                             exclude_arrs=exclude_arrs)
    if amp_dist_env is None:
        return prior_dist

    return amp_dist_env


def heuristic_amplitude_posterior_old(sg, wn, tmvals, eid, phase, debug=False):
    """
    Construct an amplitude proposal distribution by combining the env likelihood with
    the prior conditioned on the event location.

    This is especially necessary when proposing phases that don't appear to be
    present in the signal (i.e., are below the noise floor). If the prior predicts
    a log-amplitude of -28, and the likelihood predicts a log-amplitude of -4 (because
    it's impossible for the likelihood to distinguish amplitudes below the noise floor), then
    proposals from the likelihood alone would ultimately be rejected.

    """

    amp_dist_env = get_env_based_amplitude_distribution(sg, wn, tmvals, exclude_arr=(eid, phase))

    k_ampt = create_key("amp_transfer", eid=eid, sta=wn.sta, chan=":", band=":", phase=phase)
    try:
        n_ampt = sg.all_nodes[k_ampt]
    except:
        import pdb; pdb.set_trace()

    ev = sg.get_event(eid)
    source_amp = brune.source_logamp(ev.mb, phase=phase, band=wn.band)

    prior_mean = float(n_ampt.model.predict(cond=n_ampt._parent_values())) + source_amp
    prior_var = float(n_ampt.model.variance(cond=n_ampt._parent_values(), include_obs=True))
    prior_dist = Gaussian(prior_mean, np.sqrt(prior_var))

    if debug:
        import pdb; pdb.set_trace()

    if amp_dist_env is None:
        return prior_dist

    if amp_dist_env.mean < np.log(wn.nm_env.c):
        # the Gaussian model of log-amplitude isn't very good at the noise floor
        # (it should really be a model of non-log amplitude, since noise is additive).
        # so we hack in some special cases:
        # TODO: find a better solution here.

        if prior_mean < amp_dist_env.mean:
            # if the prior thinks the env needs to be *really* small, vs just kind of small,
            # we believe the prior. Since we're proposing below the noise floor, our proposal
            # won't affect env probabilities anyway, so we should just maximize probability
            # under the prior.
            heuristic_posterior = prior_dist
        #elif prior_mean > np.log(wn.nm_env.c) + 2:
            # if the prior thinks there *should* be a visible arrival
            # here, but that's not supported by the env, we propose
            # to fit the env (paying the cost under the prior) since
            # this is almost certainly cheaper than believing the prior
            # at the cost of not fitting the env.
        else:
            #heuristic_posterior = amp_dist_env
            heuristic_posterior = Gaussian(-5, 1.0)
        #else:
        #    heuristic_posterior = amp_dist_env.product(prior_dist)
    else:
        # otherwise, combine the likelihood and prior for a heuristic posterior
        heuristic_posterior = amp_dist_env.product(prior_dist)
    #heuristic_posterior = Gaussian(-2.0, 0.5)


    #nstd = np.sqrt(wn.nm_env.marginal_variance())


    return heuristic_posterior


def clean_propose_phase_template(sg, wn, eid, phase, 
                                 fix_result=None, 
                                 debug_info=None,
                                 ev=None):
    # add the given phase to the graph, with appropriate proposal values (or fix_result)
    # return the tmvals and stuff
    if ev is None:
        ev = sg.get_event(eid)
        

    # add the template
    
    #sg._topo_sort()
    
    # sample most of the template params from the event-conditional prior
    tmnodes = sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
    k_ttr, n_ttr = tmnodes["tt_residual"]
    k_time, n_time = tmnodes["arrival_time"]
    k_amp, n_amp = tmnodes["amp_transfer"]
    k_height, n_height = tmnodes["coda_height"]
    tmvals = {}
    log_q = 0.0
    for param, (k, n) in tmnodes.items():
        if param in ("tt_residual", "amp_transfer") or n.deterministic():
            continue
        if fix_result is not None:
            n.set_value(fix_result[param])
        else:
            n.parent_sample()
        param_lp = n.log_p()
        log_q += param_lp
        
        tmvals[param] = n.get_value()
        if debug_info is not None:
            debug_info[param] = (tmvals[param], param_lp, param_lp)
        sg.logger.debug( "param %s val %f lp %f" % (param, tmvals[param], param_lp))

    #if "arrival_time" not in tmvals:
    #    tmvals["arrival_time"] = tmnodes["arrival_time"][1].get_value()
 
    # then sample atime from the signal
    pred_atime = ev.time + tt_predict(ev, wn.sta, phase)
    debug_lps = {}
    if fix_result is not None:
        tmvals["arrival_time"] = fix_result["arrival_time"]
    peak_lp = smart_peak_time_proposal(sg, wn, tmvals, eid, phase,
                                       pred_atime,
                                       use_correlation=False,
                                       prebirth_unexplained=None,
                                       exclude_arrs=[],
                                       fix_result=(fix_result is not None))
    n_time.set_value(key=k_time, value = tmvals["arrival_time"])
    log_q += peak_lp
    if debug_info is not None:
        debug_info["tt_residual"] = (n_ttr.get_value(), peak_lp, n_ttr.log_p())
    #print "param atime val", tmvals["arrival_time"], "lp", peak_lp

    # then sample amplitude from the signal
    amp_dist = heuristic_amplitude_posterior(sg, wn, tmvals, eid, phase, 
                                             exclude_arrs=[(eid, phase)], 
                                             unexplained = None, 
                                             full_tssm_proposal=False)
    if fix_result is not None:
        tmvals["coda_height"] = fix_result["coda_height"]
    else:
        tmvals["coda_height"] = amp_dist.sample()
    n_height.set_value(key=k_height, value=tmvals["coda_height"])
    amp_lp = amp_dist.log_p(tmvals["coda_height"])
    log_q += amp_lp
    tmvals["amp_transfer"] = n_amp.get_value(key=k_amp)
    if debug_info is not None:
        debug_info["amp_transfer"] = (n_amp.get_value(), amp_lp, n_amp.log_p())
    #print "param atransfer val", tmvals["amp_transfer"], "lp", amp_lp

    if not np.isfinite(log_q):
        import pdb; pdb.set_trace()
    
    return tmvals, log_q

#########################################################################################

def death_proposal_log_ratio(sg, eid):
    lp_unass = 0
    lp_ev = 0

    ev = sg.get_event(eid)
    eid = ev.eid

    for (site, elements) in sg.site_elements.items():
        for sta in elements:
            for wn in sg.station_waves[sta]:
                for phase in sg.ev_arriving_phases(eid, sta):
                    tmvals = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)

                    lp_unass_tmpl = unass_template_logprob(sg, wn, tmvals)
                    lp_ev_tmpl = ev_phase_template_logprob(sg, wn, eid, phase, tmvals)
                    #print "ev tmpl prob", sta, phase, eid, lp_ev_tmpl

                    lp_unass += lp_unass_tmpl
                    lp_ev += lp_ev_tmpl
    r = lp_unass - lp_ev
    #assert(np.isfinite(r))
    return r

def death_proposal_distribution(sg):
    c = Counter()
    for eid in sg.evnodes.keys():
        if eid in sg.fixed_events: continue
        c[eid] = death_proposal_log_ratio(sg, eid)

    c.normalize_from_logs()


    # with probability ~.1, just sample an event uniformly.
    # this way all events have some possibility to die.
    for k in c.keys():
        if np.isfinite(c[k]):
            c[k] += .1/len(c)
        else:
            c[k] = .1/len(c)
    c.normalize()

    return c

def sample_death_proposal(sg):
    c = death_proposal_distribution(sg)
    if len(c) == 0:
        return None, 1.0
    eid = c.sample()
    return eid, np.log(c[eid])

def death_proposal_logprob(sg, eid):
    c = death_proposal_distribution(sg)
    if len(c) == 0:
        return 1.0
    lp = np.log(c[eid])
    #assert(np.isfinite(lp))
    return lp

    
def ev_death_executor(sg, location_proposal, 
                      proposal_includes_mb=True,
                      birth_type="mh",
                      force_kill_eid=None):
    log_qforward = 0.0
    log_qbackward = 0.0
    
        
    debug_info = {}

    if force_kill_eid is None:
        eid, lq_death = sample_death_proposal(sg)
    else:
        eid = force_kill_eid
        lq_death = 0

    if eid is None:
        return None

    log_qforward += lq_death

    lp_old = sg.current_log_p()
    s1 = sg.current_log_p_breakdown(silent=True)
    evs1 = [sg.get_event(eid1) for eid1 in sg.evnodes.keys()]
    vals1 = [(n.label, n.get_value(), n.log_p()) for n in sg.extended_evnodes[eid] if n.single_key is not None and not n.deterministic()]

    lqf, replicate_untmpls, death_records = ev_template_death_helper(sg, eid)
    log_qforward += lqf

    # this is a little inelegant 
    replicate_death, ev = ev_bare_death_move(sg, eid)
    sg._topo_sort()
    
    lp_new = sg.current_log_p()
        
    if force_kill_eid is None:
        n_current_events = len(sg.evnodes) - len(sg.fixed_events)
        log_qbackward += -np.log(n_current_events + 1)
    lq_loc, replicate_birth, eid, extra = ev_bare_birth_move(sg, location_proposal, fix_result=(ev, eid))

    log_qbackward += lq_loc

    lqb, replicate_tmpls, birth_records = \
            ev_template_birth_helper(sg, eid, 
                                     associate_using_mb=proposal_includes_mb, 
                                     fix_result=death_records, 
                                     proposal_type=birth_type)
    log_qbackward += lqb
    sg._topo_sort()
                        
    #lp_old2 = sg.current_log_p()
    #s2 = sg.current_log_p_breakdown(silent=True)
    #evs1 = [sg.get_event(eid) for eid in sg.evnodes.keys()]
    #vals2 = [(n.label, n.get_value(), n.log_p()) for n in sg.extended_evnodes[eid] if n.single_key is not None and not n.deterministic()]
    #assert(np.abs(lp_old2 - lp_old) < 1e-6)
    
    def rebirth():
        replicate_birth()
        replicate_tmpls()
        sg._topo_sort()
        
    def redeath():
        replicate_untmpls() # maybe not technically necessary
        replicate_death()
        sg._topo_sort()

    proposal_extra = (extra, eid, debug_info)
    return lp_new, lp_old, log_qforward, log_qbackward, redeath, rebirth, proposal_extra

def ev_death_move_abstract(sg, location_proposal, log_to_run_dir=None, force_outcome=None, **kwargs):

    #n_current_events = len(sg.evnodes) - len(sg.fixed_events)
    #reverse_logprob = -np.log(n_current_events) # this accounts for the different "positions" we can birth an event into

    r = ev_death_executor(sg, location_proposal, **kwargs)
    if r is None:
        return False
    lp_new, lp_old, log_qforward, log_qbackward, redeath, rebirth, proposal_extra = r

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "hough_proposals.txt")

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write("acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            for (wn, phase), (assoc, tmvals) in associations.items():
                if assoc:
                    f.write(" associated %s at %s, %s, %s\n" % (phase, wn.sta, wn.chan, wn.band))
            f.write("\n")

    sg.logger.info( "death move acceptance %f from old %f new %f lqb %f lqf %f" %( (lp_new + log_qbackward) - (lp_old+log_qforward), lp_old, lp_new, log_qbackward, log_qforward) )

    return mh_accept_util(lp_old, lp_new, log_qforward, log_qbackward, accept_move=redeath, revert_move=None, force_outcome=force_outcome)

def ev_death_move_hough(sg, hough_kwargs={}, **kwargs):
    def hlp(sg, fix_result=None, **kwargs):
        kwargs.update(hough_kwargs)
        return hough_location_proposal(sg, fix_result=fix_result, **kwargs)
    return ev_death_move_abstract(sg, hlp, proposal_includes_mb=True, **kwargs)


def ev_death_move_hough_offset(sg, **kwargs):
    hough_kwargs = {"offset": True}
    return ev_death_move_hough(sg, hough_kwargs, **kwargs)

def ev_death_move_hough_dumb(sg, **kwargs):
    hough_kwargs = {"one_event_semantics": False}
    return ev_death_move_hough(sg, hough_kwargs, birth_type="dumb", **kwargs)

def ev_death_move_correlation(sg, **kwargs):
    return ev_death_move_abstract(sg, correlation_location_proposal, proposal_includes_mb=False, **kwargs)

def ev_death_move_cheating(sg, **kwargs):
    return ev_death_move_abstract(sg, cheating_location_proposal, proposal_includes_mb=True, **kwargs)


def ev_death_move_lstsqr(sg, **kwargs):
    return ev_death_move_abstract(sg, overpropose_new_locations, **kwargs)

##########################################################################################

def ev_death_dist(sg):
    log_qforward = -np.log(len(sg.evnodes.keys()))
    
def ev_bare_death_move(sg, eid):
    
    def replicate_move():
        sg.remove_event(eid)
    
    ev = sg.get_event(eid)
    replicate_move()
    return replicate_move, ev

def ev_sta_template_death_helper(sg, wn, eid, phases=None,
                                 fix_result=None,
                                 debug_info=None):
    death_record = {}
    
    s = Sigvisa()
    site = s.get_array_site(wn.sta)
    sta = wn.sta
    replicate_fns = []
    assoc_tmids = {}
    log_qforward = 0.0
    if phases is None:
        phases = sg.ev_arriving_phases(eid, sta)

    for phase in phases:
        if fix_result is not None:
            deassociate, tmid, fixed_tmvals = fix_result[phase]
        else:
            deassociate = None
            tmid = None
            fixed_tmvals = None
        deassociate, deassociate_logprob = sample_deassociation_proposal(sg, wn, eid, phase, 
                                                                         fix_result = deassociate)
        log_qforward += deassociate_logprob
        if deassociate:
            tmid = unassociate_template(sg, wn, eid, phase, tmid=tmid, 
                                        remove_event_phase=True)
            replicate_fns.append(lambda wn=wn,phase=phase,eid=eid,tmid=tmid: \
                                 unassociate_template(sg, wn, eid, phase, tmid=tmid, 
                                                      remove_event_phase=True))

            sg.logger.debug("proposing to deassociate %s at %s (lp %.1f)" % (phase, sta, deassociate_logprob))
            assoc_tmids[phase] = tmid
        else:
            template_param_array = sg.get_template_vals(eid, wn.sta, phase, wn.band, wn.chan)
            death_record[phase] = template_param_array
            sg.delete_event_phase(eid, site, phase, re_sort=False)
            replicate_fns.append(lambda eid=eid, site=site, phase=phase: sg.delete_event_phase(eid, site, phase))
            sg.logger.debug( "proposing to delete %s at %s (lp %f)"% (phase, sta, deassociate_logprob))
    sorted_tmids = [assoc_tmids[phase] if phase in assoc_tmids else None for phase in sorted(phases)]
    death_record["assoc_tmids"] = tuple(sorted_tmids)

    def replicate_move():
        for fn in replicate_fns:
            fn()
    
    return log_qforward, replicate_move, death_record

def ev_template_death_helper(sg, eid, fix_result=None):
    birth_records = {}
    replicate_fns = []
    log_qforward = 0.0
    for site,elements in sg.site_elements.items():
        phases = sg.ev_arriving_phases(eid, site=site)
        birth_records["%s_phases" % site] = phases
        for sta in elements:
            for wn in sg.station_waves[sta]:
                fr_sta = None
                if fix_result is not None:
                    fr_sta = fix_result[wn.label]                
                lqf_sta, replicate_sta, birth_sta = ev_sta_template_death_helper(sg, wn, eid, fix_result=fr_sta)
                replicate_fns.append(replicate_sta)
                log_qforward += lqf_sta
                birth_records[wn.label] = birth_sta
                
    def replicate_move():
        for fn in replicate_fns:
            fn()
            
    return log_qforward, replicate_move, birth_records


def ev_bare_birth_move(sg, location_proposal, 
                       debug_info=None,
                       eid=None,
                       fix_result=None):
    if fix_result is not None:
        ev, eid = fix_result
        extra = None
        log_qforward = location_proposal(sg, fix_result=ev)
    else:
        ev, log_qforward, extra = location_proposal(sg)
        if ev is None:
            return None, None, None, None
        
    evnodes = sg.add_event(ev, eid=eid, phases=None)
    eid = evnodes["loc"].eid
    
    if debug_info is not None:
        evnodes = set(sg.evnodes[eid].values())
        evlps = [(n.label.split(";")[1], n.log_p()) for n in evnodes]
        evlps += [('nevents', np.log(sg.event_rate))]
        debug_info["ev"] = (ev, log_qforward, evlps)
    
    def replicate_move():
        sg.add_event(ev, eid=eid, phases=None)
        
    return log_qforward, replicate_move, eid, extra


def propose_tmvals_from_gibbs_scan(sg, wn, eid, phase, fix_result=None, debug_info=None):
    tmnodes = sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
    logq = 0.0
    tmvals = {}
    params = ("peak_offset", "tt_residual", "amp_transfer", "peak_decay", "coda_decay", "mult_wiggle_std")
    for param in params:
        try:
            (k, n) = tmnodes[param]
        except:
            continue

        proxylp = proxylp_full(sg, wn, n)
        d = approximate_scalar_gibbs_distribution(sg, wn, eid, 
                                                  phase, param, 
                                                  n, proxylp, 
                                                  prior_weight = 0.01)
        
        if fix_result is not None:
            v = fix_result[param]
        else:
            v = d.sample()
        n.set_value(v)
        logq_param = d.log_p(v)
        logq += logq_param
        
        if debug_info is not None:
            debug_info[param] = (v, logq_param, n.log_p())
        
        tmvals[param] = v
        # print phase, param, v, logq_param, d.sample(), d.sample(), d.sample()
        
    return logq, tmvals

def propose_associations(sg, wn, eid, site_phases, fix_result=None, 
                         debug_info=None, associate_using_mb=True):

    """
    Sample a joint association of all phases at this station,
    and update the graph to reflect the new association.
    """

    log_qforward = 0    
    band, chan = wn.band, wn.chan
    jd = joint_association_distribution(sg, wn, eid=eid, phases=site_phases, 
                                        associate_using_mb=associate_using_mb)
    if fix_result is None:
        assoc_tmids = jd.sample()
        assoc_lp = np.log(jd[assoc_tmids])
    else:
        assoc_tmids = fix_result["assoc_tmids"]
        assoc_lp = np.log(jd[assoc_tmids]) if assoc_tmids in jd else -np.inf
    sg.logger.debug( "using assoc %s with lp %f" % ( zip(site_phases, assoc_tmids), assoc_lp) )
    log_qforward += assoc_lp
    
    if debug_info is not None:
        debug_info["assoc"] = (zip(site_phases, assoc_tmids), assoc_lp, 0.0)

    replicate_fns = []
    birth_record = {}
    for i_phase, phase in enumerate(site_phases):
        debug_phase = None
        if debug_info is not None:
            debug_info[phase] = {}
            debug_phase = debug_info[phase]
            
        assoc_tmid = assoc_tmids[i_phase]
        birth_record[(phase)] = (assoc_tmid is not None, assoc_tmid, None)

        if assoc_tmid is not None:
            if debug_phase is not None:
                tmnodes = sg.get_template_nodes(-assoc_tmid, wn.sta, "UA", wn.band, wn.chan)
                ualps = dict([(param, n.log_p()) for (param, (k,n)) in tmnodes.items()])
                    
            associate_template(sg, wn, assoc_tmid, eid, phase, create_phase_arrival=True)
            replicate_fns.append(lambda sg=sg,wn=wn,phase=phase,eid=eid,tmid=assoc_tmid: \
                                  associate_template(sg, wn, tmid, eid, phase, create_phase_arrival=True))
            
            if debug_phase is not None:
                tmnodes = sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
                for (param, (k, n)) in tmnodes.items():
                    if n.deterministic(): continue
                    evlp = n.log_p()
                    uaparam = param
                    if param == "amp_transfer":
                        uaparam = "coda_height"
                    elif param == "tt_residual":
                        uaparam = "arrival_time"
                    ualp = ualps[uaparam]
                    if uaparam=="arrival_time":
                        ualp = np.log(sg.uatemplate_rate)
                    v = n.get_value(key=k)
                    debug_phase[param] = (v, ualp, evlp)

    return log_qforward, replicate_fns, assoc_tmids, birth_record

def propose_new_phases_mh(sg, wn, eid, new_phases, 
                          fix_result=None,
                          debug_info=None):

    log_qforward = 0
    replicate_fns = []

    # first create the new templates, and initialize to proposed values
    # (but don't bother recording the proposal probabilities since these
    # are only intermediate/auxiliary variables)
    site = Sigvisa().get_array_site(wn.sta)    
    for i_phase, phase in enumerate(new_phases):
        tg = sg.template_generator(phase)
        f1 = lambda tg=tg, site=site, phase=phase, eid=eid : \
               sg.add_event_site_phase(tg, site, phase, sg.evnodes[eid], sample_templates=False)
        f1()
        replicate_fns.append(f1)

        tmvals, tmpl_lp = clean_propose_phase_template(sg, wn, eid, phase=phase, 
                                                       fix_result=None, 
                                                       debug_info=None)      


    # run a few iterations of MH on the proposed templates
    tmnodes = [(phase, sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)) for phase in new_phases]
    from sigvisa.infer.run_mcmc import single_template_MH
    single_template_MH(sg, wn, tmnodes, steps=30)

    # then propose template values from a local approximation to the posterior
    for phase in new_phases:
        fr_phase, debug_phase = None, None
        if debug_info is not None:
            debug_phase = debug_info[phase]
        if fix_result is not None:
            fr_phase = fix_result[phase]

        lqf, tmvals = propose_tmvals_from_gibbs_scan(sg, wn, eid, phase, 
                                                     fix_result=fr_phase,
                                                     debug_info=debug_phase)
        def rf(eid=eid, wn=wn, tmvals=tmvals, phase=phase):
            sg.set_template(eid, wn.sta, phase, wn.band, wn.chan, tmvals)
        replicate_fns.append(rf)
        log_qforward += lqf
            
    return log_qforward, replicate_fns

def dumb_propose_phase_template(sg, wn, eid, phase, 
                                fix_result=None, 
                                debug_info=None,
                                ev=None):
    # add the given phase to the graph, with appropriate proposal values (or fix_result)
    # return the tmvals and stuff
    if ev is None:
        ev = sg.get_event(eid)
        
    
    # sample the template params from the event-conditional prior
    tmnodes = sg.get_template_nodes(eid, wn.sta, phase, wn.band, wn.chan)
    tmvals = {}
    log_q = 0.0
    for param, (k, n) in tmnodes.items():
        if n.deterministic():
            continue
        if fix_result is not None:
            n.set_value(fix_result[param])
        else:
            n.parent_sample()
        param_lp = n.log_p()
        log_q += param_lp

        sg.logger.debug( "dumb logq %s %s %s %s %f %s" % (param, wn.sta, phase, n.get_value(), param_lp, " fixed" if fix_result is not None else " unfixed"))

        tmvals[param] = n.get_value()
        if debug_info is not None:
            debug_info[param] = (tmvals[param], param_lp, param_lp)
        # print "param", param, "val", tmvals[param], "lp", param_lp
            
    return tmvals, log_q


def propose_new_phases_no_mh(sg, wn, eid, new_phases, fix_result=None, 
                             debug_info=None, proposal_type="clean"):

    log_qforward = 0
    replicate_fns = []

    site = Sigvisa().get_array_site(wn.sta)    
    for i_phase, phase in enumerate(new_phases):
        #if phase=="ScP" and wn.sta=="NV01":
        #    import pdb; pdb.set_trace()

        debug_phase = None
        if debug_info is not None:
            debug_info[phase] = {}
            debug_phase = debug_info[phase]            

        # cases:
        # dumb proposal: sample all templates from ev prior, and record lqf
        # old proposal: sample all templates from clean_propose, record lqf
        tg = sg.template_generator(phase)
        f1 = lambda tg=tg, site=site, phase=phase, eid=eid : \
               sg.add_event_site_phase(tg, site, phase, sg.evnodes[eid], sample_templates=False)
        f1()
        replicate_fns.append(f1)

        fr_phase = None
        if fix_result is not None:
            fr_phase = fix_result[phase]

        if proposal_type=="dumb":
            tmvals, tmpl_lp = dumb_propose_phase_template(sg, wn, eid, phase=phase, 
                                                          fix_result=fr_phase, 
                                                          debug_info=debug_phase)      
        else:
            tmvals, tmpl_lp = clean_propose_phase_template(sg, wn, eid, phase=phase, 
                                                           fix_result=fr_phase, 
                                                           debug_info=debug_phase)      
            #sg.logger.debug("%s %f" % (wn.sta, tmplg_lp))


        # to replay this move, we just need to reset the proposed values
        def rf(eid=eid, wn=wn, tmvals=tmvals, phase=phase):
            sg.set_template(eid, wn.sta, phase, wn.band, wn.chan, tmvals)
        replicate_fns.append(rf)
        log_qforward += tmpl_lp

    return log_qforward, replicate_fns

def ev_sta_template_birth_helper(sg, wn, eid, site_phases, fix_result=None, 
                                 debug_info=None, 
                                 associate_using_mb=True,
                                 proposal_type="mh"):

    if len(site_phases) == 0:
        nop = lambda : None
        return 0.0, nop, {"assoc": ((), 0.0, 0.0 )}

    # propose a set of associations to existing uatemplates
    log_qforward, replicate_fns, assoc_tmids, birth_record = \
        propose_associations(sg, wn, eid, site_phases, 
                             fix_result=fix_result, 
                             debug_info=debug_info, 
                             associate_using_mb=associate_using_mb)

    # for all phases not associated, propose template params from scratch,
    # either from 
    #  - a dumb parent-conditional proposal
    #  - a 'semismart' proposal which attempts to adapt atime and amplitude based on the signal
    #  - a smart proposal that internally runs MH steps to find good params
    new_phases = [phase for (phase, assoc) in zip(site_phases, assoc_tmids) if assoc is None]
    if proposal_type=="mh":
        lqf, rfns = propose_new_phases_mh(sg, wn, eid, new_phases, 
                                          fix_result=fix_result,
                                          debug_info=debug_info)
    else:
        lqf, rfns = propose_new_phases_no_mh(sg, wn, eid, new_phases, 
                                             fix_result=fix_result, 
                                             debug_info=debug_info,
                                             proposal_type=proposal_type)

    log_qforward += lqf
    replicate_fns += rfns

    def replicate_fn():
        for fn in replicate_fns:
            fn()
        
    return log_qforward, replicate_fn, birth_record
        
    
def phase_birth_helper(sg, eid, site, phase, proposal_type="mh", fix_result=None):
    # boilerplate to birth a single phase across a site (as in a phase mh move),
    # rather than multple phases at a sta (as in the default ev_sta_template_birth_helper)
    lqf = 0.0
    replicate_fns = []
    death_records = {}

    stas = sg.site_elements[site]
    for sta in stas:
        for wn in sg.station_waves[sta]:
            fr_sta = None
            if fix_result is not None:
                fr_sta = fix_result[wn.label]                

            r = ev_sta_template_birth_helper(sg, wn, eid, site_phases=(phase,),
                                             fix_result=fr_sta,
                                             associate_using_mb=True,
                                             proposal_type=proposal_type)
            lqf_sta, replicate_sta,death_record = r
            lqf += lqf_sta
            replicate_fns.append(replicate_sta)
            death_records[wn.label] = death_record

    sg._topo_sort()
    replicate_fns.append(sg._topo_sort)

    def replicate_move():
        for fn in replicate_fns:
            fn()

    return lqf, replicate_move, death_records

def phase_death_helper(sg, eid, site, phase, fix_result=None):
    lqf = 0.0
    replicate_fns = []
    birth_records = {}

    stas = sg.site_elements[site]
    for sta in stas:
        for wn in sg.station_waves[sta]:
            fr_sta = None
            if fix_result is not None:
                fr_sta = fix_result[wn.label]                


            r = ev_sta_template_death_helper(sg, wn, eid, phases=(phase,),
                                             fix_result=fr_sta)
            lqf_sta, replicate_sta,birth_record = r
            lqf += lqf_sta
            replicate_fns.append(replicate_sta)
            birth_records[wn.label] = birth_record

    sg._topo_sort()
    replicate_fns.append(sg._topo_sort)

    def replicate_move():
        for fn in replicate_fns:
            fn()

    return lqf, replicate_move, birth_records

def phase_birth_proposal(sg, eid, site, fix_result=None):
    # of possible phases that don't currently exist, choose one to propose

    ev = sg.get_event(eid)
    possible_phases = sg.predict_phases_site(ev, site)
    current_phases = sg.ev_arriving_phases(eid, site=site)
    new_phases = possible_phases - current_phases

    if len(new_phases)==0:
        return None, 0.0

    phase_probs = Counter()
    for phase in new_phases:
        pm = sg.get_phase_existence_model(phase)
        lp = pm.log_p(True, ev=ev, site=site)
        phase_probs[phase] = np.exp(.5*lp)
    
    phase_probs.normalize()
    if fix_result is not None:
        phase = fix_result
    else:
        phase = phase_probs.sample()
    return phase, np.log(phase_probs[phase])

def phase_death_proposal(sg, eid, site, fix_result=None):
    ev = sg.get_event(eid)
    current_phases = sg.ev_arriving_phases(eid, site=site)
    if len(current_phases) == 0:
        return None, 0.0

    phase_probs = Counter()
    for phase in current_phases:
        pm = sg.get_phase_existence_model(phase)
        lp = pm.log_p(False, ev=ev, site=site)
        phase_probs[phase] = np.exp(.5*lp)
    
    phase_probs.normalize()
    if fix_result is not None:
        phase = fix_result
    else:
        phase = phase_probs.sample()
    return phase, np.log(phase_probs[phase])
    


def phase_lp(sg, eid, site, wns):
    # get current logp
    #  (including site logp, relevant tmvals, and phase existence)

    lp = 0.0

    # always compute the ev prior, and
    # always compute all params at all stations, since
    #  - if we're not using GPs, this is cheap (though maybe not necessary)
    #  - if we're using GPs, this is necessary, since any parent-conditional 
    #    distribution can be changed by a change in ev location. 
    lp += np.sum([n.log_p() for n in sg.extended_evnodes[eid] if not n.deterministic()])

    lp += sg.phase_existence_lp(eids=(eid,), sites=(site,))
    for wn in wns:
        # include any wns where our signal explanation will have changed.
        # if the only record is that we didn't decouple, we can skip this wn.
        lp += wn.log_p()

        tmids = [-eid for (eid, phase) in wn.arrivals() if phase=="UA"]
        lp += sg.ntemplates_sta_log_p(wn, n=len(tmids))
        for tmid in tmids:
            uanodes = sg.uatemplates[tmid]
            lp += np.sum([n.log_p() for n in uanodes.values()])

    return lp

def phase_birth_move(sg, eid, site):
    
    wns = []
    for sta in sg.site_elements[site]:
        wns += sg.station_waves[sta]


    # of possible phases that don't currently exist, choose one to propose
    phase, phase_lqf = phase_birth_proposal(sg, eid, site)
    if phase is None:
        # if all possible phases already exist
        return False

    lp_old = phase_lp(sg, eid, site, wns)
    #lp_old_full = sg.current_log_p()

    # call the birth helper
    lqf, replicate_birth, death_record = phase_birth_helper(sg, eid, site, phase)

    # get new logp
    lp_new = phase_lp(sg, eid, site, wns)
    #lp_new_full = sg.current_log_p()

    #assert( np.abs((lp_new_full - lp_old_full)  - (lp_new-lp_old)) < 1e-4 )

    # call the death helper
    lqb, replicate_death, birth_record = phase_death_helper(sg, eid, site, phase, fix_result=death_record)

    # do mh acceptance
    def accept():
        replicate_birth()

    return mh_accept_util(lp_old, lp_new, lqf, lqb, accept_move=accept)


def phase_death_move(sg, eid, site):
    wns = []
    for sta in sg.site_elements[site]:
        wns += sg.station_waves[sta]

    # DEBUG section to catch illegal phases before we start...
    current_phases = sg.ev_arriving_phases(eid, site=site)
    ev = sg.get_event(eid)
    ttimes = {}
    s = Sigvisa()
    sta = s.get_default_sta(site)
    for phase in current_phases:
        ttimes[phase] = tt_predict(ev, sta=sta, phase=phase)

    # choose a phase to kill
    phase, phase_lqf = phase_death_proposal(sg, eid, site)
    if phase is None:
        return False

    lp_old = phase_lp(sg, eid, site, wns)
    #lp_old_full = sg.current_log_p()

    # call the birth helper
    lqf, replicate_death, birth_record = phase_death_helper(sg, eid, site, phase)

    # get new logp
    lp_new = phase_lp(sg, eid, site, wns)
    #lp_new_full = sg.current_log_p()

    # call the death helper
    lqb, replicate_birth, death_record = phase_birth_helper(sg, eid, site, phase, 
                                                            fix_result=birth_record)

    #assert( np.abs((lp_new_full - lp_old_full)  - (lp_new-lp_old)) < 1e-4 )

    # do mh acceptance
    def accept():
        replicate_death()

    return mh_accept_util(lp_old, lp_new, lqf, lqb, accept_move=accept)


def ev_template_birth_helper(sg, eid, fix_result=None, 
                             associate_using_mb=True,
                             proposal_type="mh",
                             debug_info=None, **kwargs):
    death_records = {}
    replicate_fns = []
    log_qforward = 0
    proposed_ev = sg.get_event(eid)
    for site,elements in sg.site_elements.items():
        key = "%s_phases" % site
        fr_phases = None
        if fix_result is not None:
            fr_phases = fix_result[key]
        site_phases, lqf = sg.sample_phases_site(proposed_ev, site=site, fix_result=fr_phases)
        site_phases = sorted(list(site_phases))
        death_records[key] = site_phases
        log_qforward += lqf

        #site_phases = sorted(sg.predict_phases_site(proposed_ev, site=site))
        for sta in elements:
            debug_info_sta = None
            if fix_result is None and debug_info is not None:
                if sta not in debug_info:
                    debug_info[sta] = dict()
                debug_info_sta = debug_info[sta]
                debug_info[sta]["wn_old"] = np.sum([wn.log_p() for wn in sg.station_waves[sta]])
                
            for wn in sg.station_waves[sta]:
                fr_sta = None
                if fix_result is not None:
                    fr_sta = fix_result[wn.label]                
                lqf_sta, replicate_sta, death_sta = \
                    ev_sta_template_birth_helper(sg, wn, eid=eid, 
                                                 site_phases=site_phases,
                                                 fix_result=fr_sta,
                                                 associate_using_mb=associate_using_mb,
                                                 debug_info=debug_info_sta, 
                                                 proposal_type=proposal_type,
                                                 **kwargs)
                log_qforward += lqf_sta
                replicate_fns.append(replicate_sta)
                death_records[wn.label] = death_sta
                
            if debug_info_sta is not None:
                debug_info[sta]["wn_new"] = np.sum([wn.log_p() for wn in sg.station_waves[sta]])
                
    def replicate_move():
        for fn in replicate_fns:
            fn()
    
    return log_qforward, replicate_move, death_records

                
    
def ev_birth_executor(sg, location_proposal, 
                      proposal_includes_mb=True, 
                      proposal_type="mh",
                      force_eid=None,
                      force_outcome=None):
    debug_info = {}
        

    log_qbackward = 0.0
    log_qforward = 0.0

    n_current_events = len(sg.evnodes) - len(sg.fixed_events)
    if force_eid is None:
        log_qforward += -np.log(n_current_events + 1)
    
    lp_old = sg.current_log_p()

    lq_loc, replicate_birth, eid, extra = ev_bare_birth_move(sg, location_proposal, debug_info=debug_info, eid=force_eid)
    if lq_loc is None:
        return None

    log_qforward += lq_loc

    lqf, replicate_tmpls, birth_records = \
                    ev_template_birth_helper(sg, eid, 
                                             associate_using_mb=proposal_includes_mb, 
                                             proposal_type=proposal_type,
                                             debug_info=debug_info)
    log_qforward += lqf
    sg._topo_sort()
    
    lp_new = sg.current_log_p()
    
    lqb, replicate_untmpls, death_records = ev_template_death_helper(sg, eid, fix_result=birth_records)
    log_qbackward += lqb

    if force_eid is None:
        lq_death = death_proposal_logprob(sg, eid)
        log_qbackward += lq_death

    replicate_death, ev = ev_bare_death_move(sg, eid)
    sg._topo_sort()
    
    # should get rid of this (and corresponding line in death move) at
    # some point once I'm confident, since it's actually pretty
    # expensive
    lp_old2 = sg.current_log_p()
    assert(np.abs(lp_old2 - lp_old) < 1e-6)

    def rebirth():
        replicate_birth()
        replicate_tmpls()
        sg._topo_sort()
        
    def redeath():
        replicate_untmpls() # maybe not technically necessary
        replicate_death()
        sg._topo_sort()

    proposal_extra = (extra, eid, debug_info)
    return lp_new, lp_old, log_qforward, log_qbackward, rebirth, redeath, proposal_extra

def ev_birth_move_abstract(sg, location_proposal, revert_action=None, 
                           accept_action=None, force_outcome=None, **kwargs):

    r = ev_birth_executor(sg, location_proposal, **kwargs)
    if r is None:
        # location proposal did not return an event
        return False
    else:
        lp_new, lp_old, log_qforward, log_qbackward, rebirth, redeath, proposal_extra = r


    def revert():
        if revert_action is not None:
            revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        #revert_move()

    def accept():
        rebirth()
        if accept_action is not None:
            accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)


    sg.logger.info( "birth move acceptance %f from old %f new %f lqb %f lqf %f" % ( (lp_new + log_qbackward) - (lp_old+log_qforward), lp_old, lp_new, log_qbackward, log_qforward))


    return mh_accept_util(lp_old, lp_new, log_qforward, log_qbackward, accept_move=accept, revert_move=revert, force_outcome=force_outcome)

def ev_birth_move_hough(sg, log_to_run_dir=None, hough_kwargs = {}, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, debug_info = proposal_extra

        if log_to_run_dir is None:
            sg.logger.warning("WARNING: not logging event because no rundir specified")
            return

        log_file = os.path.join(log_to_run_dir, "hough_proposals.txt")
        ev_log_file = os.path.join(log_to_run_dir, "birth_proposal_%d.txt" % eid)

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write(" hough args %s\n" % repr(hough_kwargs))
            f.write(" acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            f.write("\n")
        with open(ev_log_file, 'w') as f:
            f.write(prettyprint_debug(debug_info))


    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, debug_info = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

        if log_to_run_dir is None:
            return
                
        if np.random.rand() < 1.0: #0.1:
            sites = sg.site_elements.keys()
            sg.logger.info("saving hough array picture...")
            fname = 'last_hough%s.png' % ("_".join(["",] + hough_kwargs.keys()))
            visualize_hough_array(hough_array, sites, os.path.join(log_to_run_dir, fname), region=sg.inference_region)


    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        hough_array, eid, debug_info = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

        if log_to_run_dir is None:
            return

        if log_to_run_dir is not None:
            log_event_birth(sg, hough_array, log_to_run_dir, eid)
        else:
            raise Exception("why are we not logging?")

    def hlp(sg, **kwargs):
        kwargs.update(hough_kwargs)
        return hough_location_proposal(sg, **kwargs)

    return ev_birth_move_abstract(sg, location_proposal=hlp, revert_action=revert_action, accept_action=accept_action, proposal_includes_mb=True, **kwargs)


def prior_location_proposal(sg, fix_result=None):
    ev, lp = sg.prior_sample_event(return_logp=True, fix_result=fix_result)
    if fix_result is not None:
        return lp
    else:
        return ev, lp, None

def ev_birth_move_prior(sg, log_to_run_dir=None, **kwargs):
    return ev_birth_move_abstract(sg, location_proposal=prior_location_proposal, 
                                  proposal_includes_mb=True, 
                                  proposal_type="dumb", **kwargs)

def ev_death_move_prior(sg, log_to_run_dir=None, **kwargs):
    return ev_death_move_abstract(sg, location_proposal=prior_location_proposal, 
                                  proposal_includes_mb=True, 
                                  birth_type="dumb", **kwargs)

def ev_birth_move_hough_offset(sg, **kwargs):
    hough_kwargs = {"offset": True}
    return ev_birth_move_hough(sg, hough_kwargs=hough_kwargs, **kwargs)

def ev_birth_move_hough_dumb(sg, **kwargs):
    hough_kwargs = {"one_event_semantics": False}
    return ev_birth_move_hough(sg, hough_kwargs=hough_kwargs, 
                               proposal_type="dumb", **kwargs)


def ev_birth_move_correlation(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        _, eid, associations, debug_info = proposal_extra
        #hough_array, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "correlation_proposals.txt")

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write(" acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            for (wn, phase), (assoc, tmvals) in associations.items():
                if assoc:
                    f.write(" associated %s at %s, %s, %s\n" % (phase, wn.sta, wn.chan, wn.band))
            f.write("\n")


    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        #if log_to_run_dir is not None:
        #    log_event_birth(sg, None, log_to_run_dir, eid)
        #else:
        #    raise Exception("why are we not logging?")

    return ev_birth_move_abstract(sg, location_proposal=correlation_location_proposal, revert_action=revert_action, accept_action=accept_action, proposal_includes_mb=False, **kwargs)


def ev_birth_move_cheating(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_file = os.path.join(log_to_run_dir, "correlation_proposals.txt")


    def revert_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)

    def accept_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        #hough_array, eid, associations = proposal_extra
        log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward)
        #if log_to_run_dir is not None:
        #    log_event_birth(sg, None, log_to_run_dir, eid)
        #else:
        #    raise Exception("why are we not logging?")

    return ev_birth_move_abstract(sg, location_proposal=cheating_location_proposal, revert_action=revert_action, accept_action=accept_action, proposal_includes_mb=True, **kwargs)


def ev_birth_move_lstsqr(sg, log_to_run_dir=None, **kwargs):

    def log_action(proposal_extra, lp_old, lp_new, log_qforward, log_qbackward):
        refined_proposals, eid, associations, debug_info = proposal_extra
        log_file = os.path.join(log_to_run_dir, "lsqr_proposals.txt")

        # proposed event should be the most recently created
        try:
            proposed_ev = sg.get_event(np.max(sg.evnodes.keys()))
        except:
            proposed_ev = None

        if refined_proposals is None:
            refined_proposals = []

        with open(log_file, 'a') as f:
            f.write("proposed ev: %s\n" % proposed_ev)
            f.write("acceptance lp %.2f (lp_old %.2f lp_new %.2f log_qforward %.2f log_qbackward %.2f)\n" % (lp_new +log_qbackward - (lp_old + log_qforward), lp_old, lp_new, log_qforward, log_qbackward))
            for abserror, z, C in refined_proposals:
                f.write("  %.2f lon %.2f lat %.2f depth %.2f time %.2f\n" % (abserror, z[0], z[1], z[2], z[3]))
            f.write("\n")

    return ev_birth_move_abstract(sg, location_proposal=overpropose_new_locations, accept_action=log_action, revert_action=log_action, **kwargs)

##############################################################

def log_event_birth(sg, hough_array, run_dir, eid):

    log_dir = os.path.join(run_dir, "ev_%05d" % eid)
    mkdir_p(log_dir)

    # save post-birth signals and general state
    # sg.debug_dump(dump_path=log_dir, pickle_graph=False)


    # save Hough transform
    sites = sg.site_elements.keys()
    if hough_array is not None:
        sg.logger.info("visualizing hough array...")
        visualize_hough_array(hough_array, sites, os.path.join(log_dir, 'hough.png'), region=sg.inference_region)


def prettyprint_debug(birth_debug):
    s = ""

    # track lp_new - (lp_old + log_qforward)
    overall_score = 0

    inferred_lpnew = 0
    inferred_lpold = 0
    inferred_qforward = 0

    ev, lq_ev, lps_ev = birth_debug["ev"]
    s += "proposed ev %s\n" % ev
    s += "proposal logq %.2f, lps " % lq_ev
    total_lp = 0
    for (param, lp) in lps_ev:
        s += "%s %.2f, " % (param, lp)
        inferred_lpnew += lp
        total_lp += lp

    inferred_qforward += lq_ev
    delta = total_lp - lq_ev
    s += "total %.2f, delta %.2f\n" % (total_lp, delta)
    overall_score = delta

    
    for sta in birth_debug.keys():
        if sta=="ev": continue

        wn_old, wn_new = birth_debug[sta]["wn_old"], birth_debug[sta]["wn_new"]
        inferred_lpold += wn_old
        inferred_lpnew += wn_new
        wn_delta = wn_new - wn_old

        try:
            phase_assocs, assoc_lp, _ = birth_debug[sta]["assoc"]
        except KeyError:
            s += "sta %s wn_old %.2f wn_new %.2f wn_delta %.2f NO ASSOC INFO overall %.2f\n" % (sta, wn_old, wn_new, wn_delta, wn_delta)
            continue
            

        s += "sta %s wn_old %.2f wn_new %.2f wn_delta %.2f assoc %.2f overall STASCORE\n" % (sta, wn_old, wn_new, wn_delta, assoc_lp)
        sta_score = wn_delta - assoc_lp
        inferred_qforward += assoc_lp

        phase_assocs = dict(phase_assocs)
        
        for phase in birth_debug[sta].keys():
            if "wn" in phase or phase=="assoc" : continue
            phase_score = 0
            tmid = phase_assocs[phase]
            if tmid is not None:
                s += " phase %s: associating tmid %d, score PHASESCORE\n" % (phase, tmid)
            else:
                s += " phase %s: birthing new template, score PHASESCORE\n" % (phase)

            d = birth_debug[sta][phase]
            for param, (v, lp1, lp2) in sorted(d.items()):
                if param=="assoc": continue
                delta = lp2-lp1
                if tmid is not None:
                    s += "   %s %.2f ualp %.2f evlp %.2f delta %.2f\n" % (param, v, lp1, lp2, delta)
                    inferred_lpold += lp1
                    inferred_lpnew += lp2
                else:
                    s += "   %s %.2f logq %.2f logp %.2f delta %.2f\n" % (param, v, lp1, lp2, delta)
                    inferred_qforward += lp1
                    inferred_lpnew += lp2

                phase_score += delta
            s = s.replace("PHASESCORE", "%.2f" % phase_score)
            sta_score += phase_score

        overall_score += sta_score
        s = s.replace("STASCORE", "%.2f" % sta_score)
    s += "final proposal score %.2f\n" % overall_score
    s += "inferred lpold %.1f lpnew %.1f delta %.1f log_qforward %.1f alt_score %.1f\n" % (inferred_lpold, inferred_lpnew, inferred_lpnew-inferred_lpold, inferred_qforward, inferred_lpnew - inferred_lpold - inferred_qforward)
    s += "REMEMBER: the acceptance ratio also includes the reverse proposal probability from the death move.\n"

    return s
